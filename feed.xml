<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://millengustavo.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://millengustavo.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-08-24T15:44:24-05:00</updated><id>https://millengustavo.github.io/blog/feed.xml</id><title type="html">Gustavo Millen</title><subtitle>Data Science and Machine Learning blog.</subtitle><entry><title type="html">Learning Python Design Patterns</title><link href="https://millengustavo.github.io/blog/book/software%20engineering/python/design%20patterns/2020/08/22/python-design-patterns.html" rel="alternate" type="text/html" title="Learning Python Design Patterns" /><published>2020-08-22T00:00:00-05:00</published><updated>2020-08-22T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/software%20engineering/python/design%20patterns/2020/08/22/python-design-patterns</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/software%20engineering/python/design%20patterns/2020/08/22/python-design-patterns.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Author: Chetan Giridhar&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Learning-Python-Design-Patterns-Second-ebook/dp/B018XYKNOM&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch1-introduction-to-design-patterns&quot;&gt;Ch1. Introduction to design patterns&lt;/h1&gt;

&lt;h2 id=&quot;understanding-object-oriented-programming&quot;&gt;Understanding object-oriented programming&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Concept of &lt;em&gt;objects&lt;/em&gt; that have attributes (data members) and procedures (member functions)&lt;/li&gt;
  &lt;li&gt;Procedures are responsible for manipulating the attributes&lt;/li&gt;
  &lt;li&gt;Objects, which are instances of classes, interact among each other to serve the purpose of an application under development&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;classes&quot;&gt;Classes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Define objects in attributes and behaviors (methods)&lt;/li&gt;
  &lt;li&gt;Classes consist of constructors that provide the initial state for these objects&lt;/li&gt;
  &lt;li&gt;Are like templates and hence can be easily reused&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;methods&quot;&gt;Methods&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Represent the behavior of the object&lt;/li&gt;
  &lt;li&gt;Work on attributes and also implement the desired functionality&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;major-aspects-of-oop&quot;&gt;Major aspects of OOP&lt;/h2&gt;

&lt;h3 id=&quot;encapsulation&quot;&gt;Encapsulation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An object’s behavior is kept hidden from the outside world or objects keep their state information private&lt;/li&gt;
  &lt;li&gt;Clients can’t change the object’s internal state by directly acting on them&lt;/li&gt;
  &lt;li&gt;Clients request the object by sending requests. Based on the type, objects may respond by changing their internal state using special member functions such as &lt;code class=&quot;highlighter-rouge&quot;&gt;get&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;set&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;polymorphism&quot;&gt;Polymorphism&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Can be of two types:
    &lt;ul&gt;
      &lt;li&gt;An object provides different implementations of the method based on input parameters&lt;/li&gt;
      &lt;li&gt;The same interface can be used by objects of different types&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In Python polymorphism is a feature built-in for the language (e.g. + operator)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inheritance&quot;&gt;Inheritance&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Indicates that one class derives (most of) its functionality from the parent class&lt;/li&gt;
  &lt;li&gt;An option to reuse functionality defined in the base class and allow independent extensions of the original software implementation&lt;/li&gt;
  &lt;li&gt;Creates hierarchy via the relationships among objects of different classes&lt;/li&gt;
  &lt;li&gt;Python supports multiple inheritance (multiple base classes)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;abstraction&quot;&gt;Abstraction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Provides a simple interface to the clients. Clients can interact with class objects and call methods defined in the interface&lt;/li&gt;
  &lt;li&gt;Abstracts the complexity of internal classes with an interface so that the client need not be aware of internal implementations&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;composition&quot;&gt;Composition&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Combine objects or classes into more complex data structures or software implementations&lt;/li&gt;
  &lt;li&gt;An object is used to call member functions in other modules thereby making base functionality available across modules without inheritance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;object-oriented-design-principles&quot;&gt;Object-oriented design principles&lt;/h2&gt;

&lt;h3 id=&quot;the-openclose-principle&quot;&gt;The open/close principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Classes or objects and methods should be open for extension but closed for modifications&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Make sure you write your classes or modules in a generic way&lt;/li&gt;
  &lt;li&gt;Existing classes are not changed reducing the chances of regression&lt;/li&gt;
  &lt;li&gt;Helps maintain backward compatibility&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-inversion-of-control-principle&quot;&gt;The inversion of control principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;High-level modules shouldn’t be dependent on low-level modules; they should be dependent on abstractions. Details should depend on abstractions and not the other way round&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The base module and dependent module should be decoupled with an abstraction layer in between&lt;/li&gt;
  &lt;li&gt;The details of your class should represent the abstractions&lt;/li&gt;
  &lt;li&gt;The tight coupling of modules is no more prevalent and hence no complexity/rigidity in the system&lt;/li&gt;
  &lt;li&gt;Easy to deal with dependencies across modules in a better way&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-interface-segregation-principle&quot;&gt;The interface segregation principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Clients should not be force to depend on interfaces they don’t use&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Forces developers to write thin interfaces and have methods that are specific to the interface&lt;/li&gt;
  &lt;li&gt;Helps you not to populate interfaces by adding unintentional methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-single-responsibility-principle&quot;&gt;The single responsibility principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;A class should have only one reason to change&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;If a class is taking care of two functionalities, it is better to split them&lt;/li&gt;
  &lt;li&gt;Functionality = a reason to change&lt;/li&gt;
  &lt;li&gt;Whenever there is a change in one functionality, this particular class needs to change, and nothing else&lt;/li&gt;
  &lt;li&gt;If a class has multiple functionalities, the dependent classes will have to undergo changes for multiple reasons, which gets avoided&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-substitution-principle&quot;&gt;The substitution principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Derived classes must be able to completely substitute the base classes&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-concept-of-design-patterns&quot;&gt;The concept of design patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Solutions to given problems&lt;/li&gt;
  &lt;li&gt;Design patterns are discoveries and not a invention in themselves&lt;/li&gt;
  &lt;li&gt;Is about learning from others’ successes rather than your own failures!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;advantages-of-design-patterns&quot;&gt;Advantages of design patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Reusable across multiple projects&lt;/li&gt;
  &lt;li&gt;Architectural level of problems can be solved&lt;/li&gt;
  &lt;li&gt;Time-tested and well-proven, which is the experience of developers and architects&lt;/li&gt;
  &lt;li&gt;They have reliability and dependence&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;patterns-for-dynamic-languages&quot;&gt;Patterns for dynamic languages&lt;/h3&gt;
&lt;p&gt;Python:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Types or classes are objects at runtime&lt;/li&gt;
  &lt;li&gt;Variables can have type as a value and can be modified at runtime&lt;/li&gt;
  &lt;li&gt;Dynamic languages have more flexibility in terms of class restrictions&lt;/li&gt;
  &lt;li&gt;Everything is public by default&lt;/li&gt;
  &lt;li&gt;Design patterns can be easily implemented in dynamic languages&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;classifying-patterns&quot;&gt;Classifying patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Creational&lt;/li&gt;
  &lt;li&gt;Structural&lt;/li&gt;
  &lt;li&gt;Behavioral&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Classification of patterns is done based primarily on how the objects get created, how classes and objects are structured in a software application, and also covers the way objects interact among themselves&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;creational-patterns&quot;&gt;Creational patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Work on the basis of how objects can be created&lt;/li&gt;
  &lt;li&gt;Isolate the details of object creation&lt;/li&gt;
  &lt;li&gt;Code is independent of the type of object to be created&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;structural-patterns&quot;&gt;Structural patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Design the structure of objects and classes so that they can compose to achieve larger results&lt;/li&gt;
  &lt;li&gt;Focus on simplifying the structure and identifying the relationship between classes and objects&lt;/li&gt;
  &lt;li&gt;Focus on class inheritance and composition&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;behavioral-patterns&quot;&gt;Behavioral patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Concerned with the interaction among objects and responsibilities of objects&lt;/li&gt;
  &lt;li&gt;Objects should be able to interact and still be loosely coupled&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-the-singleton-design-pattern&quot;&gt;Ch2. The singleton design pattern&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Typically used in logging or database operations, printer spoolers, thread pools, caches, dialog boxes, registry settings, and so on&lt;/li&gt;
  &lt;li&gt;Ensure that only one object of the class gets created&lt;/li&gt;
  &lt;li&gt;Provide an access point for an object that is global to the program&lt;/li&gt;
  &lt;li&gt;Control concurrent access to resources that are shared&lt;/li&gt;
  &lt;li&gt;Make the constructor private and create a static method that does the object initialization&lt;/li&gt;
  &lt;li&gt;Override the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method (Python’s special method to instantiate objects) to control the object creation&lt;/li&gt;
  &lt;li&gt;Another use case: &lt;strong&gt;lazy instantiation&lt;/strong&gt;. Makes sure that the object gets created when it’s actually needed&lt;/li&gt;
  &lt;li&gt;All modules are Singletons by default because of Python’s importing behavior&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;monostate-singleton-pattern&quot;&gt;Monostate Singleton pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;All objects share the same state&lt;/li&gt;
  &lt;li&gt;Assign the &lt;code class=&quot;highlighter-rouge&quot;&gt;__dict__&lt;/code&gt; variable with the &lt;code class=&quot;highlighter-rouge&quot;&gt;__shared_state&lt;/code&gt; class variable. Python uses &lt;code class=&quot;highlighter-rouge&quot;&gt;__dict__&lt;/code&gt; to store the state of every object of a class&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;singletons-and-metaclasses&quot;&gt;Singletons and metaclasses&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;A metaclass is a class of a class&lt;/li&gt;
  &lt;li&gt;The class is an instance of its metaclass&lt;/li&gt;
  &lt;li&gt;Programmers get an opportunity to create classes of their own type from the predefined Python classes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;drawbacks&quot;&gt;Drawbacks&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Singletons have a global point of access&lt;/li&gt;
  &lt;li&gt;Al classes that are dependent on global variables get tightly coupled as a change to the global data by one class can inadvertently impact the other class&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch3-the-factory-pattern---building-factories-to-create-objects&quot;&gt;Ch3. The factory pattern - building factories to create objects&lt;/h1&gt;

&lt;h2 id=&quot;understanding-the-factory-pattern&quot;&gt;Understanding the factory pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Factory = a class that is responsible for creating objects of other types&lt;/li&gt;
  &lt;li&gt;The class that acts as a factory has an object and methods associated with it&lt;/li&gt;
  &lt;li&gt;The client calls this method with certain parameters; objects of desired types are created in turn and returned to the client by the factory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Loose coupling: object creation can be independent of the class implementation&lt;/li&gt;
  &lt;li&gt;The client only needs to know the interface, methods, and parameters that need to be passed to create objects of the desired type (simplifies implementations for the client)&lt;/li&gt;
  &lt;li&gt;Adding another class to the factory to create objects of another type can be easily done without the client changing the code&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-simple-factory-pattern&quot;&gt;The simple factory pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Not a pattern in itself&lt;/li&gt;
  &lt;li&gt;Helps create objects of different types rather than direct object instantiation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-factory-method-pattern&quot;&gt;The factory method pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;We define an interface to create objects, but instead of the factory being responsible for the object creation, the responsibility is deferred to the subclass that decides the class to be instantiated&lt;/li&gt;
  &lt;li&gt;Creation is through inheritance and not through instantiation&lt;/li&gt;
  &lt;li&gt;Makes the design more customizable. It can return the same instance or subclass rather than an object of a certain type&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The factory method pattern defines an interface to create an object, but defers the decision ON which class to instantiate to its subclasses&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Makes the code generic and flexible, not being tied to a certain class for instantiation. We’re dependent on the interface (Product) and not on the ConcreteProduct class&lt;/li&gt;
  &lt;li&gt;Loose coupling: the code that creates the object is separate from the code that uses it&lt;/li&gt;
  &lt;li&gt;The client don’t need to bother about what argument to pass and which class to instantiate -&amp;gt; the addition of new classes is easy and involves low maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-abstract-factory-pattern&quot;&gt;The abstract factory pattern&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Provide an interface to create families of related objects without specifying the concrete class&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Makes sure that the client is isolated from the creation of objects but allowed to use the objects created&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;factory-method-versus-abstract-factory-method&quot;&gt;Factory method versus abstract factory method&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;Factory method&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;Abstract Factory method&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Exposes a method to the client to create the objects&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Contains one or more factory methods of another class&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Uses inheritance and subclass to decide which object to create&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Uses composition to delegate responsibility to create objects of another class&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Is used to create one product&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Is about creating families of related products&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;ch4-the-façade-pattern---being-adaptive-with-façade&quot;&gt;Ch4. The façade pattern - being adaptive with façade&lt;/h1&gt;

&lt;h2 id=&quot;understanding-structural-design-patterns&quot;&gt;Understanding Structural design patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Describe how objects and classes can be combined to form larger structures. Structural patterns are a combination of class and object patterns&lt;/li&gt;
  &lt;li&gt;Ease the design by identifying simpler ways to realize or demonstrate relationships between entities&lt;/li&gt;
  &lt;li&gt;Class patterns: describe abstraction with the help of inheritance and provide a more useful program interface&lt;/li&gt;
  &lt;li&gt;Object patterns: describe how objects can be associated and composed to form larger objects&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;understanding-the-façade-design-pattern&quot;&gt;Understanding the Façade design pattern&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Façade hides the complexities of the internal system and provides an interface to the client that can access the system in a very simplified way&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Provides an unified interface to a set of interfaces in a subsystem and defines a high-level interface that helps the client use the subsystem in an easy way&lt;/li&gt;
  &lt;li&gt;Discusses representing a complex subsystem with a single interface object -&amp;gt; it doesn’t encapsulate the subsystem, but actually combines the underlying subsystems&lt;/li&gt;
  &lt;li&gt;Promotes the decoupling of the implementation with multiple clients&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;main-participants&quot;&gt;Main participants&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Façade&lt;/strong&gt;: wrap up a complex group of subsystems so that it can provide a pleasing look to the outside world&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;System&lt;/strong&gt;: represents a set of varied subsystems that make the whole system compound and difficult to view or work with&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;: interact with the façade so that it can easily communicate with the subsystem and get the work completed (doesn’t have to bother about the complex nature of the system)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-principle-of-least-knowledge&quot;&gt;The principle of least knowledge&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Design principle behind Façade pattern&lt;/li&gt;
  &lt;li&gt;Reduce the interactions between objects to just a few friend that are close enough to you&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-law-of-demeter&quot;&gt;The Law of Demeter&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Design guideline:
    &lt;ul&gt;
      &lt;li&gt;Each unit should have only limited knowledge of other units of the system&lt;/li&gt;
      &lt;li&gt;A unit should talk to its friends only&lt;/li&gt;
      &lt;li&gt;A unit should not know about the internal details of the object that it manipulates&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The principle of least knowledge and Law of Demeter are the same and both point to the philosophy of &lt;em&gt;loose coupling&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch5-the-proxy-pattern---controlling-object-access&quot;&gt;Ch5. The proxy pattern - controlling object access&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Proxy: a system that intermediates between the seeker and provider. Seeker is the one that makes the request, and provider delivers the resources in response to the request&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;A proxy server encapsulates requests, enables privacy, and works well in distributed architectures&lt;/li&gt;
  &lt;li&gt;Proxy is a wrapper or agent object that wraps the real serving object&lt;/li&gt;
  &lt;li&gt;Provide a surrogate or placeholder for another object in order to control access to a real object&lt;/li&gt;
  &lt;li&gt;Some useful scenarios:
    &lt;ul&gt;
      &lt;li&gt;Represents a complex system in a simpler way&lt;/li&gt;
      &lt;li&gt;Acts as a shield against malicious intentions and protect the real object&lt;/li&gt;
      &lt;li&gt;Provides a local interface for remote objects on different servers&lt;/li&gt;
      &lt;li&gt;Provides a light handle for a higher memory-consuming object&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-structure-components&quot;&gt;Data Structure components&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Proxy&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Subject/RealSubject&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;different-types-of-proxies&quot;&gt;Different types of proxies&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Virtual proxy&lt;/strong&gt;: placeholder for objects that are very heavy to instantiate&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remote proxy&lt;/strong&gt;: provides a local representation of a real object that resides on a remote server or different address space&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Protective proxy&lt;/strong&gt;: controls access to the sensitive matter object of &lt;code class=&quot;highlighter-rouge&quot;&gt;RealSubject&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Smart proxy&lt;/strong&gt;: interposes additional actions when an object is accessed&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Proxy&lt;/th&gt;
      &lt;th&gt;Façade&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Provides you with a surrogate or placeholder for another object to control access to it&lt;/td&gt;
      &lt;td&gt;Provides you with an interface to large subsystems of classes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A Proxy object has the same interface as that of the target object and holds references to target objects&lt;/td&gt;
      &lt;td&gt;Minimizes the communication and dependencies between subsystems&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Acts as an intermediary between the client and object that is wrapped&lt;/td&gt;
      &lt;td&gt;Provides a single simplified interface&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;decorator-vs-proxy&quot;&gt;Decorator vs Proxy&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Decorator adds behavior to the object that it decorates at runtime&lt;/li&gt;
  &lt;li&gt;Proxy controls access to an object&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;disadvantages&quot;&gt;Disadvantages&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Proxy pattern can increase the response time&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-the-observer-pattern---keeping-objects-in-the-know&quot;&gt;Ch6. The observer pattern - keeping objects in the know&lt;/h1&gt;

&lt;h2 id=&quot;behavioral-patterns-1&quot;&gt;Behavioral patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Focus on the responsibilities that an object has&lt;/li&gt;
  &lt;li&gt;Deal with the interaction among objects to achieve larger functionality&lt;/li&gt;
  &lt;li&gt;Objects should be able to interact with each other, &lt;strong&gt;but they should still be loosely coupled&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;understanding-the-observer-design-pattern&quot;&gt;Understanding the observer design pattern&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;An object (Subject) maintains a list of dependents (Observers) so that the Subject can notify all the Observers about the changes that it undergoes using any of the methods defined by the Observer&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Defines a one-to-many dependency between objects so that any change in one object will be notified to the other dependent objects automatically&lt;/li&gt;
  &lt;li&gt;Encapsulates the core component of the Subject&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-pull-model&quot;&gt;The pull model&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Subject broadcasts to all the registered Observers when there is any change&lt;/li&gt;
  &lt;li&gt;Observer is responsible for getting the changes or pulling data from the subscriber when there is an amendment&lt;/li&gt;
  &lt;li&gt;Pull model is &lt;strong&gt;ineffective&lt;/strong&gt;: involves two steps:
    &lt;ul&gt;
      &lt;li&gt;Subject notifies the Observer&lt;/li&gt;
      &lt;li&gt;Observer pulls the required data from the Subject&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-push-model&quot;&gt;The push model&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Changes are pushed by the Subject to the Observer&lt;/li&gt;
  &lt;li&gt;Subject can send detailed information to the Observer (even though it may not be needed) -&amp;gt; can result in sluggish response times when a large amount of data in sent by the Subject but is never actually used by the Observer&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loose-coupling-and-the-observer-pattern&quot;&gt;Loose coupling and the observer pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Coupling refers to the degree of knowledge that one object has about the other object that it interacts with&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Loosely-coupled designs allow us to build flexbile object-oriented systems that can handle changes because they reduce the dependency between multiple objects&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Reduces the risk that a change made within one element might create an unanticipated impact on the other elements&lt;/li&gt;
  &lt;li&gt;Simplifies testing, maintenance, and troubleshooting problems&lt;/li&gt;
  &lt;li&gt;System can be easily broken down into definable elements&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch7-the-command-pattern---encapsulating-invocation&quot;&gt;Ch7. The command pattern - encapsulating invocation&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Behavioral design pattern in which an object is used to encapsulate all the information needed to perform an action or trigger an event at a later time&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;understanding-the-command-design-pattern&quot;&gt;Understanding the command design pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;Command&lt;/code&gt; object knows about the &lt;code class=&quot;highlighter-rouge&quot;&gt;Receiver&lt;/code&gt; objects and invokes a method of the &lt;code class=&quot;highlighter-rouge&quot;&gt;Receiver&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;Values for parameters of the receiver method are stored in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Command&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;The invoker knows how to execute a command&lt;/li&gt;
  &lt;li&gt;The client creates a &lt;code class=&quot;highlighter-rouge&quot;&gt;Command&lt;/code&gt; object and sets its receiver&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intentions&quot;&gt;Intentions&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Encapsulating a request as an object&lt;/li&gt;
  &lt;li&gt;Allowing the parametrization of clients with different requests&lt;/li&gt;
  &lt;li&gt;Allowing to save the requests in a queue&lt;/li&gt;
  &lt;li&gt;Providing an object-oriented callback&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scenarios-of-use&quot;&gt;Scenarios of use&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Parametrizing objects depending on the action to be performed&lt;/li&gt;
  &lt;li&gt;Adding actions to a queue and executing requests at different points&lt;/li&gt;
  &lt;li&gt;Creating a structure for high-level operations that are based on smaller operations&lt;/li&gt;
  &lt;li&gt;E.g.:
    &lt;ul&gt;
      &lt;li&gt;Redo or rollback operations&lt;/li&gt;
      &lt;li&gt;Asynchronous task execution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advantages&quot;&gt;Advantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Decouples the classes that invoke the operation from the object that knows how to execute the operation&lt;/li&gt;
  &lt;li&gt;Provide a queue system&lt;/li&gt;
  &lt;li&gt;Extensions to add new commands are easy&lt;/li&gt;
  &lt;li&gt;A rollback system with the command pattern can be defined&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;disadvantages-1&quot;&gt;Disadvantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;High number of classes and objects working together to achieve a goal&lt;/li&gt;
  &lt;li&gt;Every individual command is a &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteCommand&lt;/code&gt; class that increases the volume of classes for implementation and maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch8-the-templated-method-pattern---encapsulating-algorithm&quot;&gt;Ch8. The templated method pattern - encapsulating algorithm&lt;/h1&gt;

&lt;h2 id=&quot;use-cases&quot;&gt;Use cases&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;When multiple algorithms or classes implements similar or identical logic&lt;/li&gt;
  &lt;li&gt;The implementation of algorithms in subclasses helps reduce code duplication&lt;/li&gt;
  &lt;li&gt;Multiple algorithms can be defined by letting the subclasses implement the behavior through overriding&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intentions-1&quot;&gt;Intentions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Define a skeleton of an algorithm with primitive operations&lt;/li&gt;
  &lt;li&gt;Redefine certain operations of the subclass without changing the algorithm’s structure&lt;/li&gt;
  &lt;li&gt;Achieve code reuse and avoid duplicate efforts&lt;/li&gt;
  &lt;li&gt;Leverage common interfaces or implementations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;terms&quot;&gt;Terms&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AbstractClass&lt;/code&gt;: Declares an interface to define the steps of the algorithm&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteClass&lt;/code&gt;: Defines subclass-specific step definitions&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;template_method()&lt;/code&gt;: Defines the algorithm by calling the step methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hooks&quot;&gt;Hooks&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hook: a method that is declared in the abstract class&lt;/li&gt;
  &lt;li&gt;Give a subclass the ability to &lt;em&gt;hook into&lt;/em&gt; the algorithm whenever needed&lt;/li&gt;
  &lt;li&gt;Not imperative for the subclass to use hooks&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;We use abstract methods when the subclass must provide the implementation, and hook is used when it is optional for the subclass to implement it&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-hollywood-principle&quot;&gt;The Hollywood principle&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Design principle summarized by &lt;strong&gt;Don’t call us, we’ll call you&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Relates to the template method -&amp;gt; it’s the high-level abstract class that arranges the steps to define the algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advantages-1&quot;&gt;Advantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;No code duplication&lt;/li&gt;
  &lt;li&gt;Uses inheritance and not composition -&amp;gt; only a few methods need to be overriden&lt;/li&gt;
  &lt;li&gt;Flexibility lets subclasses decide how implement steps in an algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;disadvantages-2&quot;&gt;Disadvantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Confusing debugging and undestanding the sequence of flow&lt;/li&gt;
  &lt;li&gt;Documentation and strict error handling has to be done by the programmer&lt;/li&gt;
  &lt;li&gt;Maintenance can be a problem -&amp;gt; changes to any level can disturb the implementation&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch9-model-view-controller---compound-patterns&quot;&gt;Ch9. Model-View-Controller - Compound patterns&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;“A compound pattern combines two or more patterns into a solution that solves a recurring or general problem” - GoF&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A compound pattern is not a set of patterns working together; it is a general solution to a problem&lt;/p&gt;

&lt;h2 id=&quot;the-model-view-controller-pattern&quot;&gt;The Model-View-Controller pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Model represents the data and business logic: how information is stored and queried&lt;/li&gt;
  &lt;li&gt;View is nothing but the representation: how it is presented&lt;/li&gt;
  &lt;li&gt;Controller is the one that directs the model and view to behave in a certain way: it’s the glue between the two&lt;/li&gt;
  &lt;li&gt;The view and controller are dependent on the model, but not the other way around&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;terms-1&quot;&gt;Terms&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Model - knowledge of the application&lt;/strong&gt;: store and manipulate data (create, modify and delete). Has state and methods to change states, but is not aware of how the data would be seen by the client&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;View - the appearance&lt;/strong&gt;: build user interfaces and data displays (it should not contain any logic of its own and just display the data it receives)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Controller - the glue&lt;/strong&gt;: connects the model and view (it has methods that are used to route requests)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;User&lt;/strong&gt;: requests for certain results based on certain actions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intention&quot;&gt;Intention&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Keep the data and presentation of the data separate&lt;/li&gt;
  &lt;li&gt;Easy maintenance of the class and implementation&lt;/li&gt;
  &lt;li&gt;Flexibility to change the way in which data is stored and displayed -&amp;gt; both are independent and hence have the flexibility to change&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-mvc-pattern-in-the-real-world&quot;&gt;The MVC pattern in the real world&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Django or Rails&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MTV (Model, Template, View)&lt;/strong&gt;: model is the database, templates are the views, and controllers are the views/routes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;benefits-of-the-mvc-pattern&quot;&gt;Benefits of the MVC pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Easy maintenance&lt;/li&gt;
  &lt;li&gt;Loose coupling&lt;/li&gt;
  &lt;li&gt;Decrease complexity&lt;/li&gt;
  &lt;li&gt;Development efforts can run independently&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-the-state-design-pattern&quot;&gt;Ch10. The state design pattern&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Behavioral design pattern&lt;/li&gt;
  &lt;li&gt;Sometimes referred to as an &lt;strong&gt;objects for states&lt;/strong&gt; pattern&lt;/li&gt;
  &lt;li&gt;Used to develop Finite State Machines and helps to accommodate State Transaction Actions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;understanding-the-state-design-pattern&quot;&gt;Understanding the state design pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;State&lt;/code&gt;: an interface that encapsulates the object’s behavior. This behavior is associated with the state of the object&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt;: a subclass that implements the &lt;code class=&quot;highlighter-rouge&quot;&gt;State&lt;/code&gt; interface -&amp;gt; implements the actual behavior associated with the object’s particular state&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Context&lt;/code&gt;: the interface of interest to clients. Also maintains an instance of the &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt; subclass that internally defines the implementation of the object’s particular state&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advantages-2&quot;&gt;Advantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Removes the dependency on the if/else or switch/else conditional logic&lt;/li&gt;
  &lt;li&gt;Benefits of implementing polymorphic behavior, also easier to add states to support additional behavior&lt;/li&gt;
  &lt;li&gt;Improves cohesion: state-specific behaviors are aggregated into the &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt; classes, which are placed in one location in the code&lt;/li&gt;
  &lt;li&gt;Improves the flexibility to extend the behavior of the application and overall improves code maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;disadvantages-3&quot;&gt;Disadvantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Class explosion: every state needs to be defined with the help of &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt; -&amp;gt; might end up writing many more classes with a small functionality&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Context&lt;/code&gt; class needs to be updated to deal with each behavior&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch11-antipatterns&quot;&gt;Ch11. AntiPatterns&lt;/h1&gt;
&lt;p&gt;Four aspects of a bad design:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Immobile&lt;/strong&gt;: hard to reuse&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rigid&lt;/strong&gt;: any small change may in turn result in moving too many parts of the software&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fragile&lt;/strong&gt;: any change results in breaking the existing system fairly easy&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Viscose&lt;/strong&gt;: changes are done in the code or envinronment itself to avoid difficult architectural level changes&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;An AntiPattern is an outcome of a solution to recurring problems so that the outcome is innefective and becomes counterproductive&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;AntiPatterns may be the result of:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A developer not knowing the software development practices&lt;/li&gt;
  &lt;li&gt;A developer not applying design patterns in the correct context&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;software-development-antipatterns&quot;&gt;Software development AntiPatterns&lt;/h2&gt;
&lt;p&gt;Software deviates from the original code structure due to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The tought process of the developer evolves with development&lt;/li&gt;
  &lt;li&gt;Use cases change based on customer feedback&lt;/li&gt;
  &lt;li&gt;Data structures designed initially may undergo change with functionality or scalability considerations&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Refactoring is one of the critical parts of the software development journey, which provides developers an opportunity to relook the data structures and think about scalability and ever-evolving customer’s needs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;spaghetti-code&quot;&gt;Spaghetti code&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Minimum reuse of structures is possible&lt;/li&gt;
  &lt;li&gt;Maintenance efforts are too high&lt;/li&gt;
  &lt;li&gt;Extension and flexibility to change is reduced&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;golden-hammer&quot;&gt;Golden Hammer&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;One solution is obsessively applied to all software projects&lt;/li&gt;
  &lt;li&gt;The product is describe, not by the features, but the technology used in development&lt;/li&gt;
  &lt;li&gt;In the company corridors, you hear developers talking, “That could have been better than using this”&lt;/li&gt;
  &lt;li&gt;Requirements are not completed and not in sync with user expectations&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lava-flow&quot;&gt;Lava Flow&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Low code coverage for developed tests&lt;/li&gt;
  &lt;li&gt;Commented code without reasons&lt;/li&gt;
  &lt;li&gt;Obsolete interfaces, or developers try to work around existing code&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;copy-and-paste-or-cut-and-paste-programming&quot;&gt;Copy-and-paste or cut-and-paste programming&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Similar type of issues across software application&lt;/li&gt;
  &lt;li&gt;Higher maintenance costs and increased bug life cycle&lt;/li&gt;
  &lt;li&gt;Less modular code base with the same code running into a number of lines&lt;/li&gt;
  &lt;li&gt;Inheriting issues that existed in the first place&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;software-architecture-antipatterns&quot;&gt;Software architecture AntiPatterns&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Software architecture looks at modeling the software that is well understood by the development and test teams, product managers, and other stakeholders&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;reinventing-the-wheel&quot;&gt;Reinventing the wheel&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Too many solutions to solve one standard problem, with many of them not being well thought out&lt;/li&gt;
  &lt;li&gt;More time and resource utilization for the engineering team leading overbudgeting and more time to market&lt;/li&gt;
  &lt;li&gt;A closed system architecture (useful for only one product), duplication of efforts, and poor risk management&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vendor-lock-in&quot;&gt;Vendor lock-in&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Release cycles and product maintenance cycles of a company’s product releases are directly dependent on the vendor’s release time frame&lt;/li&gt;
  &lt;li&gt;The product is developed around the technology rather than on the customer’s requirements&lt;/li&gt;
  &lt;li&gt;The product’s time to market is unreliable and doesn’t meet customer’s expectations&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;design-by-committee&quot;&gt;Design by committee&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Conflicting viewpoints between developers and architects even after the design is finalized&lt;/li&gt;
  &lt;li&gt;Overly complex design that is very difficult to document&lt;/li&gt;
  &lt;li&gt;Any change in the specification or design undergoes review by many, resulting in implementation delays&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/python_design_patterns/python_design_patterns.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/python_design_patterns/python_design_patterns.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Clean Code: A Handbook of Agile Software Craftsmanship</title><link href="https://millengustavo.github.io/blog/book/software%20engineering/2020/07/26/clean-code.html" rel="alternate" type="text/html" title="Clean Code: A Handbook of Agile Software Craftsmanship" /><published>2020-07-26T00:00:00-05:00</published><updated>2020-07-26T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/software%20engineering/2020/07/26/clean-code</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/software%20engineering/2020/07/26/clean-code.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Authors: Robert C. Martin&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch1-clean-code&quot;&gt;Ch1. Clean Code&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Most managers want good code, even when they are obsessing about the schedule (…) It’s &lt;em&gt;your&lt;/em&gt; job to defend the code with equal passion”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Clean code is &lt;em&gt;focused&lt;/em&gt;: each function, each class, each module exposes a single-minded attitude that remains entirely undistracted, and upolluted, by the surrounding details&lt;/li&gt;
  &lt;li&gt;Code, without tests, is not clean. No matter how elegant it is, no matter how readable and accessible, if it hath not tests, it be unclean&lt;/li&gt;
  &lt;li&gt;You will read it, and it will be pretty much what you expected. It will be obvious, simple, and compelling&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reading-vs-writing&quot;&gt;Reading vs. Writing&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The ratio of time spent reading vs. writing is well over 10:1&lt;/li&gt;
  &lt;li&gt;We are constantly reading old code as part of the effort to write new code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;We want the reading of code to be easy, even if it makes the writing harder&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;You cannot write code if you cannot read the surrounding code&lt;/li&gt;
  &lt;li&gt;If you want to go fast, get done quickly, if you want your code to be easy to write, make it easy to read&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-meaningful-names&quot;&gt;Ch2. Meaningful Names&lt;/h1&gt;

&lt;h2 id=&quot;use-intention-revealing-names&quot;&gt;Use intention-revealing names&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Choosing good names takes time, but saves more than it takes. Take care with your names and change them when you find better ones&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;avoid-disinformation&quot;&gt;Avoid disinformation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Avoid leaving false clues that obscure the meaning of code&lt;/li&gt;
  &lt;li&gt;Avoid words whose entrenched meanings vary from our intended meaning&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;make-meaningful-distinctions&quot;&gt;Make meaningful distinctions&lt;/h2&gt;
&lt;p&gt;If names must be different, then they should also mean something different&lt;/p&gt;

&lt;h2 id=&quot;use-pronounceable-names&quot;&gt;Use pronounceable names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Humans are good at words&lt;/li&gt;
  &lt;li&gt;Words are, by definition, pronounceable&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-searchable-names&quot;&gt;Use searchable names&lt;/h2&gt;
&lt;p&gt;Single-letter names and numeric constants have a particular problem in that they are not easy to locate across a body of text&lt;/p&gt;

&lt;h2 id=&quot;avoid-encodings&quot;&gt;Avoid encodings&lt;/h2&gt;
&lt;p&gt;Encoding type or scope information into names simply adds an extra burden of deciphering&lt;/p&gt;

&lt;h2 id=&quot;avoid-mental-mapping&quot;&gt;Avoid mental mapping&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Clarity is king&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;class-names&quot;&gt;Class names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Classes and objects should have noun or noun phrase names&lt;/li&gt;
  &lt;li&gt;A class name should not be a verb&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;method-names&quot;&gt;Method names&lt;/h2&gt;
&lt;p&gt;Methods should have verb or verb phrase names&lt;/p&gt;

&lt;h2 id=&quot;dont-be-cute&quot;&gt;Don’t be cute&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Choose clarity over entertainment value&lt;/li&gt;
  &lt;li&gt;Say what you mean. Mean what you say&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pick-one-word-per-concept&quot;&gt;Pick one word per concept&lt;/h2&gt;
&lt;p&gt;A consistent lexicon is a great boon to the programmers who must use your code&lt;/p&gt;

&lt;h2 id=&quot;dont-pun&quot;&gt;Don’t pun&lt;/h2&gt;
&lt;p&gt;Avoid using the same word for two purposes -&amp;gt; essentially a pun&lt;/p&gt;

&lt;h2 id=&quot;use-solution-domain-names&quot;&gt;Use solution domain names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;People who read your code will be programmers&lt;/li&gt;
  &lt;li&gt;Use CS terms, algorithm names, pattern names, math terms&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-problem-domain-names&quot;&gt;Use problem domain names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Separate solution and problem domain concepts&lt;/li&gt;
  &lt;li&gt;Code that has more to do with problem domain concepts should have names drawn from the problem domain&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;add-meaningful-context&quot;&gt;Add meaningful context&lt;/h2&gt;
&lt;p&gt;Most names are not meaningful in and of themselves&lt;/p&gt;

&lt;h2 id=&quot;dont-add-gratuitous-context&quot;&gt;Don’t add gratuitous context&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Shorter names are generally better than long ones, so long as they are clear&lt;/li&gt;
  &lt;li&gt;Add no more context to a name than is necessary&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Choosing good names requires good descriptive skills and a shared cultural background. This is a teaching issue rather than a technical, business, or management issue&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch3-functions&quot;&gt;Ch3. Functions&lt;/h1&gt;
&lt;h2 id=&quot;small&quot;&gt;Small&lt;/h2&gt;
&lt;p&gt;Functions should be small&lt;/p&gt;

&lt;h3 id=&quot;blocks-and-indenting&quot;&gt;Blocks and Indenting&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Blocks within &lt;code class=&quot;highlighter-rouge&quot;&gt;if&lt;/code&gt; statements, &lt;code class=&quot;highlighter-rouge&quot;&gt;else&lt;/code&gt; statements, &lt;code class=&quot;highlighter-rouge&quot;&gt;while&lt;/code&gt; statements should be on line long -&amp;gt; probably a function call&lt;/li&gt;
  &lt;li&gt;Keep the enclosing function small, adds documentary value&lt;/li&gt;
  &lt;li&gt;Functions should not be large enough to hold nested structures -&amp;gt; makes easier to read and understand&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;do-one-thing&quot;&gt;Do one thing&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Functions should do one thing. They should do it well. They should do it only&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Reasons to write functions: decompose a larger concept (the name of the function) into a set of steps at the next level of abstraction&lt;/li&gt;
  &lt;li&gt;Functions that do one thing cannot be divided into sections&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;one-level-of-abstraction-per-function&quot;&gt;One level of abstraction per function&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Once details are mixed with essential concepts, more details tend to accrete within the function&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-stepdown-rule&quot;&gt;The Stepdown rule&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;We want code to be read like a top-down narrative&lt;/li&gt;
  &lt;li&gt;A set of TO paragraphs, each describing the current level of abstraction and referencing subsequent TO paragraphs at the next level down&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-descriptive-names&quot;&gt;Use descriptive names&lt;/h2&gt;
&lt;p&gt;Ward’s principle: &lt;em&gt;“You know you are working on clean code when each routine turns out to be pretty much what you expected”&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spend time choosing a name&lt;/li&gt;
  &lt;li&gt;You should try several different names and read the code with each in place&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;function-arguments&quot;&gt;Function arguments&lt;/h2&gt;
&lt;p&gt;Ideal number of arguments for a function:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;zero (niladic)&lt;/li&gt;
  &lt;li&gt;one (monadic)&lt;/li&gt;
  &lt;li&gt;two (dyadic)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;more than that should be avoided where possible&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Arguments are hard from a testing point of view&lt;/strong&gt; -&amp;gt; test cases for all combinations of arguments&lt;/li&gt;
  &lt;li&gt;Output arguments are harder to understand than input arguments&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Passing a boolean into a function (flag arguments) is a terrible practice&lt;/strong&gt; -&amp;gt; loudly proclaiming that this function does more than one thing -&amp;gt; does one thing if the flag is true and another if the flag is false!&lt;/li&gt;
  &lt;li&gt;When a function seems to need more than two or three arguments, it is likely that some of those arguments ought to be wrapped into a class of their own -&amp;gt; When groups of variables are passed together, they are likely part of a concept that deserves a name of its own&lt;/li&gt;
  &lt;li&gt;Side effects are lies -&amp;gt; your functions promises to do one thing, but it also does other &lt;em&gt;hidden&lt;/em&gt; things&lt;/li&gt;
  &lt;li&gt;Either your function should change the state of an object, or it should return some information about the object&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Prefer Exceptions to returing error codes&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Extract try/catch blocks into functions of their own&lt;/li&gt;
  &lt;li&gt;Functions should do one thing -&amp;gt; error handling is one thing&lt;/li&gt;
  &lt;li&gt;Don’t repeat yourself -&amp;gt; duplication may be the root of all evil in software&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-do-you-write-functions-like-this&quot;&gt;How do you write functions like this?&lt;/h2&gt;
&lt;p&gt;Writing software is like any other kind of writing&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Get your thoughts down first&lt;/li&gt;
  &lt;li&gt;Massage it until it reads well&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first draft might be clumsy and disorganized, so you restructure it and refine it until it reads the way you want it to read&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Every system is built from a domain-specific language designed by the programmers to describe the system. Functions are the verbs of that language, and classes are the nouns.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch4-comments&quot;&gt;Ch4. Comments&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Comments are always failures. We must have them because we cannot always figure out how to express ourselves without them, but their use is not a cause for celebration&lt;/li&gt;
  &lt;li&gt;Comments lie. Not always, and not intentionally, but too often&lt;/li&gt;
  &lt;li&gt;The older a comment is, and the farther away it is from the code it describes, the more likely it is to be wrong&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Truth can only be found in the code&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Explain your intent in code: &lt;strong&gt;create a function that says the same thing as the comment you want to write&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;A comment may be used to amplify the importance of something that may otherwise seem inconsequential&lt;/li&gt;
  &lt;li&gt;We have good source code control systems now. Those systems will remember the code for us. We don’t have to comment it out any more. Just delete the code&lt;/li&gt;
  &lt;li&gt;Short functions don’t need much description -&amp;gt; well-chosen name for a small function that does one thing is better than a comment header&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch5-formatting&quot;&gt;Ch5. Formatting&lt;/h1&gt;
&lt;p&gt;Code formatting&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Too important to ignore&lt;/li&gt;
  &lt;li&gt;Is about communication -&amp;gt; developer’s first order of business&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Small files are easier to understand than large files are&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-newspaper-metaphor&quot;&gt;The newspaper metaphor&lt;/h2&gt;
&lt;p&gt;Source file should be like a newspaper article&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Name should be simple but explanatory&lt;/li&gt;
  &lt;li&gt;The name, by itself, should be sufficient to tell us whether we are in the right module or not&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vertical-formatting&quot;&gt;Vertical formatting&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Avoid forcing the reader to hop around through the source files and classes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dependent functions&lt;/strong&gt;: if one function calls another, they should be vertically close, and the caller should be above the callee&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;horizontal-formatting&quot;&gt;Horizontal formatting&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Strive to keep your lines short&lt;/li&gt;
  &lt;li&gt;Beyond 100~120 isn’t advisable&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-objects-and-data-structures&quot;&gt;Ch6. Objects and Data Structures&lt;/h1&gt;

&lt;h2 id=&quot;dataobject-anti-symmetry&quot;&gt;Data/Object anti-symmetry&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Objects hide their data behind abstractions and expose functions that operate on that data. Data structure expose their data and have no meaningful functions&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Procedural code (code using data structures) makes it easy to add new functions without changing the existing data structures. OO code makes it easy to add new classes without changing existing functions&lt;/li&gt;
  &lt;li&gt;Procedural code makes it hard to add new data structures because all the functions must change. OO code makes it hard to add new functions because all the classes must change&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mature programmers know that the idea that &lt;em&gt;everything is an object is a myth&lt;/em&gt;. Sometimes you really do want simple data structures with procedures operating on them&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;data-transfer-objects-dto&quot;&gt;Data transfer objects (DTO)&lt;/h2&gt;
&lt;p&gt;DTO: quintessential form of a data structure -&amp;gt; a class with public variables and no functions&lt;/p&gt;

&lt;h3 id=&quot;active-records&quot;&gt;Active records&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Special forms of DTOs&lt;/li&gt;
  &lt;li&gt;Data structures with public (or bean-accessed) variables; but they typically have navigational methods like &lt;code class=&quot;highlighter-rouge&quot;&gt;save&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;find&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;objects&quot;&gt;Objects&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;expose behavior and hide data&lt;/li&gt;
  &lt;li&gt;easy to add new kinds of objects without changing existing behaviors&lt;/li&gt;
  &lt;li&gt;hard to add new behaviors to existing objects&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-structures&quot;&gt;Data Structures&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;expose data and have no significant behavior&lt;/li&gt;
  &lt;li&gt;easy to add new behaviors to existing data structures&lt;/li&gt;
  &lt;li&gt;hard to add new data structures to existing functions&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch7-error-handling&quot;&gt;Ch7. Error Handling&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Things can go wrong, and when they do, we as programmers are responsible for making sure that our code what it needs to do&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Error handling is important, but if it obscures logic, it’s wrong&lt;/li&gt;
  &lt;li&gt;It is better to throw an exception when you encounter an error. The calling code is cleaner. Its logic is not obscured by error handling&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;write-your-try-catch-finally-statement-first&quot;&gt;Write your &lt;code class=&quot;highlighter-rouge&quot;&gt;Try-Catch-Finally&lt;/code&gt; statement first&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;try&lt;/code&gt; blocks are like transactions&lt;/li&gt;
  &lt;li&gt;Your &lt;code class=&quot;highlighter-rouge&quot;&gt;catch&lt;/code&gt; has to leave your program in a consistent state, no matter what happens in the &lt;code class=&quot;highlighter-rouge&quot;&gt;try&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Try to write tests to force exceptions, and then add behavior to your handler to satisfy your tests -&amp;gt; cause you to build the transaction scope of the &lt;code class=&quot;highlighter-rouge&quot;&gt;try&lt;/code&gt; block first and help maintain the transaction nature of that scope&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;provide-context-with-exceptions&quot;&gt;Provide context with exceptions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Create informative error messages and pass them along with your exceptions&lt;/li&gt;
  &lt;li&gt;Mention the operation that failed and the type of failure&lt;/li&gt;
  &lt;li&gt;If you are logging in your application, pass along enough information to be able to log the error in your &lt;code class=&quot;highlighter-rouge&quot;&gt;catch&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Wrapping third-party APIs is a best practice -&amp;gt; minimize your dependencies upon it: you can choose to move to a different library in the future without much penalty; makes it easier to mock out third-party calls when you are testing your own code&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;define-the-normal-flow&quot;&gt;Define the normal flow&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Special case pattern&lt;/strong&gt;: you create a class or configure an object so that it handles a special case for you -&amp;gt; the client code doesn’t have to deal with exceptional behavior&lt;/p&gt;

&lt;h1 id=&quot;ch8-boundaries&quot;&gt;Ch8. Boundaries&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;It’s not our job to test the third-party code, but it may be in our best interest to write tests for the third-party code we use&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Learning tests&lt;/strong&gt;: call the third-party API, as we expect to use it in our application -&amp;gt; controlled experiments that check our understanding of that API&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clean Boundaries&lt;/strong&gt;: code at the boundaries needs clear separation and tests that define expectations&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Avoid letting too much of our code know about the third-party particulars. It’s betters to depend on something you control than on something you don’t control, lest it end up controlling you&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch9-unit-tests&quot;&gt;Ch9. Unit Tests&lt;/h1&gt;
&lt;h2 id=&quot;the-three-laws-of-tdd&quot;&gt;The three laws of TDD&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;First Law&lt;/strong&gt;: You may not write production code until you have written a failing unit test&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second Law&lt;/strong&gt;: You may not write more of a unit test than is sufficient to fail, and not compiling is failing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Third Law&lt;/strong&gt;: You may not write more production code than is sufficient to pass the current failing test&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;keeping-tests-clean&quot;&gt;Keeping tests clean&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Having dirty tests is equivalent to, if not worse than, having no tests&lt;/li&gt;
  &lt;li&gt;Tests must change as the production code evolves -&amp;gt; the dirtier the tests, the harder they are to change&lt;/li&gt;
  &lt;li&gt;If your tests are dirty, you begin to lose the ability to improve the structure of that code
    &lt;blockquote&gt;
      &lt;p&gt;Test code is just as important as production code. It requires thought, design, and care. It must be kept as clean as production code&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;clean-tests&quot;&gt;Clean tests&lt;/h2&gt;
&lt;p&gt;Readability is perhaps even more important in unit tests than it is in production code&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Clarity&lt;/li&gt;
  &lt;li&gt;Simplicity&lt;/li&gt;
  &lt;li&gt;Density of expression (say a lot with as few expressions as possible)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;BUILD-OPERATE-CHECK&lt;/strong&gt; pattern:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;First part builds up the test data&lt;/li&gt;
  &lt;li&gt;Second part operates on that test data&lt;/li&gt;
  &lt;li&gt;Third part checks that the operation yielded the expected results&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Domain-Specific Testing Language&lt;/strong&gt;: testing language (specialized API used by the tests) -&amp;gt; make tests expressive and succint -&amp;gt; make the tests more convenient to write and easier to read&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;given-when-then&lt;/strong&gt; convention: makes the tests even easier to read&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TEMPLATE METHOD&lt;/strong&gt; pattern -&amp;gt; putting the given/when parts in the base classs, and the then parts in different derivatives&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The number of asserts in a test ought to be minimized&lt;/li&gt;
  &lt;li&gt;We want to test a single concept in each test function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;first&quot;&gt;F.I.R.S.T.&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: when tests run slow, you won’t want to run them frequently&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Independent&lt;/strong&gt;: you should be able to run each test independently and run the tests in any order you like&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Repeatable&lt;/strong&gt;: if your tests aren’t repeatable in any environment, then you’ll always have an excuse for why they fail&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Self-Validating&lt;/strong&gt;: you should not have to read through a log file to tell whether the tests pass (should have a boolean output -&amp;gt; pass/fail)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Timely&lt;/strong&gt;: unit tests should be written just before the production code that makes them pass&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-classes&quot;&gt;Ch10. Classes&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Smaller is the primary rule when it comes to designing classes&lt;/li&gt;
  &lt;li&gt;Name of the class = describe what responsibilities it fulfills&lt;/li&gt;
  &lt;li&gt;If we cannot derive a concise name for a class, then it’s likely too large -&amp;gt; the more ambiguous the class name, the more likely it has too many responsibilities&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-single-responsibility-principle&quot;&gt;The Single Responsibility Principle&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SRP&lt;/strong&gt; is one of the more important concepts in OO design&lt;/li&gt;
  &lt;li&gt;States that a class or module should have one and only one, &lt;em&gt;reason to change&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Definition of responsibility&lt;/li&gt;
  &lt;li&gt;Guidelines for class size&lt;/li&gt;
  &lt;li&gt;A system with many small classes has no more moving parts than a system with a few large classes&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Trying to identify responsibilities (reasons to change) often helps us recognize and create better abstractions in our code&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;cohesion&quot;&gt;Cohesion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Classes should have a small number of instance variables&lt;/li&gt;
  &lt;li&gt;Each of the methods of a class should manipulate one or more of those variables&lt;/li&gt;
  &lt;li&gt;A class in which each variable is used by each method is &lt;strong&gt;maximally cohesive&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Maintaining cohesion results in many small classes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;organizing-for-change&quot;&gt;Organizing for change&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Change is continual&lt;/li&gt;
  &lt;li&gt;Every change -&amp;gt; risk that the remainder of the system no longer works as intended&lt;/li&gt;
  &lt;li&gt;Clean system -&amp;gt; organize our classes to reduce the risk of change&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Open-Closed Principle (OCP)&lt;/strong&gt;: another key OO class design principle -&amp;gt; Classes should be open for extension but closed for modification&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Ideal system -&amp;gt; we incorporate new features by extending the system, not by making modifications to existing code&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Dependency Inversion Principle (DIP)&lt;/strong&gt; -&amp;gt; classes should depend upon abstractions, not on concrete details&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch11-systems&quot;&gt;Ch11. Systems&lt;/h1&gt;
&lt;h2 id=&quot;separate-constructing-a-system-from-using-it&quot;&gt;Separate constructing a system from using it&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Software systems should separate the startup process, when the application objects are constructed and the dependencies are “wired” together, from the runtime logic that takes over after startup&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Startup process: &lt;em&gt;concern&lt;/em&gt; that any application must address&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Separation of concerns&lt;/em&gt;: one of the most important design techniques&lt;/li&gt;
  &lt;li&gt;Never let little, convenient idioms lead to modularity breakdown&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;separation-of-main&quot;&gt;Separation of main&lt;/h2&gt;
&lt;h3 id=&quot;factories&quot;&gt;Factories&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ABSTRACT FACTORY&lt;/strong&gt;: pattern -&amp;gt; give the application control of &lt;em&gt;when&lt;/em&gt; to build the object, but keep the details of that construction separate from the application code&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dependency-injection-di&quot;&gt;Dependency injection (DI)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Powerful mechanism for separating construction from use&lt;/li&gt;
  &lt;li&gt;Application of &lt;em&gt;Inversion of Control&lt;/em&gt; (IoC) to dependency management&lt;/li&gt;
  &lt;li&gt;Moves secondary responsibilities from an object to other objects that are dedicated to the purpose (supporting SRP)&lt;/li&gt;
  &lt;li&gt;The invoking object doesn’t control what kind of object is actually returned, but the invoking object still actively resolves the dependency
    &lt;blockquote&gt;
      &lt;p&gt;An object should not take responsibility for instantiating dependencies itself. Instead, it should pass this responsibility to another “authoritative” mechanism (inverting control). Setup is a global concern, this authoritative mechanism will be either the “main” routine or a special-purpose container&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scaling-up&quot;&gt;Scaling up&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Myth&lt;/strong&gt;: we can get systems “right the first time”&lt;/li&gt;
  &lt;li&gt;Implement only today’s stories -&amp;gt; then refactor and expand the system to implement new stories tomorrow = essence of iterative and incremental agility&lt;/li&gt;
  &lt;li&gt;TDD, refactoring, and the clean code they produce make this work at the code level&lt;/li&gt;
  &lt;li&gt;Software systems are unique compared to physical systems. Their archiectures can grow incrementally, &lt;strong&gt;if we maintain the proper separation of concerns&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;test-drive-the-system-architecture&quot;&gt;Test drive the system architecture&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Big Design Up Front (BDUF)&lt;/strong&gt;: harmful because it inhibits adapting to change, due to psychological resistance to discarding prior effort and because of the way architecture choices influence subsequent thinking about the design&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;optimize-decision-making&quot;&gt;Optimize decision making&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Modularity and separation of concerns make decentralized management and decision making possible&lt;/li&gt;
  &lt;li&gt;Give responsibilities to the most qualified persons&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;It is best to postpone decisions until the last possible moment&lt;/strong&gt; -&amp;gt; lets us make informed choices with the best possible information. A premature decision is a decision made with suboptimal knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Whether you are designing systems or individual modules, never forget to use &lt;strong&gt;the simplest thing that can possibly work&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch12-emergence&quot;&gt;Ch12. Emergence&lt;/h1&gt;
&lt;p&gt;A design is “simple”, if it follows these rules:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Run all the tests&lt;/li&gt;
  &lt;li&gt;Contains no duplication&lt;/li&gt;
  &lt;li&gt;Expresses the intent of the programmer&lt;/li&gt;
  &lt;li&gt;Minimizes the number of classes and methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;simple-design-rule-1-runs-all-the-tests&quot;&gt;Simple design rule 1: runs all the tests&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Systems that aren’t testable aren’t verifiable&lt;/li&gt;
  &lt;li&gt;A system that cannot be verified should never be deployed&lt;/li&gt;
  &lt;li&gt;Tight coupling makes it difficult to write tests&lt;/li&gt;
  &lt;li&gt;The more tests we write, the more we use principles like DIP and tools like dependency injection, interfaces, and abstraction to minimize coupling -&amp;gt; our designs improve even more&lt;/li&gt;
  &lt;li&gt;Primary OO goals -&amp;gt; low coupling and high cohesion&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;simple-design-rule-2-4-refactoring&quot;&gt;Simple design rule 2-4: refactoring&lt;/h2&gt;
&lt;p&gt;For each few lines of code we add, we pause and reflect on the new design&lt;/p&gt;

&lt;h3 id=&quot;no-duplication&quot;&gt;No duplication&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Duplication is the primary enemy of a well-designed system&lt;/li&gt;
  &lt;li&gt;It represents additional work, additional risk, and additional unnecessary complexity&lt;/li&gt;
  &lt;li&gt;TEMPLATE METHOD pattern: common technique for removing higher-level duplication&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;expressive&quot;&gt;Expressive&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;It’s easy to write code that &lt;em&gt;we&lt;/em&gt; understand, because at the time we write it we’re deep in an understanding of the problem we’re trying to solve. Other maintainers of the code aren’t going to have so deep an understanding&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Choose good names&lt;/li&gt;
  &lt;li&gt;Keep your functions and classes small&lt;/li&gt;
  &lt;li&gt;Use standard nomenclature&lt;/li&gt;
  &lt;li&gt;Tests primary goal = act as documentation by example&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The most important way to be expressive is to try. Care is a precious resource&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;minimal-classes-and-methods&quot;&gt;Minimal classes and methods&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Effort to make our classes and methods small -&amp;gt; we might create too many tiny classes and methods -&amp;gt; &lt;strong&gt;also keep our function and class counts low!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Although it’s important to keep class and function count low, it’s more important to have tests, eliminate duplication, and express yourself&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch13-concurrency&quot;&gt;Ch13. Concurrency&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Objects are abstractions of processing. Threads are abstractions of schedule - James O. Coplien&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;why-concurrency&quot;&gt;Why concurrency?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Concurrency is a decoupling strategy&lt;/li&gt;
  &lt;li&gt;Helps us decouple &lt;strong&gt;what&lt;/strong&gt; gets done from &lt;strong&gt;when&lt;/strong&gt; it gets done&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;myths-and-misconceptions&quot;&gt;Myths and misconceptions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Concurrency can &lt;em&gt;sometimes&lt;/em&gt; improve performance, but only when there is a lot of wait time that can be shared between multiple threads or multiple processors&lt;/li&gt;
  &lt;li&gt;The design of a concurrent algorithm can be remarkably different from the design of a single-threaded system&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Concurrency bugs aren’t usually repeatable&lt;/strong&gt;, so they are often ignored as one-offs instead of the true defects they are&lt;/li&gt;
  &lt;li&gt;Concurrency often requires a fundamental change in design strategy&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;concurrency-defense-principles&quot;&gt;Concurrency defense principles&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Single responsibility principle&lt;/strong&gt;: keep your concurrency-related code separate from other code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Limit the scope of data&lt;/strong&gt;: data encapsulation; severely limit the access of any data that may be shared&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use copies of data&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Threads should be as independent as possible&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;know-your-execution-models&quot;&gt;Know your execution models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Producer-Consumer&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Readers-Writers&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dining Philosophers&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;others&quot;&gt;Others&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Keep synchronized sections small&lt;/li&gt;
  &lt;li&gt;Think about shut-down early and get it working early&lt;/li&gt;
  &lt;li&gt;Write tests that have the potential to expose problems and then run them frequently, with different programatic configurations and system configurations and load&lt;/li&gt;
  &lt;li&gt;Do not ignore system failures as one-offs&lt;/li&gt;
  &lt;li&gt;Do not try to chase down nonthreading bugs and threading bugs at the same time. Make sure your code works outside of threads&lt;/li&gt;
  &lt;li&gt;Make your thread-based code especially pluggable so that you can run it in various configurations&lt;/li&gt;
  &lt;li&gt;Run your threaded code on all target platforms early and often&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Code that is simple to follow can become nightmarish when multiple threads and shared data get into the mix -&amp;gt; you need to write clean code with rigor or else face subtle and infrequent failures&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/clean_code/clean_code.jpeg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/clean_code/clean_code.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Mastering Large Datasets with Python: Parallelize and Distribute Your Python Code</title><link href="https://millengustavo.github.io/blog/book/software%20engineering/python/big%20data/2020/06/23/master-large-data-python.html" rel="alternate" type="text/html" title="Mastering Large Datasets with Python: Parallelize and Distribute Your Python Code" /><published>2020-06-23T00:00:00-05:00</published><updated>2020-06-23T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/software%20engineering/python/big%20data/2020/06/23/master-large-data-python</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/software%20engineering/python/big%20data/2020/06/23/master-large-data-python.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Authors: John T. Wolohan&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.manning.com/books/mastering-large-datasets-with-python&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch1-introduction&quot;&gt;Ch1. Introduction&lt;/h1&gt;
&lt;p&gt;Map and reduce style of programming:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;easily write parallel programs&lt;/li&gt;
  &lt;li&gt;organize the code around two functions: &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;MapReduce&lt;/code&gt; = framework for parallel and distributed computing; &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; = style of programming that allows running the work in parallel with minimal rewriting and extend the work to distributed workflows&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Dask&lt;/strong&gt; -&amp;gt; another tool for managing large data without &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;procedural-programming&quot;&gt;Procedural programming&lt;/h2&gt;
&lt;p&gt;Program Workflow&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Starts to run&lt;/li&gt;
  &lt;li&gt;issues an instruction&lt;/li&gt;
  &lt;li&gt;instruction is executed&lt;/li&gt;
  &lt;li&gt;repeat 2 and 3&lt;/li&gt;
  &lt;li&gt;finishes running&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;parallel-programming&quot;&gt;Parallel programming&lt;/h2&gt;
&lt;p&gt;Program workflow&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Starts to run&lt;/li&gt;
  &lt;li&gt;divides up the work into chunks of instructions and data&lt;/li&gt;
  &lt;li&gt;each chunk of work is executed independently&lt;/li&gt;
  &lt;li&gt;chunks of work are reassembled&lt;/li&gt;
  &lt;li&gt;finishes running&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;map_reduce.png&quot; alt=&quot;map_reduce&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; style is applicable everywhere, but its specific strengths are in areas where you may need to scale&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-map-function-for-transforming-data&quot;&gt;The map function for transforming data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;: function to transform sequences of data from one type to another&lt;/li&gt;
  &lt;li&gt;Always retains the same number of objects in the output as were provided in the input&lt;/li&gt;
  &lt;li&gt;performs one-to-one transformations -&amp;gt; is a great way to transform data so it is more suitable for use&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Declarative programming: focuses on explaining the logic of the code and not on specifying low-level details -&amp;gt; scaling is natural, the logic stays the same&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-reduce-function-for-advanced-transformations&quot;&gt;The reduce function for advanced transformations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;: transform a sequence of data into a data structure of any shape or size&lt;/li&gt;
  &lt;li&gt;MapReduce programming pattern relies on the &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; function to transform some data into another type of data and then uses the &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; function to combine that data&lt;/li&gt;
  &lt;li&gt;performs one-to-any transformations -&amp;gt; is a great way to assemble data into a final result&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;distributed-computing-for-speed-and-scale&quot;&gt;Distributed computing for speed and scale&lt;/h2&gt;
&lt;p&gt;Extension of parallel computing in which the computer resource we are dedicating to work on each chunk of a given task is its own machine&lt;/p&gt;

&lt;h2 id=&quot;hadoop-a-distributed-framework-for-map-and-reduce&quot;&gt;Hadoop: A distributed framework for map and reduce&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Designed as an open source implementation of Google’s original MapReduce framework&lt;/li&gt;
  &lt;li&gt;Evolved into distributed computing software used widely by companies processing large amounts of data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spark-for-high-powered-map-reduce-and-more&quot;&gt;Spark for high-powered map, reduce, and more&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Something of a sucessor to the Apache Hadoop framework that does more of its work in memory instead of by writing to file&lt;/li&gt;
  &lt;li&gt;Can run more than 100x faster than Hadoop&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;aws-elastic-mapreduce-emr---large-datasets-in-the-cloud&quot;&gt;AWS Elastic MapReduce (EMR) - Large datasets in the cloud&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Popular way to implement Hadoop and Spark&lt;/li&gt;
  &lt;li&gt;tackle small problems with parallel programming as its cost effective&lt;/li&gt;
  &lt;li&gt;tackle large problems with parallel programming because we can procure as many resources as we need&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-accelerating-large-dataset-work-map-and-parallel-computing&quot;&gt;Ch2. Accelerating large dataset work: Map and parallel computing&lt;/h1&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;’s primary capabilities:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loops&lt;/li&gt;
  &lt;li&gt;Transform data&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; evaluates only when necessary, not when called -&amp;gt; generic &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; object as output&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; makes easy to parallel code -&amp;gt; break into pieces&lt;/p&gt;

&lt;h2 id=&quot;pattern&quot;&gt;Pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Take a sequence of data&lt;/li&gt;
  &lt;li&gt;Transform it with a function&lt;/li&gt;
  &lt;li&gt;Get the outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Generators&lt;/code&gt; instead of normal loops prevents storing all objects in memory in advance&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;lazy-functions-for-large-datasets&quot;&gt;Lazy functions for large datasets&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; = lazy function = it doesn’t evaluate when we call &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Python stores the instructions for evaluating the function and runs them at the exact moment we ask for the value&lt;/li&gt;
  &lt;li&gt;Common lazy objects in Python = &lt;code class=&quot;highlighter-rouge&quot;&gt;range&lt;/code&gt; function&lt;/li&gt;
  &lt;li&gt;Lazy &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; allows us to transform a lot of data without an unnecessarily large amount of memory or spending the time to generate it&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parallel-processing&quot;&gt;Parallel processing&lt;/h2&gt;
&lt;h3 id=&quot;problems&quot;&gt;Problems&lt;/h3&gt;
&lt;h4 id=&quot;inability-to-pickle-data-or-functions&quot;&gt;Inability to pickle data or functions&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Pickling&lt;/em&gt;: Python’s version of object serialization or mashalling&lt;/li&gt;
  &lt;li&gt;Storing objects from our code in an efficient binary format on the disk that can be read back by our program at a later time (&lt;code class=&quot;highlighter-rouge&quot;&gt;pickle&lt;/code&gt; module)&lt;/li&gt;
  &lt;li&gt;allows us to share data across procesors or even machines, saving the instructions and data and then executing them elsewhere&lt;/li&gt;
  &lt;li&gt;Objects we can’t pickle: lambda functions, nested functions, nested classes&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pathos&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;dill&lt;/code&gt; module allows us to pickle almost anything&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;order-sensitive-operations&quot;&gt;Order-sensitive operations&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Work in parallel: not guaranteed that tasks will be finished in the same order they’re input&lt;/li&gt;
  &lt;li&gt;If work needs to be processed in a linear order -&amp;gt; probably shouldn’t do it in parallel&lt;/li&gt;
  &lt;li&gt;Even though Python may not complete the problems in order, it still remembers the order in which it was supposed to do them -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; returns in the exact order we would expect, even if it doesn’t process in that order&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;state-dependent-operations&quot;&gt;State-dependent operations&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Common solution for the state problem: &lt;strong&gt;take the internal state and make it an external variable&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other-observations&quot;&gt;Other observations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Best way to flatten a list into one big list -&amp;gt; Python’s itertools &lt;code class=&quot;highlighter-rouge&quot;&gt;chain&lt;/code&gt; function: takes an iterable of iterables and chains them together so they can all be accessed one after another -&amp;gt; lazy by default&lt;/li&gt;
  &lt;li&gt;Best way to visualize graphs is to take it out of Python and import it into Gephi: dedicated piece of graph visualization software&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Anytime we’re converting a sequence of some type into a sequence of another type, what we’re doing can be expressed as a map -&amp;gt; N-to-N transformation: we’re converting N data elements, into N data elements but in different format&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;To make this type of problem parallel only adds up to few lines of code:
    &lt;ul&gt;
      &lt;li&gt;one import&lt;/li&gt;
      &lt;li&gt;wrangling our processors with &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;modifying our &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; statements to use &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool.map&lt;/code&gt; method&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch3-function-pipelines-for-mapping-complex-transformations&quot;&gt;Ch3. Function pipelines for mapping complex transformations&lt;/h1&gt;

&lt;h2 id=&quot;helper-functions-and-function-chains&quot;&gt;Helper functions and function chains&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Helper functions&lt;/strong&gt;: small, simple functions that we rely on to do complex things -&amp;gt; break down large problems into small pieces that we can code quickly&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Function chains&lt;/strong&gt; or &lt;strong&gt;pipelines&lt;/strong&gt;: the way we put helper functions to work&lt;/p&gt;

&lt;h3 id=&quot;creating-a-pipeline&quot;&gt;Creating a pipeline&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Chaining helper functions together&lt;/li&gt;
  &lt;li&gt;Ways to do this:
    &lt;ul&gt;
      &lt;li&gt;Using a sequence of maps&lt;/li&gt;
      &lt;li&gt;Chaining functions together with &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Creating a function pipeline with &lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; are functions in the &lt;code class=&quot;highlighter-rouge&quot;&gt;toolz&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;compose&quot;&gt;Compose&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from toolz.functoolz import compose
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Pass &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; all the functions we want to include in our pipeline&lt;/li&gt;
  &lt;li&gt;Pass in &lt;strong&gt;reverse order&lt;/strong&gt; because &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; is going to apply them backwards&lt;/li&gt;
  &lt;li&gt;Store the output of our &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; function, which is itself a function, to a variable&lt;/li&gt;
  &lt;li&gt;Call that variable or pass it along to &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;pipe&quot;&gt;Pipe&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from toolz.functoolz import pipe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; function will pass a value through a pipeline&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; expects the functions to be in the order we want to apply them&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; evaluates each of the functions and returns a results&lt;/li&gt;
  &lt;li&gt;If we want to pass it to &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;, we have to wrap it in a function definition&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Major advantages of creating pipelines of helper functions are that the code becomes: &lt;strong&gt;Readable and clear; Modular and easy to edit&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Modular code play very nice with &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and can readily move into parallel workflows, such as by using the &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;We can simplify working with nested data structures by using nested function pipelines, which we can apply with &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch4-processing-large-datasets-with-lazy-workflows&quot;&gt;Ch4. Processing large datasets with lazy workflows&lt;/h1&gt;
&lt;h2 id=&quot;laziness&quot;&gt;Laziness&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Lazy evaluation&lt;/em&gt;: strategy when deciding when to perform computations&lt;/li&gt;
  &lt;li&gt;Under lazy evaluation, the Python interpreter executes lazy Python code only when the program needs the results of that code&lt;/li&gt;
  &lt;li&gt;Opposite of &lt;em&gt;eager evaluation&lt;/em&gt;, where everything is evaluated when it’s called&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;shrinking-sequences-with-the-filter-function&quot;&gt;Shrinking sequences with the filter function&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt;: function for pruning sequences.&lt;/li&gt;
  &lt;li&gt;Takes a sequence and restricts it to only the elements that meet a given condition&lt;/li&gt;
  &lt;li&gt;Related functions to know
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.filterfalse&lt;/code&gt;: get all the results that make a qualifier function return &lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.dicttoolz.keyfilter&lt;/code&gt;: filter on the keys of a &lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.dicttoolz.valfilter&lt;/code&gt;: filter on the values of a &lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.dicttoolz.itemfilter&lt;/code&gt;: filter on both the keys and the values of a dict&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;combining-sequences-with-zip&quot;&gt;Combining sequences with zip&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt;: function for merging sequences.&lt;/li&gt;
  &lt;li&gt;Takes two sequences and returns a single sequence of &lt;code class=&quot;highlighter-rouge&quot;&gt;tuples&lt;/code&gt;, each of which contains an element from each of the original sequences&lt;/li&gt;
  &lt;li&gt;Behaves like a zipper, it interlocks the values of Python iterables&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lazy-file-searching-with-iglob&quot;&gt;Lazy file searching with iglob&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;iglob&lt;/code&gt;: function for lazily reading from the filesystem.&lt;/li&gt;
  &lt;li&gt;Lazy way of querying our filesystem&lt;/li&gt;
  &lt;li&gt;Find a sequence of files on our filesystem that match a given pattern&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from glob import iglob
posts = iglob(&quot;path/to/posts/2020/06/*.md&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;understanding-iterators-the-magic-behind-lazy-python&quot;&gt;Understanding iterators: the magic behind lazy Python&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Replace data with instructions about where to find data and replace transformations with instructions for how to execute those transformations.&lt;/li&gt;
  &lt;li&gt;The computer only has to concern itself with the data it is processing right now, as opposed to the data it just processed or has to process in the future&lt;/li&gt;
  &lt;li&gt;Iterators are the base class of all the Python data types that can be iterated over&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The iteration process is defined by a special method called &lt;code class=&quot;highlighter-rouge&quot;&gt;.__iter__()&lt;/code&gt;. If a class has this method and returns an object with a &lt;code class=&quot;highlighter-rouge&quot;&gt;.__next__()&lt;/code&gt; method, then we can iterate over it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;One-way streets: once we call &lt;code class=&quot;highlighter-rouge&quot;&gt;next&lt;/code&gt;, the item returned is removed from the sequence. We can never back up or retrieve that item again&lt;/li&gt;
  &lt;li&gt;Not meant for by-hand inspection -&amp;gt; meant for processing big data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generators-functions-for-creating-data&quot;&gt;Generators: functions for creating data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Class of functions in Python that lazily produce values in a sequence&lt;/li&gt;
  &lt;li&gt;We can create generators with functions using &lt;code class=&quot;highlighter-rouge&quot;&gt;yield&lt;/code&gt; statements or through concise and powerful list comprehension-like generator expressions&lt;/li&gt;
  &lt;li&gt;They’re a simple way of implementing an iterator&lt;/li&gt;
  &lt;li&gt;Primary advantage of generators and lazy functions: &lt;strong&gt;avoiding storing more in memory than we need to&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.islice&lt;/code&gt;: take chunks from a sequence&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lazy functions are great at processing data, but hardware still limits how quickly we can work through it&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.frequencies&lt;/code&gt;: takes a sequence in and returns a &lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt; of items that occurred in the sequence as keys with corresponding values equal to the number of times they occurred -&amp;gt; provides the frequencies of items in our sequence&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;simulations&quot;&gt;Simulations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;For simulations -&amp;gt; writing classes allow us to consolidate the data about each piece of the simulation&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.count()&lt;/code&gt;: returns a generator that produces an infinite sequence of increasing numbers&lt;/li&gt;
  &lt;li&gt;Unzipping = the opposite of zipping -&amp;gt; takes a single sequence and returns two -&amp;gt; unzip = &lt;code class=&quot;highlighter-rouge&quot;&gt;zip(*my_sequence)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;operator.methodcaller&lt;/code&gt;: takes a string and returns a function that calls that method with the name of that string on any object passed to it -&amp;gt; call class methods using functions is helpful = allows us to use functions like &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt; on them&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch5-accumulation-operations-with-reduce&quot;&gt;Ch5. Accumulation operations with reduce&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;: function for N-to-X transformations&lt;/li&gt;
  &lt;li&gt;We have a sequence and want to transform it into something that we can’t use &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; for&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; can take care of the transformations in a very concise manner, whereas &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; can take care of the very final transformation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;three-parts-of-reduce&quot;&gt;Three parts of reduce&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Accumulator function&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sequence&lt;/strong&gt;: object that we can iterate through, such as lists, strings, and generators&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Initializer&lt;/strong&gt;: initial value to be passed to our accumulator (may be &lt;em&gt;optional&lt;/em&gt;) -&amp;gt; use an initalizer not when we want to change the value of our data, but when we want to change the &lt;em&gt;type&lt;/em&gt; of the data&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from functools import reduce

reduce(acc_fn, sequence, initializer)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;accumulator-functions&quot;&gt;Accumulator functions&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Does the heavy lifting for &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Special type of helper function&lt;/li&gt;
  &lt;li&gt;Common prototype:
    &lt;ul&gt;
      &lt;li&gt;take an accumulated value and the next element in the sequence&lt;/li&gt;
      &lt;li&gt;return another object, typically of the same type as the accumulated value&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;accumulator functions always needs to return a value&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Accumulator functions take two variables: one for the accumulated data (often designated as acc, left, or a), and one for the next element in the sequence (designated nxt, right, or b).&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def my_add(acc, nxt):
    return acc + nxt

# or, using lambda functions
lambda acc, nxt: acc + nxt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;reductions&quot;&gt;Reductions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;frequencies&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;using-map-and-reduce-together&quot;&gt;Using map and reduce together&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;If you can decompose a problem into an N-to-X transformation, all that stands between you and a reduction that solves that problem is a well-crafted accumulation function&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Using &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; pattern to decouple the transformation logic from the actual transformation itself:
    &lt;ul&gt;
      &lt;li&gt;leads to highly reusable code&lt;/li&gt;
      &lt;li&gt;with large datasets -&amp;gt; simple functions becomes paramount -&amp;gt; we may have to wait a long time to discover we made a small error&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;speeding-up-map-and-reduce&quot;&gt;Speeding up map and reduce&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Using a parallel map can counterintuitively be slower than using a lazy map in map an reduce scenarios&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;We can always use parallelization at the &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; level instead of at the &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; level&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-speeding-up-map-and-reduce-with-advanced-parallelization&quot;&gt;Ch6. Speeding up map and reduce with advanced parallelization&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;: use parallelization in the accumulation process instead of the transformation process&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;getting-the-most-out-of-parallel-map&quot;&gt;Getting the most out of parallel map&lt;/h2&gt;
&lt;p&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; will be slower than lazy &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;we’re going to iterate through the sequence a second time later in our workflow&lt;/li&gt;
  &lt;li&gt;size of the work done in each parallel instance is small compared to the overhead that parallelization imposes -&amp;gt; &lt;em&gt;chunksize&lt;/em&gt;: size of the different pieces into which we break our tasks for parallel processing&lt;/li&gt;
  &lt;li&gt;Python makes &lt;em&gt;chunksize&lt;/em&gt; available as an option -&amp;gt; vary according to the task at hand&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;more-parallel-maps-imap-and-starmap&quot;&gt;More parallel maps: &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt;&lt;/h3&gt;
&lt;h4 id=&quot;imap&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt;: for lazy parallel mapping&lt;/li&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt; method to work in parallel on very large sequences efficiently&lt;/li&gt;
  &lt;li&gt;Lazy and parallel? use the &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap_unordered&lt;/code&gt; methods of &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool()&lt;/code&gt; -&amp;gt; both methods return iterators instead of lists&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.imap_unordered&lt;/code&gt;: behaves the same, except it doesn’t necessarily put the sequence in the right order for our iterator&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;starmap&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt; to work with complex iterables, especially those we’re likely to create using the &lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt; function -&amp;gt; more than one single parameter (map’s limitation)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt; unpacks &lt;code class=&quot;highlighter-rouge&quot;&gt;tuples&lt;/code&gt; as &lt;strong&gt;positional parameters&lt;/strong&gt; to the function with which we’re mapping&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.starmap&lt;/code&gt;: lazy function&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Pool().starmap&lt;/code&gt;: parallel function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parallel-reduce-for-faster-reductions&quot;&gt;Parallel reduce for faster reductions&lt;/h2&gt;
&lt;p&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;break a problem into chunks&lt;/li&gt;
  &lt;li&gt;make no guarantees about order&lt;/li&gt;
  &lt;li&gt;need to pickle data&lt;/li&gt;
  &lt;li&gt;be finicky about stateful objects&lt;/li&gt;
  &lt;li&gt;run slower than its linear counterpart on small datasets&lt;/li&gt;
  &lt;li&gt;run faster than its linear counterpart on big datasets&lt;/li&gt;
  &lt;li&gt;require an accumulator function, some data, and an initial value&lt;/li&gt;
  &lt;li&gt;perform N-to-X transformations&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Parallel reduce has six parameters: an accumulation function, a sequence, an initializer value, a map, a chunksize, and a combination function - three more than the standard reduce function&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; workflow:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;break our problem into pieces&lt;/li&gt;
  &lt;li&gt;do some work&lt;/li&gt;
  &lt;li&gt;combine the work&lt;/li&gt;
  &lt;li&gt;return a result&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;With parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; we trade the simplicity of always having the same combination function for the flexibility of more possible transformations&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Implementing parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Importing the proper classes and functions&lt;/li&gt;
  &lt;li&gt;Rounding up some processors&lt;/li&gt;
  &lt;li&gt;Passing our &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; function the right helper functions and variables&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Python doesn’t natively support parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;pathos&lt;/code&gt; library&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.fold&lt;/code&gt; -&amp;gt; parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; implementation&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz&lt;/code&gt; library: functional utility library that Python never came with. High-performance version of the library = &lt;code class=&quot;highlighter-rouge&quot;&gt;CyToolz&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch7-processing-truly-big-datasets-with-hadoop-and-spark&quot;&gt;Ch7. Processing truly big datasets with Hadoop and Spark&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hadoop&lt;/strong&gt;: set of tools that support distributed map and reduce style of programming through Hadoop MapReduce&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Spark&lt;/strong&gt;: analytics toolkit designed to modernize Hadoop&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;distributed-computing&quot;&gt;Distributed computing&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;share tasks and data long-term across a network of computers&lt;/li&gt;
  &lt;li&gt;offers large benefits in speed when we can parallelize our work&lt;/li&gt;
  &lt;li&gt;challenges:
    &lt;ul&gt;
      &lt;li&gt;keeping track of all our data&lt;/li&gt;
      &lt;li&gt;coordinating our work&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;If we distribute our work prematurely, we’ll end up losing performance spending too much time talking between computers and processors. A lot of performance improvements at the high-performance limits of distributed computing revolve around &lt;strong&gt;optimizing communication between machines&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;hadoop-five-modules&quot;&gt;Hadoop five modules&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;MapReduce&lt;/em&gt;: way of dividing work into parallelizable chunks&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;YARN&lt;/em&gt;: scheduler and resource manager&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;HDFS&lt;/em&gt;: file system for Hadoop&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Ozone&lt;/em&gt;: Hadoop extension for object storage and semantic computing&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Common&lt;/em&gt;: set of utilities that are shared across the previous four modules&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;yarn-for-job-scheduling&quot;&gt;YARN for job scheduling&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Scheduling
    &lt;ul&gt;
      &lt;li&gt;Oversees all of the work that is being done&lt;/li&gt;
      &lt;li&gt;Acts as a final decision maker in terms of how resources should be allocated across the cluster&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Application management (&lt;em&gt;node managers&lt;/em&gt;): work at the node (single-machine) level to determine how resources should be allocated within that machine
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;federation&lt;/em&gt;: tie together resource managers in extremely high demand use cases where thousands of nodes are not sufficient&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-data-storage-backbone-of-hadoop-hdfs&quot;&gt;The data storage backbone of Hadoop: HDFS&lt;/h3&gt;
&lt;p&gt;Hadoop Distributed File System (HDFS) -&amp;gt; reliable, performant foundation for high-performance distributed computing (but with that comes complexity). Use cases:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;process big datasets&lt;/li&gt;
  &lt;li&gt;be flexible in hardware choice&lt;/li&gt;
  &lt;li&gt;be protected against hardware failure&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moving code is faster than moving data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mapreduce-jobs-using-python-and-hadoop-streaming&quot;&gt;MapReduce jobs using Python and Hadoop Streaming&lt;/h3&gt;
&lt;p&gt;Hadoop MapReduce with Python -&amp;gt; Hadoop Streaming = utility for using Hadoop MapReduce with programming languages besides Java&lt;/p&gt;

&lt;p&gt;Hadoop natively supports compression data: .gz, .bz2, and .snappy&lt;/p&gt;

&lt;h2 id=&quot;spark-for-interactive-workflows&quot;&gt;Spark for interactive workflows&lt;/h2&gt;
&lt;p&gt;Analytics-oriented data processing framework designed to take advantage of higher-RAM compute clusters. Advantages for Python programmers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;direct Python interface - &lt;code class=&quot;highlighter-rouge&quot;&gt;PySpark&lt;/code&gt;: allows for us to interactively explore big data through a PySpark shell REPL&lt;/li&gt;
  &lt;li&gt;can query SQL databases directly (Java Database Connectivity - JDBC)&lt;/li&gt;
  &lt;li&gt;has a &lt;em&gt;DataFrame&lt;/em&gt; API: rows-and-columns data structure familiar to &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt; -&amp;gt; provides a convenience layer on top of the core Spark data object: the RDD (Resilient Distributed Dataset)&lt;/li&gt;
  &lt;li&gt;Spark has two high-performance data structures: RDDs, which are excellent for any type of data, and DataFrames, which are optimized for tabular data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Favor Spark over Hadoop when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;processing streaming data&lt;/li&gt;
  &lt;li&gt;need to get the task completed nearly instantaneously&lt;/li&gt;
  &lt;li&gt;willing to pay for high-RAM compute clusters&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pyspark-for-mixing-python-and-spark&quot;&gt;PySpark for mixing Python and Spark&lt;/h3&gt;
&lt;p&gt;PySpark: we can call Spark’s Scala methods through Python just like we would a normal Python library&lt;/p&gt;

&lt;h1 id=&quot;ch8-best-practices-for-large-data-with-apache-streaming-and-mrjob&quot;&gt;Ch8. Best practices for large data with Apache Streaming and mrjob&lt;/h1&gt;
&lt;p&gt;Use Hadoop to process&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;lots of data fast: distributed parallelization&lt;/li&gt;
  &lt;li&gt;data that’s important: low data loss&lt;/li&gt;
  &lt;li&gt;enormous amounts of data: petabyte scale&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Drawbacks&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;To use Hadoop with Python -&amp;gt; Hadoop Streaming utility&lt;/li&gt;
  &lt;li&gt;Repeatedly read in string from &lt;code class=&quot;highlighter-rouge&quot;&gt;stdin&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Error messages for Java are not helpful&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;unstructured-data-logs-and-documents&quot;&gt;Unstructured data: Logs and documents&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hadoop creators designed Hadoop to work on &lt;em&gt;unstructured data&lt;/em&gt; -&amp;gt; data in the form of documents&lt;/li&gt;
  &lt;li&gt;Unstructured data is notoriously unwieldly =/= tabular data&lt;/li&gt;
  &lt;li&gt;But, is one of the most common forms of data around&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;json-for-passing-data-between-mapper-and-reducer&quot;&gt;JSON for passing data between mapper and reducer&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;JavaScript Object Notation (JSON)&lt;/li&gt;
  &lt;li&gt;Data format used for moving data in plain text between one place and another&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;json.dumps()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;json.loads()&lt;/code&gt; functions from Python’s json library to achieve the transfer&lt;/li&gt;
  &lt;li&gt;Advantages:
    &lt;ul&gt;
      &lt;li&gt;easy for humans and machines to read&lt;/li&gt;
      &lt;li&gt;provides a number of useful basic data types (string, numeric, array)&lt;/li&gt;
      &lt;li&gt;emphasis on key-value pairs that aids the loose coupling of systems&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mrjob-for-pythonic-hadoop-streaming&quot;&gt;mrjob for pythonic Hadoop streaming&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt;: Python library for Hadoop Streaming that focuses on cloud compatibility for truly scalable analysis&lt;/li&gt;
  &lt;li&gt;keeps the mapper and reducer steps but wraps them up in a single worker class named &lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt; versions of &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; share the same type signature, taking in keys and values and outputting keys and values&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt; enforces JSON data exchange between the mapper and reducer phases, so we need to ensure that our output data is JSON serializable.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch9-pagerank-with-map-and-reduce-in-pyspark&quot;&gt;Ch9. PageRank with map and reduce in PySpark&lt;/h1&gt;
&lt;p&gt;PySpark’s RDD class methods:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;-like methods: replicate the function of &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;-like methods: replicate the function of &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Convenience methods&lt;/em&gt;: solve common problems&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Partitions&lt;/strong&gt; are the abstraction that RDDs use to implement parallelization. The data in an RDD is split up across different partitions, and each partition is handled in memory. It is common in large data tasks to partition an RDD by a key&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;map-like-methods-in-pyspark&quot;&gt;Map-like methods in PySpark&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.map&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.flatMap&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.mapValues&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.flatMapValues&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;. mapPartitions&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.mapPartitionsWithIndex&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reduce-like-methods-in-pyspark&quot;&gt;Reduce-like methods in PySpark&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.reduce&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.fold&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.aggregate&lt;/code&gt; -&amp;gt; provides all the functionality of a parallel reduce. We can provide an initializer value, an aggregation function, and a combination function&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;convenience-methods-in-pyspark&quot;&gt;Convenience methods in PySpark&lt;/h3&gt;
&lt;p&gt;Many of these mirror functions in &lt;code class=&quot;highlighter-rouge&quot;&gt;functools&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;itertools&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;toolz&lt;/code&gt;. Some examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;.countByKey()&lt;/li&gt;
  &lt;li&gt;.countByValue()&lt;/li&gt;
  &lt;li&gt;.distinct()&lt;/li&gt;
  &lt;li&gt;.countApproxDistinct()&lt;/li&gt;
  &lt;li&gt;.filter()&lt;/li&gt;
  &lt;li&gt;.first()&lt;/li&gt;
  &lt;li&gt;.groupBy()&lt;/li&gt;
  &lt;li&gt;.groupByKey()&lt;/li&gt;
  &lt;li&gt;.saveAsTextFile()&lt;/li&gt;
  &lt;li&gt;.take()&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;saving-rdds-to-text-files&quot;&gt;Saving RDDs to text files&lt;/h4&gt;
&lt;p&gt;Excellent for a few reasons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The data is in a human-readable, persistent format.&lt;/li&gt;
  &lt;li&gt;We can easily read this data back into Spark with the &lt;code class=&quot;highlighter-rouge&quot;&gt;.textFile&lt;/code&gt; method of &lt;code class=&quot;highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The data is well structured for other parallel tools, such as Hadoop’s MapReduce.&lt;/li&gt;
  &lt;li&gt;We can specify a compression format for efficient data storage or transfer.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;RDD &lt;code class=&quot;highlighter-rouge&quot;&gt;.aggregate&lt;/code&gt; method—returns a dict. We need an RDD so that we can take advantage of Spark’s parallelization. To get an RDD, we’ll need to explicitly convert the items of that dict into an RDD using the &lt;code class=&quot;highlighter-rouge&quot;&gt;.parallelize&lt;/code&gt; method from our SparkContext: &lt;code class=&quot;highlighter-rouge&quot;&gt;sc&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Spark programs often use \ characters in their method chaining to increase their readability&lt;/li&gt;
  &lt;li&gt;Using the &lt;code class=&quot;highlighter-rouge&quot;&gt;byKey&lt;/code&gt; variations of methods in PySpark often results in significant speed-ups because like data is worked on by the same distributed compute worker&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-faster-decision-making-with-machine-learning-and-pyspark&quot;&gt;Ch10. Faster decision-making with machine learning and PySpark&lt;/h1&gt;
&lt;p&gt;One of the reasons why Spark is so popular = built-in machine learning capabilities&lt;/p&gt;

&lt;p&gt;PySpark’s machine learning capabilities live in a package called &lt;code class=&quot;highlighter-rouge&quot;&gt;ml&lt;/code&gt;. This package itself contains a few different modules categorizing some of the core machine learning capabilities, including&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.feature&lt;/code&gt; — For feature transformation and creation&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.classification&lt;/code&gt; — Algorithms for judging the category in which a data point belongs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.tuning&lt;/code&gt; — Algorithms for improving our machine learners&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.evaluation&lt;/code&gt; — Algorithms for evaluating machine leaners&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.util&lt;/code&gt; — Methods of saving and loading machine learners&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;PySpark’s machine learning features expect us to have our data in a PySpark &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; object - not an &lt;code class=&quot;highlighter-rouge&quot;&gt;RDD&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;RDD&lt;/code&gt; is an abstract parallelizable data structure at the core of Spark, whereas the &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; is a layer on top of the &lt;code class=&quot;highlighter-rouge&quot;&gt;RDD&lt;/code&gt; that provides a notion of rows and columns&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;organizing-the-data-for-learning&quot;&gt;Organizing the data for learning&lt;/h2&gt;
&lt;p&gt;Spark’s ml classifiers look for two columns in a &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;label&lt;/code&gt; column: indicates the correct classification of the data&lt;/li&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;features&lt;/code&gt; column: contains the features we’re going to use to predict that label&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;auxiliary-classes&quot;&gt;Auxiliary classes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;PySpark’s &lt;code class=&quot;highlighter-rouge&quot;&gt;StringIndexer&lt;/code&gt;: transforms categorical data stored as category names (using strings) and indexes the names as numerical variables. &lt;code class=&quot;highlighter-rouge&quot;&gt;StringIndexer&lt;/code&gt; indexes categories in order of frequency — from most common to least common. The most common category will be 0, the second most common category 1, and so on&lt;/li&gt;
  &lt;li&gt;Most data structures in Spark are immutable -&amp;gt; property of Scala (in which Spark is written)&lt;/li&gt;
  &lt;li&gt;Spark’s ml only want one column name &lt;code class=&quot;highlighter-rouge&quot;&gt;features&lt;/code&gt; -&amp;gt; PySpark’s &lt;code class=&quot;highlighter-rouge&quot;&gt;VectorAssembler&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;Transformer&lt;/code&gt; like &lt;code class=&quot;highlighter-rouge&quot;&gt;StringIndexer&lt;/code&gt; -&amp;gt; takes some input column names and an output column name and has methods to return a new &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; that has all the columns of the original, plus the new column we want to add&lt;/li&gt;
  &lt;li&gt;The feature creation classes are &lt;code class=&quot;highlighter-rouge&quot;&gt;Transformer&lt;/code&gt;-class objects, and their methods return new &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrames&lt;/code&gt;, rather than transforming them in place&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;PySpark’s &lt;code class=&quot;highlighter-rouge&quot;&gt;ml.evaluation&lt;/code&gt; module:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BinaryClassifierEvaluator&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RegressionEvaluator&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;MulticlassClassificationEvaluator&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cross-validation-in-pyspark&quot;&gt;Cross-validation in PySpark&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CrossValidator&lt;/code&gt; class: k-fold cross-validation, needs to be initialized with:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;An &lt;em&gt;estimator&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;parameter estimator&lt;/em&gt; - &lt;code class=&quot;highlighter-rouge&quot;&gt;ParamGridBuilder&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;An &lt;em&gt;evaluator&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch11-large-datasets-in-the-cloud-with-amazon-web-services-and-s3&quot;&gt;Ch11. Large datasets in the cloud with Amazon Web Services and S3&lt;/h1&gt;
&lt;p&gt;S3 is the go-to service for large datasets:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;effectively unlimited storage capacity&lt;/em&gt;. We never have to worry about our dataset becoming too large&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;cloud-based&lt;/em&gt;. We can scale up and down quickly as necessary.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;offers object storage&lt;/em&gt;. We can focus on organizing our data with metadata and store many different types of data.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;managed service&lt;/em&gt;. Amazon Web Services takes care of a lot of the details for us, such as ensuring data availability and durability. They also take care of security patches and software updates.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;supports versioning and life cycle policies&lt;/em&gt;. We can use them to update or archive our data as it ages&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;objects-for-convenient-heterogenous-storage&quot;&gt;Objects for convenient heterogenous storage&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Object storage: storage pattern that focuses on the &lt;strong&gt;what of the data instead of the where&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;With object storage we recognize objects by a unique identifier (instead of the name and directory)&lt;/li&gt;
  &lt;li&gt;Supports arbitrary metadata -&amp;gt; we can tag our objects flexibly based on our needs (helps us find those objects later when we need to use them)&lt;/li&gt;
  &lt;li&gt;Querying tools are available for S3 that allow SQL-like querying on these metadata tags for metadata analysis&lt;/li&gt;
  &lt;li&gt;Unique identifiers -&amp;gt; we can store heterogenous data in the same way&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parquet-a-concise-tabular-data-store&quot;&gt;Parquet: A concise tabular data store&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;CSV is a simple, tabular data store, and JSON is a human-readable document store. Both are common in data interchange and are often used in the storage of distributed large datasets. Parquet is a Hadoop- native tabular data format.&lt;/li&gt;
  &lt;li&gt;Parquet uses clever metadata to improve the performance of map and reduce operations. Running a job on Parquet can take as little as 1/100th the time a comparable job on a CSV or JSON file would take. Additionally, Parquet supports efficient compression. As a result, it can be stored at a fraction of the cost of CSV or JSON.&lt;/li&gt;
  &lt;li&gt;These benefits make Parquet an excellent option for data that primarily needs to be read by a machine, such as for batch analytics operations. JSON and CSV remain good options for smaller data or data that’s likely to need some human inspection.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Boto is a library that provides Pythonic access to many of the AWS APIs. We need the access key and secret key to programmatically access AWS through boto&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch12-mapreduce-in-the-cloud-with-amazons-elastic-mapreduce&quot;&gt;Ch12. MapReduce in the cloud with Amazon’s Elastic MapReduce&lt;/h1&gt;
&lt;h2 id=&quot;convenient-cloud-clusters-with-emr&quot;&gt;Convenient cloud clusters with EMR&lt;/h2&gt;
&lt;p&gt;Ways to get access to a compute cluster that support both Hadoop and Spark:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;AWS: Amazon’s Elastic MapReduce&lt;/li&gt;
  &lt;li&gt;Microsoft’s Azure HDInsight&lt;/li&gt;
  &lt;li&gt;Google’s Cloud Dataproc&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aws-emr&quot;&gt;AWS EMR&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;AWS EMR is a managed data cluster service&lt;/li&gt;
  &lt;li&gt;We specify general properties of the cluster, and AWS runs software that creates the cluster for us&lt;/li&gt;
  &lt;li&gt;When we’re done using the cluster, AWS absorbs the compute resources back into its network&lt;/li&gt;
  &lt;li&gt;Pricing model is a per-compute-unit per-second charge&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;There are no cost savings to doing things slowly. AWS encourages us to parallelize our problems away&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;starting-emr-clusters-with-mrjob&quot;&gt;Starting EMR clusters with mrjob&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;We can run Hadoop jobs on EMR with the &lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt; library, which allows us to write distributed MapReduce and procure cluster computing in Python.&lt;/li&gt;
  &lt;li&gt;We can use &lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt;’s configuration files to describe what we want our clusters to look like, including which instances we’d like to use, where we’d like those instances to be located, and any tags we may want to add.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hadoop on EMR is excellent for large data processing workloads, such as batch analytics or extract-transform-load (ETL)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;machine-learning-in-the-cloud-with-spark-on-emr&quot;&gt;Machine learning in the cloud with Spark on EMR&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hadoop is great for low-memory workloads and massive data.&lt;/li&gt;
  &lt;li&gt;Spark is great for jobs that are harder to break down into map and reduce steps, and situations where we can afford higher memory machines&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;running-machine-learning-algorithms-on-a-truly-large-dataset&quot;&gt;Running machine learning algorithms on a truly large dataset&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Get a sample of the full dataset.&lt;/li&gt;
  &lt;li&gt;Train and evaluate a few models on that dataset.&lt;/li&gt;
  &lt;li&gt;Select some models to evaluate on the full dataset.&lt;/li&gt;
  &lt;li&gt;Train several models on the full dataset in the cloud.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Run your Spark code with &lt;code class=&quot;highlighter-rouge&quot;&gt;spark-submit&lt;/code&gt; utility instead of Python. The &lt;code class=&quot;highlighter-rouge&quot;&gt;spark-submit&lt;/code&gt; utility queues up a Spark job, which will run in parallel locally and simulate what would happen if you ran the program on an active cluster&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;ec2-instance-types-and-clusters&quot;&gt;EC2 instance types and clusters&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;M-series&lt;/code&gt;: use for Hadoop and for testing Spark jobs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;C-series&lt;/code&gt;: compute-heavy workloads such as Spark analytics, Batch Spark jobs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;R-series&lt;/code&gt;: high-memory, use for streaming analytics&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;software-available-on-emr&quot;&gt;Software available on EMR&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;JupyterHub: cluster-ready version of Jupyter Notebook -&amp;gt; run interactive Spark and Hadoop jobs from a notebook environment&lt;/li&gt;
  &lt;li&gt;Hive: compile SQL code to Hadoop MapReduce jobs&lt;/li&gt;
  &lt;li&gt;Pig: compile &lt;em&gt;Pig-latin&lt;/em&gt; (SQL-like) commands to run Hadoop MapReduce jobs&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/master_large_data_python/master_large_data_python.png" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/master_large_data_python/master_large_data_python.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">High performance Python: Practical Performant Programming for Humans</title><link href="https://millengustavo.github.io/blog/book/python/software%20engineering/2020/06/10/high-performance-python.html" rel="alternate" type="text/html" title="High performance Python: Practical Performant Programming for Humans" /><published>2020-06-10T00:00:00-05:00</published><updated>2020-06-10T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/python/software%20engineering/2020/06/10/high-performance-python</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/python/software%20engineering/2020/06/10/high-performance-python.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Authors: Micha Gorelick, Ian Ozsvald&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Every programmer can benefit from understanding how to build performant systems (…) When something becomes ten times cheaper in time or compute costs, suddenly the set of applications you can address is wider than you imagined”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Supplemental material for the book (code examples, exercises, etc.) is available for download at https://github.com/mynameisfiber/high_performance_python_2e.&lt;/p&gt;

&lt;h1 id=&quot;ch1-understanding-performant-python&quot;&gt;Ch1. Understanding Performant Python&lt;/h1&gt;

&lt;h2 id=&quot;why-use-python&quot;&gt;Why use Python?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;highly expressive and easy to learn&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;scikit-learn&lt;/code&gt; wraps LIBLINEAR and LIBSVM (written in C)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; includes BLAS and other C and Fortran libraries&lt;/li&gt;
  &lt;li&gt;python code that properly utilizes these modules can be as fast as comparable C code&lt;/li&gt;
  &lt;li&gt;“batteries included”&lt;/li&gt;
  &lt;li&gt;enable fast prototyping of an idea&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-to-be-a-highly-performant-programmer&quot;&gt;How to be a highly performant programmer&lt;/h2&gt;
&lt;p&gt;Overall team velocity is far more important than speedups and complicated solutions. Several factors are key to this:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Good structure&lt;/li&gt;
  &lt;li&gt;Documentation&lt;/li&gt;
  &lt;li&gt;Debuggability&lt;/li&gt;
  &lt;li&gt;Shared standards&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-profiling-to-find-bottlenecks&quot;&gt;Ch2. Profiling to Find Bottlenecks&lt;/h1&gt;

&lt;p&gt;Profiling let you make the most pragmatic decisions for the least overall effort: Code run “fast enough” and “lean enough”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“If you avoid profiling and jump to optmization, you’ll quite likely do more work in the long run. Always be driven by the results of profiling”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;“Embarrassingly parallel problem”&lt;/em&gt;: no data is shared between points&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;timeit&lt;/code&gt; module temporarily disables the garbage collector&lt;/p&gt;

&lt;h2 id=&quot;cprofile-module&quot;&gt;cProfile module&lt;/h2&gt;
&lt;p&gt;Built-in profiling tool in the standard library&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;profile&lt;/code&gt;: original and slower pure Python profiler&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cProfile&lt;/code&gt;: same interface as &lt;code class=&quot;highlighter-rouge&quot;&gt;profile&lt;/code&gt; and is written in &lt;code class=&quot;highlighter-rouge&quot;&gt;C&lt;/code&gt; for a lower overhead&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Generate a &lt;em&gt;hypothesis&lt;/em&gt; about the speed of parts of your code&lt;/li&gt;
  &lt;li&gt;Measure how wrong you are&lt;/li&gt;
  &lt;li&gt;Improve your intuition about certain coding styles&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;visualizing-cprofile-output-with-snakeviz&quot;&gt;Visualizing cProfile output with Snakeviz&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;snakeviz&lt;/code&gt;: visualizer that draws the output of &lt;code class=&quot;highlighter-rouge&quot;&gt;cProfile&lt;/code&gt; as a diagram -&amp;gt; larger boxes are areas of code that take longer to run&lt;/p&gt;

&lt;h2 id=&quot;using-line_profiler-for-line-by-line-measurements&quot;&gt;Using line_profiler for line-by-line measurements&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;line_profilier&lt;/code&gt;: strongest tool for identifying the cause of CPU-bound problems in Python code: profile individual functions on a line-by-line basis&lt;/p&gt;

&lt;p&gt;Be aware of the complexity of &lt;strong&gt;Python’s dynamic machinery&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The order of evaluation for Python statements is both &lt;strong&gt;left to right and opportunistic&lt;/strong&gt;: put the cheapest test on the left side of the equation&lt;/p&gt;

&lt;h2 id=&quot;using-memory_profiler-to-diagnose-memory-usage&quot;&gt;Using memory_profiler to diagnose memory usage&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt; measures memory usage on a line-by-line basis:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Could we use less RAM by rewriting this function to work more efficiently?&lt;/li&gt;
  &lt;li&gt;Could we use more RAM and save CPU cycles by caching?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Memory profiling make your code run 10-100x slower&lt;/li&gt;
  &lt;li&gt;Install &lt;code class=&quot;highlighter-rouge&quot;&gt;psutil&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt; run faster&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt; occasionally and &lt;code class=&quot;highlighter-rouge&quot;&gt;line_profiler&lt;/code&gt; more frequently&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--pdb-mmem=XXX&lt;/code&gt; flag: &lt;code class=&quot;highlighter-rouge&quot;&gt;pdb&lt;/code&gt; debugger is activate after the process exceeds XXX MB -&amp;gt; drop you in directly at the point in your code where too many allocations are occurring&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introspecting-an-existing-process-with-pyspy&quot;&gt;Introspecting an existing process with PySpy&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;py-spy&lt;/code&gt;: sampling profiler, don’t require any code changes -&amp;gt; it introspects an already-running Python process and reports in the console with a &lt;em&gt;top-like&lt;/em&gt; display&lt;/p&gt;

&lt;h1 id=&quot;ch3-lists-and-tuples&quot;&gt;Ch3. Lists and Tuples&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lists&lt;/strong&gt;: dynamic arrays; mutable and allow for resizing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tuples&lt;/strong&gt;: static arrays; immutable and the data within them cannot be changed aftey they have been created&lt;/li&gt;
  &lt;li&gt;Tuples are cached by the Python runtime which means that we don’t need to talk to the kernel to reserve memory every time we want to use one&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Python lists have a built-in sorting algorithm that uses Tim sort -&amp;gt; O(n) in the best case and O(nlogn) in the worst case&lt;/p&gt;

&lt;p&gt;Once sorted, we can find our desired element using a binary search -&amp;gt; average case of complexity of O(logn)&lt;/p&gt;

&lt;p&gt;Dictionary lookup takes only O(1), but:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;converting the data to a dictionary takes O(n)&lt;/li&gt;
  &lt;li&gt;no repeating keys may be undesirable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bisect&lt;/code&gt; module: provide alternative functions, heavily optimized&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“&lt;strong&gt;Pick the right data structure and stick with it!&lt;/strong&gt; Although there may be more efficient data structures for particular operations, the cost of converting to those data structures may negate any efficiency boost”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Tuples are for describing multiple properties of one unchanging thing&lt;/li&gt;
  &lt;li&gt;List can be used to store collections of data about completely disparate objects&lt;/li&gt;
  &lt;li&gt;Both can take mixed types&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Generic code will be much slower than code specifically designed to solve a particular problem”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Tuple (immutable): lightweight data structure&lt;/li&gt;
  &lt;li&gt;List (mutable): extra memory needed to store them and extra computations needed when using them&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch4-dictionaries-and-sets&quot;&gt;Ch4. Dictionaries and Sets&lt;/h1&gt;
&lt;p&gt;Ideal data structures to use when your data has no intrinsic order (except for insertion order), but does have a unique object that can be used to reference it&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;key&lt;/em&gt;: reference object&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;value&lt;/em&gt;: data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sets do not actually contain values: is a collection of unique keys -&amp;gt; useful for doing set operations&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hashable&lt;/strong&gt; type: implements &lt;code class=&quot;highlighter-rouge&quot;&gt;__hash__&lt;/code&gt; and either &lt;code class=&quot;highlighter-rouge&quot;&gt;__eq__&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;__cmp__&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;complexity-and-speed&quot;&gt;Complexity and speed&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;O(1) lookups based on the arbitrary index&lt;/li&gt;
  &lt;li&gt;O(1) insertion time&lt;/li&gt;
  &lt;li&gt;Larger footprint in memory&lt;/li&gt;
  &lt;li&gt;Actual speed depends on the hashing function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-do-dictionaries-and-sets-work&quot;&gt;How do dictionaries and sets work?&lt;/h2&gt;
&lt;p&gt;Use &lt;em&gt;hash tables&lt;/em&gt; to achieve O(1) lookups and insertions -&amp;gt; clever usage of a hash function to turn an arbitrary key (i.e., a string or object) into an index for a list&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;load factor&lt;/em&gt;: how well distributed the data is throughout the hash table -&amp;gt; related to the entropy of the hash function&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hash functions must return integers&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Numerical types (&lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;float&lt;/code&gt;): hash is based on the bit value of the number they represent&lt;/li&gt;
  &lt;li&gt;Tuples and strings: hash value based on their contents&lt;/li&gt;
  &lt;li&gt;Lists: do not support hashing because their values can change&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;A custom-selected hash function should be careful to evenly distribute hash values in order to avoid collisions (will degrade the performance of a hash table) -&amp;gt; constantly “probe” the other values -&amp;gt; worst case O(n) = searching through a list&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Entropy&lt;/strong&gt;: “how well distributed my hash function is” -&amp;gt; max entropy = &lt;em&gt;ideal&lt;/em&gt; hash function = minimal number of collisions&lt;/p&gt;

&lt;h1 id=&quot;ch5-iterators-and-generators&quot;&gt;Ch5. Iterators and Generators&lt;/h1&gt;

&lt;h2 id=&quot;python-for-loop-deconstructed&quot;&gt;Python &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loop deconstructed&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# The Python loop
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;do_work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Is equivalent to
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;object_iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;object_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;StopIteration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;do_work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Changing to generators instead of precomputed arrays may require algorithmic changes (sometimes not so easy to understand)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Many of Python’s built-in functions that operate on sequences are generators themselves. &lt;code class=&quot;highlighter-rouge&quot;&gt;range&lt;/code&gt; returns a generator of values as opposed to the actual list of numbers within the specified range. Similarly, &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;reversed&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;enumerate&lt;/code&gt; all perform the calculation as needed and don’t store the full result”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Generators have less memory impact than list comprehension&lt;/li&gt;
  &lt;li&gt;Generators are really a way of organizing your code and having smarter loops&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lazy-generator-evaluation&quot;&gt;Lazy generator evaluation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Single pass&lt;/em&gt; or &lt;em&gt;online&lt;/em&gt; algorithms: at any point in our calculation with a generator, we have only the current value and cannot reference any other items in the sequence&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools&lt;/code&gt; from the standard library provides useful functions to make generators easier to use:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;islice&lt;/code&gt;: slicing a potentially infinite generator&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;chain&lt;/code&gt;: chain together multiple generators&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;takewhile&lt;/code&gt;: adds a condition that will end a generator&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cycle&lt;/code&gt;: makes a finite generator infinite by constantly repeating it&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-matrix-and-vector-computation&quot;&gt;Ch6. Matrix and Vector Computation&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Understanding the motivation behind your code and the intricacies of the algorithm will give you deeper insight about possible methods of optimization&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;memory-fragmentation&quot;&gt;Memory fragmentation&lt;/h2&gt;
&lt;p&gt;Python doesn’t natively support vectorization&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Python lists store pointers to the actual data -&amp;gt; good because it allows us to store whatever type of data inside a list, however when it comes to vector and matrix operations, this is a source of performance degradation&lt;/li&gt;
  &lt;li&gt;Python bytecode is not optimized for vectorization -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loops cannot predict when using vectorization would be benefical&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;von Neumann bottleneck&lt;/em&gt;: limited bandwidth between memory and CPU as a result of the tiered memory architecture that modern computers use&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;perf&lt;/code&gt; Linux tool: insights into how the CPU is dealing with the program being run&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; object is less suitable for math and more suitable for storing fixed-type data more efficiently in memory&lt;/p&gt;

&lt;h2 id=&quot;numpy&quot;&gt;numpy&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; has all of the features we need—it stores data in contiguous chunks of memory and supports vectorized operations on its data. As a result, any arithmetic we do on &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays happens in chunks without us having to explicitly loop over each element. Not only is it much easier to do matrix arithmetic this way, but it is also faster&lt;/p&gt;

&lt;p&gt;Vectorization from &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt;: may run fewer instructions per cycle, but each instruction does much more work&lt;/p&gt;

&lt;h2 id=&quot;numexpr-making-in-place-operations-faster-and-easier&quot;&gt;numexpr: making in-place operations faster and easier&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt;’s optimization of vector operations: occurs on only one operation at a time&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numexpr&lt;/code&gt; is a module that can take an entire vector expression and compile it into very efficient code that is optimized to minimize cache misses and temporary space used. Expressions can utilize multiple CPU cores&lt;/li&gt;
  &lt;li&gt;Easy to change code to use &lt;code class=&quot;highlighter-rouge&quot;&gt;numexpr&lt;/code&gt;: rewrite the expressions as strings with references to local variables&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lessons-from-matrix-optimizations&quot;&gt;Lessons from matrix optimizations&lt;/h2&gt;
&lt;p&gt;Always take care of any administrative things the code must do during initialization&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;allocating memory&lt;/li&gt;
  &lt;li&gt;reading a configuration from a file&lt;/li&gt;
  &lt;li&gt;precomputing values that will be needed throughout the lifetime of a program&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pandas&quot;&gt;Pandas&lt;/h2&gt;
&lt;h3 id=&quot;pandass-internal-model&quot;&gt;Pandas’s internal model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Operations on columns often generate temporary intermediate arrays which consume RAM: expect a temporary memory usage of up to 3-5x your current usage&lt;/li&gt;
  &lt;li&gt;Operations can be single-threaded and limited by Python’s global interpreter lock (GIL)&lt;/li&gt;
  &lt;li&gt;Columns of the same &lt;code class=&quot;highlighter-rouge&quot;&gt;dtype&lt;/code&gt; are grouped together by a &lt;code class=&quot;highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt; -&amp;gt; make row-wise operations on columns of the same datatype faster&lt;/li&gt;
  &lt;li&gt;Operations on data of a single common block -&amp;gt; &lt;em&gt;view&lt;/em&gt;; different &lt;code class=&quot;highlighter-rouge&quot;&gt;dtypes&lt;/code&gt; -&amp;gt; can cause a &lt;em&gt;copy&lt;/em&gt; (slower)&lt;/li&gt;
  &lt;li&gt;Pandas uses a mix of NumPy datatypes and its own extension datatypes&lt;/li&gt;
  &lt;li&gt;numpy &lt;code class=&quot;highlighter-rouge&quot;&gt;int64&lt;/code&gt; isn’t NaN aware -&amp;gt; Pandas &lt;code class=&quot;highlighter-rouge&quot;&gt;Int64&lt;/code&gt; uses two columns of data: integers and NaN bit mask&lt;/li&gt;
  &lt;li&gt;numpy &lt;code class=&quot;highlighter-rouge&quot;&gt;bool&lt;/code&gt; isn’t NaN aware -&amp;gt; Pandas &lt;code class=&quot;highlighter-rouge&quot;&gt;boolean&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;More safety makes things run slower (checking passing appropriate data) -&amp;gt; &lt;strong&gt;Developer time (and sanity) x Execution time&lt;/strong&gt;. Checks enabled: avoid painful debugging sessions, which kill developer productivity. If we know that our data is of the correct form for our chosen algorithm, these checks will add a penalty&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;building-dataframes-and-series-from-partial-results-rather-than-concatenating&quot;&gt;Building DataFrames and Series from partial results rather than concatenating&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Avoid repeated calls to &lt;code class=&quot;highlighter-rouge&quot;&gt;concat&lt;/code&gt; in Pandas (and to the equivalent &lt;code class=&quot;highlighter-rouge&quot;&gt;concatenate&lt;/code&gt; in NumPy)&lt;/li&gt;
  &lt;li&gt;Build lists of intermediate results and then construct a Series or DataFrame from this list, rather than concatenating to an existing object&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advice-for-effective-pandas-development&quot;&gt;Advice for effective pandas development&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Install the optional dependencies &lt;code class=&quot;highlighter-rouge&quot;&gt;numexpr&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;bottleneck&lt;/code&gt; for additional performance improvements&lt;/li&gt;
  &lt;li&gt;Caution against chaining too many rows of pandas operations in sequence: difficult to debug, chain only a couple of operations together to simplify your maintenance&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Filter your data before calculating&lt;/strong&gt; on the remaining rows rather than filtering after calculating&lt;/li&gt;
  &lt;li&gt;Check the schema of your DataFrames as they evolve -&amp;gt; tool like &lt;code class=&quot;highlighter-rouge&quot;&gt;bulwark&lt;/code&gt;, you can visualize confirm that your expectations are being met&lt;/li&gt;
  &lt;li&gt;Large Series with low cardinality: &lt;code class=&quot;highlighter-rouge&quot;&gt;df['series_of_strings'].astype('category')&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;value_counts&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;groupby&lt;/code&gt; run faster and the Series consume less RAM&lt;/li&gt;
  &lt;li&gt;Convert 8-byte &lt;code class=&quot;highlighter-rouge&quot;&gt;float64&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;int64&lt;/code&gt; to smaller datatypes -&amp;gt; 2-byte &lt;code class=&quot;highlighter-rouge&quot;&gt;float16&lt;/code&gt; or 1-byte &lt;code class=&quot;highlighter-rouge&quot;&gt;int8&lt;/code&gt; -&amp;gt; smaller range to further save RAM&lt;/li&gt;
  &lt;li&gt;Use the &lt;code class=&quot;highlighter-rouge&quot;&gt;del&lt;/code&gt; keyword to delete earlier references and clear them from memory&lt;/li&gt;
  &lt;li&gt;Pandas &lt;code class=&quot;highlighter-rouge&quot;&gt;drop&lt;/code&gt; method to delete unused columns&lt;/li&gt;
  &lt;li&gt;Persist the prepared DataFrame version to disk by using &lt;code class=&quot;highlighter-rouge&quot;&gt;to_pickle&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Avoid &lt;code class=&quot;highlighter-rouge&quot;&gt;inplace=True&lt;/code&gt; -&amp;gt; are scheduled to be removed from the library over time&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Modin&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;cuDF&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Vaex&lt;/code&gt;: work on very large datasets that exceed RAM by using lazy evaluation while retaining a similar interface to Pandas -&amp;gt; large datasets and string-heavy operations&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch7-compiling-to-c&quot;&gt;Ch7. Compiling to C&lt;/h1&gt;
&lt;p&gt;To make code run faster:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Make it do less work&lt;/li&gt;
  &lt;li&gt;Choose good algorithms&lt;/li&gt;
  &lt;li&gt;Reduce the amount of data you’re processing&lt;/li&gt;
  &lt;li&gt;Execute fewer instructions -&amp;gt; compile your code down to machine code&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;python-offers&quot;&gt;Python offers&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt;: pure C-based compiling&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Numba&lt;/code&gt;: LLVM-based compiling&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PyPy&lt;/code&gt;: replacement virtual machine which includes a built-in just-in-time (JIT) compiler&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-sort-of-speed-gains-are-possible&quot;&gt;What sort of speed gains are possible?&lt;/h2&gt;
&lt;p&gt;Compiling generate more gains when the code:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;is mathematical&lt;/li&gt;
  &lt;li&gt;has lots of loops that repeat the same operations many times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unlikely to show speed up:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;calls to external libraries (regexp, string operations, calls to database)&lt;/li&gt;
  &lt;li&gt;programs that are I/O-bound&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;jit-versus-aot-compilers&quot;&gt;JIT versus AOT compilers&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;AOT (ahead of time)&lt;/strong&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt; -&amp;gt; you’ll have a library that can instantly be used -&amp;gt; best speedups, but requires the most manual effort&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;JIT (just in time)&lt;/strong&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;Numba&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;PyPy&lt;/code&gt; -&amp;gt; you don’t have to do much work up front, but you have a “cold start” problem -&amp;gt; impressive speedups with little manual intervention&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-does-type-information-help-the-code-run-faster&quot;&gt;Why does type information help the code run faster?&lt;/h2&gt;
&lt;p&gt;Python is dynamically typed -&amp;gt; keeping the code generic makes it run more slowly&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Inside a section of code that is CPU-bound, it is often the case that the types of variables do not change. This gives us an opportunity for &lt;strong&gt;static compilation and faster code execution&lt;/strong&gt;”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;using-a-c-compiler&quot;&gt;Using a C compiler&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt; uses &lt;code class=&quot;highlighter-rouge&quot;&gt;gcc&lt;/code&gt;: good choice for most platforms; well supported and quite advanced&lt;/p&gt;

&lt;h2 id=&quot;cython&quot;&gt;Cython&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Compiler that converts type-annotaded (C-like) Python into a compiled extension module&lt;/li&gt;
  &lt;li&gt;Wide used and mature&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OpenMP&lt;/code&gt; support: possible to convert parallel problems into multiprocessing-aware modules&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyximport&lt;/code&gt;: simplified build system&lt;/li&gt;
  &lt;li&gt;Annotation option that output an HTML file -&amp;gt; more yellow = more calls into the Python virtual machine; more white = more non-Python C code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lines that cost the most CPU time:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;inside tight inner loops&lt;/li&gt;
  &lt;li&gt;dereferencing &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;np.array&lt;/code&gt; items&lt;/li&gt;
  &lt;li&gt;mathematical operations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cdef&lt;/code&gt; keyword: declare variables inside the function body. These must be declared at the top of the function, as that’s a requirement from the C language specification&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Strength reduction&lt;/strong&gt;: writing equivalent but more specialized code to solve the same problem. Trade worse flexibility (and possibly worse readability) for faster execution&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;memoryview&lt;/code&gt;: allows the same low-level access to any object that implements the buffer interface, including &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays and Python arrays&lt;/p&gt;

&lt;h2 id=&quot;numba&quot;&gt;Numba&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;JIT compiler that specializes in &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; code, which it compiles via LLVM compiler at runtime&lt;/li&gt;
  &lt;li&gt;You provide a decorator telling it which functions to focus on and then you let Numba take over&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays and nonvectorized code that iterates over many items: Numba should give you a quick and very painless win.&lt;/li&gt;
  &lt;li&gt;Numba does not bind to external C libraries (which Cython can do), but it can automatically generate code for GPUs (which Cython cannot).&lt;/li&gt;
  &lt;li&gt;OpenMP parallelization support with &lt;code class=&quot;highlighter-rouge&quot;&gt;prange&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Break your code into small (&amp;lt;10 line) and discrete functions and tackle these one at a time&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from numba import jit

@jit()
def my_fn():
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;pypy&quot;&gt;PyPy&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Alternative implementation of the Python language that includes a tracing just-in-time compiler&lt;/li&gt;
  &lt;li&gt;Offers a faster experience than CPython&lt;/li&gt;
  &lt;li&gt;Uses a different type of garbage collector (modified mark-and-sweep) than CPython (reference counting) = may clean up an unused object much later&lt;/li&gt;
  &lt;li&gt;PyPy can use a lot of RAM&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;vmprof&lt;/code&gt;: lightweight sampling profiler&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;when-to-use-each-technology&quot;&gt;When to use each technology&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;./compiler_options.png&quot; alt=&quot;compiler_options&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Numba&lt;/code&gt;: quick wins for little effort; young project&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt;: best results for the widest set of prolbmes; requires more effort; mix Python and C annotations&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PyPy&lt;/code&gt;: strong option if you’re not using &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; or other hard-to-port C extensions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other-upcoming-projects&quot;&gt;Other upcoming projects&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Pythran&lt;/li&gt;
  &lt;li&gt;Transonic&lt;/li&gt;
  &lt;li&gt;ShedSkin&lt;/li&gt;
  &lt;li&gt;PyCUDA&lt;/li&gt;
  &lt;li&gt;PyOpenCL&lt;/li&gt;
  &lt;li&gt;Nuitka&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;graphics-processing-units-gpus&quot;&gt;Graphics Processing Units (GPUs)&lt;/h2&gt;
&lt;p&gt;Easy-to-use GPU mathematics libraries:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;TensorFlow&lt;/li&gt;
  &lt;li&gt;PyTorch&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dynamic-graphs-pytorch&quot;&gt;Dynamic graphs: PyTorch&lt;/h3&gt;
&lt;p&gt;Static computational graph tensor library that is particularly user-friendly and has a very intuitive API for anyone familiar with &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Static computational graph&lt;/em&gt;: performing operations on &lt;code class=&quot;highlighter-rouge&quot;&gt;PyTorch&lt;/code&gt; objects creates a dynamic definition of a program that gets compiled to GPU code in the background when it is executed -&amp;gt; changes to the Python code automatically get reflected in changes in the GPU code without an explicit compilation step needed&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;basic-gpu-profiling&quot;&gt;Basic GPU profiling&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nvidia-smi&lt;/code&gt;: inspect the resource utilization of the GPU&lt;/li&gt;
  &lt;li&gt;Power usage is a good proxy for judging how much of the GPU’s compute power is being used -&amp;gt; more power the GPU is drawing = more compute it is currently doing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;when-to-use-gpus&quot;&gt;When to use GPUs&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Task requires mainly linear algebra and matrix manipulations (multiplication, addition, Fourier transforms)&lt;/li&gt;
  &lt;li&gt;Particularly true if the calculation can happen on the GPU uninterrupted for a period of time before being copied back into system memory&lt;/li&gt;
  &lt;li&gt;GPU can run many more tasks at once than the CPU can, but each of those tasks run more slowly on the GPU than on the CPU&lt;/li&gt;
  &lt;li&gt;Not a good tool for tasks that require exceedingly large amounts of data, many conditional manipulations of the data, or changing data&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Ensure that the memory use of the problem will fit withing the GPU&lt;/li&gt;
  &lt;li&gt;Evaluate whether the algorithm requires a lot of branching conditions versus vectorized operations&lt;/li&gt;
  &lt;li&gt;Evaluate how much data needs to be moved between the GPU and the CPU&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;ch8-asynchronous-io&quot;&gt;Ch8. Asynchronous I/O&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;I/O bound program&lt;/em&gt;: the speed is bounded by the efficiency of the input/output&lt;/p&gt;

&lt;p&gt;Asynchronous I/O helps utilize the wasted &lt;em&gt;I/O wait&lt;/em&gt; time by allowing us to perform other operations while we are in that state&lt;/p&gt;

&lt;h2 id=&quot;introduction-to-asynchronous-programming&quot;&gt;Introduction to asynchronous programming&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Context switch&lt;/em&gt;: when a program enters I/O wait, the execution is paused so that the kernel can perform the low-level operations associated with the I/O request&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Callback paradigm&lt;/strong&gt;: functions are called with an argument that is generally called the callback -&amp;gt; instead of the function returing its value, it call the callback function with the value instead -&amp;gt; long chains = “callback hell”&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Future paradigm&lt;/strong&gt;: an asynchronous function returns a &lt;code class=&quot;highlighter-rouge&quot;&gt;Future&lt;/code&gt; object, which is a promise of a future result&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;asyncio&lt;/code&gt; standard library module and PEP 492 made the future’s mechanism native to Python&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-does-asyncawait-work&quot;&gt;How does async/await work?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;async&lt;/code&gt; function (defined with &lt;code class=&quot;highlighter-rouge&quot;&gt;async def&lt;/code&gt;) is called a &lt;em&gt;coroutine&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Coroutines are implemented with the same philosophies as generators&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt; is similar in function to a &lt;code class=&quot;highlighter-rouge&quot;&gt;yield&lt;/code&gt; -&amp;gt; the execution of the current function gets paused while other code is run&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gevent&quot;&gt;Gevent&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Patches the standard library with asynchronous I/O functions,&lt;/li&gt;
  &lt;li&gt;Has a &lt;code class=&quot;highlighter-rouge&quot;&gt;Greenlets&lt;/code&gt; object that can be used for concurrent execution&lt;/li&gt;
  &lt;li&gt;Ideal solution for mainly CPU-based problems that sometimes involve heavy I/O&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tornado&quot;&gt;tornado&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Frequently used package for asynchronous I/O in Python&lt;/li&gt;
  &lt;li&gt;Originally developed by Facebook primarily for HTTP clients and servers&lt;/li&gt;
  &lt;li&gt;Ideal for any application that is mostly I/O-bound and where most of the application should be asynchronous&lt;/li&gt;
  &lt;li&gt;Performant web server&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aiohttp&quot;&gt;aiohttp&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Built entirely on the &lt;code class=&quot;highlighter-rouge&quot;&gt;asyncio&lt;/code&gt; library&lt;/li&gt;
  &lt;li&gt;Provides both HTTP client and server functionality&lt;/li&gt;
  &lt;li&gt;Uses a similar API to &lt;code class=&quot;highlighter-rouge&quot;&gt;tornado&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;batched-results&quot;&gt;Batched results&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Pipelining&lt;/em&gt;: batching results -&amp;gt; can help lower the burden of an I/O task&lt;/li&gt;
  &lt;li&gt;Good compromise between the speeds of asynchronous I/O and the ease of writing serial programs&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch9-the-multiprocessing-module&quot;&gt;Ch9. The multiprocessing module&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Additional process = more communication overhead = decrease available RAM -&amp;gt; rarely get a full &lt;em&gt;n&lt;/em&gt;-times speedup&lt;/li&gt;
  &lt;li&gt;If you run out of RAM and the system reverts to using the disk’s swap space, any parallelization advantage will be massively lost to the slow paging of RAM back and forth to disk&lt;/li&gt;
  &lt;li&gt;Using hyperthreads: CPython uses a lot of RAM -&amp;gt; hyperthreading is not cache friendly. Hyperthreads = added bonus and not a resource to be optimized against -&amp;gt; adding more CPUs is more economical than tuning your code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Amdahl’s law&lt;/strong&gt;: if only a small part of your code can be parallelized, it doesn’t matter how many CPUs you throw at it; it still won’t run much faster overall&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt; module: process and thread-based parallel processing, share work over queues, and share data among processes -&amp;gt; focus: single-machine multicore parallelism&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt;: higher level, sharing Python data structures&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OpenMP&lt;/code&gt;: works with C primitive objects once you’ve compiled to C&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Keep the parallelism as simple as possible so that your development velocity is kept high&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Embarrassingly parallel&lt;/em&gt;: multiple Python processes all solving the same problem without communicating with one another -&amp;gt; not much penalty will be incurred as we add more and more Python processes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Typical jobs for the &lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt; module:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Parallelize a CPU-bound task with &lt;code class=&quot;highlighter-rouge&quot;&gt;Process&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool&lt;/code&gt; objects&lt;/li&gt;
  &lt;li&gt;Parallelize an I/O-bound task in a &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool&lt;/code&gt; with threads using the &lt;code class=&quot;highlighter-rouge&quot;&gt;dummy&lt;/code&gt; module&lt;/li&gt;
  &lt;li&gt;Share pickled work via a &lt;code class=&quot;highlighter-rouge&quot;&gt;Queue&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Share state between parallelized workers, including bytes, primitive datatypes, dictionaries, and lists&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Joblib&lt;/code&gt;: stronger cross-platform support than &lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;replacing-multiprocessing-with-joblib&quot;&gt;Replacing multiprocessing with Joblib&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Joblib&lt;/code&gt; is an improvement on &lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Enables lightweight pipelining with a focus on:
    &lt;ul&gt;
      &lt;li&gt;easy parallel computing&lt;/li&gt;
      &lt;li&gt;transparent disk-based caching of results&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;It focuses on NumPy arrays for scientific computing&lt;/li&gt;
  &lt;li&gt;Quick wins:
    &lt;ul&gt;
      &lt;li&gt;process a loop that could be embarrassingly parallel&lt;/li&gt;
      &lt;li&gt;expensive functions that have no side effect&lt;/li&gt;
      &lt;li&gt;able to share &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; data between processes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Parallel&lt;/code&gt; class: sets up the process pool&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;delayed&lt;/code&gt; decorator: wraps our target function so it can be applied to the instantiated &lt;code class=&quot;highlighter-rouge&quot;&gt;Parallel&lt;/code&gt; object via an iterator&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intelligent-caching-of-function-call-results&quot;&gt;Intelligent caching of function call results&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Memory&lt;/code&gt; cache: decorator that caches functions results based on the input arguments to a disk cache&lt;/p&gt;

&lt;h3 id=&quot;using-numpy&quot;&gt;Using numpy&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; is more cache friendly&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; can achieve some level of additional speedup around threads by working outside the GIL&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;asynchronous-systems&quot;&gt;Asynchronous systems&lt;/h2&gt;
&lt;p&gt;Require a special level of patience. Suggestions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;K.I.S.S.&lt;/li&gt;
  &lt;li&gt;Avoiding asynchronous self-contained systems if possible, as they will grow in complexity and quickly become hard to maintain&lt;/li&gt;
  &lt;li&gt;Using mature libraries like &lt;code class=&quot;highlighter-rouge&quot;&gt;gevent&lt;/code&gt; that give you tried-and-tested approaches to dealing with certain problem sets&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;interprocess-communication-ipc&quot;&gt;Interprocess Communication (IPC)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Cooperation cost can be high: synchronizing data and checking the shared data&lt;/li&gt;
  &lt;li&gt;Sharing state tends to make things complicated&lt;/li&gt;
  &lt;li&gt;IPC is fairly easy but generally comes with a cost&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiprocessingmanager&quot;&gt;multiprocessing.Manager()&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Lets us share higher-level Python objects between processes as managed shared objects; the lower-level objects are wrapped in proxy objects&lt;/li&gt;
  &lt;li&gt;The wrapping and safety have a speed cost but also offer great flexibility.&lt;/li&gt;
  &lt;li&gt;You can share both lower-level objects (e.g., integers and floats) and lists and dictionaries.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;redis&quot;&gt;Redis&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Key/value in-memory storage engine&lt;/strong&gt;. It provides its own locking and each operation is atomic, so we don’t have to worry about using locks from inside Python (or from any other interfacing language).&lt;/li&gt;
  &lt;li&gt;Lets you share state not just with other Python processes but also other tools and other machines, and even to expose that state over a web-browser interface&lt;/li&gt;
  &lt;li&gt;Redis lets you store: Lists of strings; Sets of strings; Sorted sets of strings; Hashes of strings&lt;/li&gt;
  &lt;li&gt;Stores everything in RAM and snapshots to disk&lt;/li&gt;
  &lt;li&gt;Supports master/slave replication to a cluster of instances&lt;/li&gt;
  &lt;li&gt;Widely used in industry and is mature and well trusted&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mmap&quot;&gt;mmap&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Memory-mapped (shared memory) solution&lt;/li&gt;
  &lt;li&gt;The bytes in a shared memory block are not synchronized and they come with very little overhead&lt;/li&gt;
  &lt;li&gt;Bytes act like a file -&amp;gt; block of memory with a file-like interface&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-clusters-and-job-queues&quot;&gt;Ch10. Clusters and Job Queues&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Cluster&lt;/em&gt;: collection of computers working together to solve a common task&lt;/p&gt;

&lt;p&gt;Before moving to a clustered solution:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Profile your system to understand the bottlenecks&lt;/li&gt;
  &lt;li&gt;Exploit compile solutions (Numba, Cython)&lt;/li&gt;
  &lt;li&gt;Exploit multiple cores on a single machine (Joblib, multiprocessing)&lt;/li&gt;
  &lt;li&gt;Exploit techniques for using less RAM&lt;/li&gt;
  &lt;li&gt;Really need a lot of CPUs, high resiliency, rapid speed of response, ability to process data from disks in parallel&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;benefits-of-clustering&quot;&gt;Benefits of clustering&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Easily scale computing requirements&lt;/li&gt;
  &lt;li&gt;Improve reliability&lt;/li&gt;
  &lt;li&gt;Dynamic scaling&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;drawbacks-of-clustering&quot;&gt;Drawbacks of clustering&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Change in thinking&lt;/li&gt;
  &lt;li&gt;Latency between machines&lt;/li&gt;
  &lt;li&gt;Sysadmin problems: software versions between machines, are other machines working?&lt;/li&gt;
  &lt;li&gt;Moving parts that need to be in sync&lt;/li&gt;
  &lt;li&gt;“If you don’t have a documented restart plan, you should assume you’ll have to write one at the worst possible time”&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Using a cloud-based cluster can mitigate a lot of these problems, and some cloud providers also offer a spot-priced market for cheap but temporary computing resources.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;A system that’s easy to debug &lt;em&gt;probably&lt;/em&gt; beats having a faster system&lt;/li&gt;
  &lt;li&gt;Engineering time and the cost of downtime are &lt;em&gt;probably&lt;/em&gt; your largest expenses&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parallel-pandas-with-dask&quot;&gt;Parallel Pandas with Dask&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Provide a suite of parallelization solutions that scales from a single core on a laptop to multicore machines to thousands of cores in a cluster.&lt;/li&gt;
  &lt;li&gt;“Apache Spark lite”&lt;/li&gt;
  &lt;li&gt;For &lt;code class=&quot;highlighter-rouge&quot;&gt;Pandas&lt;/code&gt; users: larger-than-RAM datasets and desire for multicore parallelization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dask&quot;&gt;Dask&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Bag&lt;/em&gt;: enables parallelized computation on unstructured and semistructured data&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Array&lt;/em&gt;: enables distributed and larger-than-RAM &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; operations&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Distributed DataFrame&lt;/em&gt;: enables distributed and larger-than-RAM &lt;code class=&quot;highlighter-rouge&quot;&gt;Pandas&lt;/code&gt; operations&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Delayed&lt;/em&gt;: parallelize chains of arbitrary Python functions in a lazy fashion&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Futures&lt;/em&gt;: interface that includes &lt;code class=&quot;highlighter-rouge&quot;&gt;Queue&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Lock&lt;/code&gt; to support task collaboration&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Dask-ML&lt;/em&gt;: scikit-learn-like interface for scalable machine learning&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;You can use Dask (and Swifter) to parallelize any side-effect-free function that you’d usually use in an &lt;code class=&quot;highlighter-rouge&quot;&gt;apply&lt;/code&gt; call&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;npartitions&lt;/code&gt; = # cores&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;swifter&quot;&gt;Swifter&lt;/h4&gt;
&lt;p&gt;Builds on Dask to provide three parallelized options with very simple calls: &lt;code class=&quot;highlighter-rouge&quot;&gt;apply&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;resample&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;rolling&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;vaex&quot;&gt;Vaex&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;String-heavy DataFrames&lt;/li&gt;
  &lt;li&gt;Larger-than-RAM datasets&lt;/li&gt;
  &lt;li&gt;Subsets of a DataFrame -&amp;gt; Implicit lazy evaluation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;nsq-for-robust-production-clustering&quot;&gt;NSQ for robust production clustering&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Highly performant distributed messaging platform&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Queues&lt;/em&gt;: type of buffer for messages&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Pub/subs&lt;/em&gt;: describes who gets what messages (&lt;em&gt;publisher/subscriber&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch11-using-less-ram&quot;&gt;Ch11. Using less RAM&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Counting the amount of RAM used by Python object is tricky -&amp;gt; if we ask the OS for a count of bytes used, it will tell us the total amount allocated to the process&lt;/li&gt;
  &lt;li&gt;Each unique object has a memory cost&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;objects-for-primitives-are-expensive&quot;&gt;Objects for primitives are expensive&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%load_ext memory_profiler

%memit &amp;lt;operation&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;the-array-module-stores-many-primitive-objects-cheaply&quot;&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; module stores many primitive objects cheaply&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Creates a contiguos block of RAM to hold the underlying data. Which data structures:
    &lt;ul&gt;
      &lt;li&gt;integers, floats and characters&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;not&lt;/em&gt; complex numbers or classes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Good to pass the array to an external process or use only some of the data (not to compute on them)&lt;/li&gt;
  &lt;li&gt;Using a regular &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; to store many numbers is much less efficient in RAM than using an &lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays are almost certainly a better choice if you are doing anything heavily numeric:
    &lt;ul&gt;
      &lt;li&gt;more datatype options&lt;/li&gt;
      &lt;li&gt;many specialized and fast functions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;using-less-ram-in-numpy-with-numexpr&quot;&gt;Using less RAM in NumPy with NumExpr&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NumExpr&lt;/code&gt; is a tool that both speeds up and reduces the size of intermediate operations&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Install the optional NumExpr when using Pandas (Pandas does not tell you if you haven’t installed NumExpr) -&amp;gt; calls to &lt;code class=&quot;highlighter-rouge&quot;&gt;eval&lt;/code&gt; will run more quickly -&amp;gt; import numpexpr: if this fails, install it!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;NumExpr breaks the long vectors into shorter, cache-friendly chunks and processes each in series, so local chunks of results are calculated in a cache-friendly way&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bytes-versus-unicode&quot;&gt;Bytes versus Unicode&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Python 3.x, all strings are Unicode by default, and if you want to deal in bytes, you’ll explicitly create a &lt;code class=&quot;highlighter-rouge&quot;&gt;byte&lt;/code&gt; sequence&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UTF-8 encoding&lt;/strong&gt; of a Unicode object uses 1 byte per ASCII character and more bytes for less frequently seen characters&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;more-efficient-tree-structures-to-represent-strings&quot;&gt;More efficient tree structures to represent strings&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tries&lt;/strong&gt;: share common prefixes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DAWG&lt;/strong&gt;: share common prefixes and suffixes&lt;/li&gt;
  &lt;li&gt;Overlapping sequences in your strings -&amp;gt; you’ll likely see a RAM improvement&lt;/li&gt;
  &lt;li&gt;Save RAM and time in exchange for a little additional effort in preparation&lt;/li&gt;
  &lt;li&gt;Unfamiliar data structures to many developers -&amp;gt; isolate in a module to simplify maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;directed-acyclic-word-graph-dawg&quot;&gt;Directed Acyclic Word Graph (DAWG)&lt;/h3&gt;
&lt;p&gt;Attemps to efficiently represent strings that share common prefixes and suffixes&lt;/p&gt;

&lt;h3 id=&quot;marisa-trie&quot;&gt;Marisa Trie&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Static trie&lt;/em&gt; using Cython bindings to an external library -&amp;gt; it cannot be modified after construction&lt;/p&gt;

&lt;h2 id=&quot;scikit-learns-dictvectorizer-and-featurehasher&quot;&gt;Scikit-learn’s DictVectorizer and FeatureHasher&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DictVectorizer&lt;/code&gt;: takes a dictionary of terms and their frequences and converts them into a variable-width sparse matrix -&amp;gt; it is possible to revert the process&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;FeatureHasher&lt;/code&gt;: converts the same dictionary of terms and frequencies into a fixed-width sparse matrix -&amp;gt; it doesn’t store a vocabulary and instead employs a hashing algorithm to assign token frequencies to columns -&amp;gt; can’t convert it back to the original token from hash&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scypys-sparse-matrices&quot;&gt;ScyPy’s Sparse Matrices&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Matrix in which most matrix elements are 0&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;C00&lt;/code&gt; matrices: simplest implementation: each non-zero element we store the value in addition to the location of the value -&amp;gt; each non-zero value = 3 numbers stored -&amp;gt; used only to contruct sparse matrices and not for actual computation&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CSR/CSC&lt;/code&gt; is preferred for computation&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Push and pull of speedups with sparse arrays: balance between losing the use of efficient caching and vectorization versus not having to do a lot of the calculations associated with the zero values of the matrix&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Limitations:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Low amount of support&lt;/li&gt;
  &lt;li&gt;Multiple implementations with benefits and drawbacks&lt;/li&gt;
  &lt;li&gt;May require expert knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tips-for-using-less-ram&quot;&gt;Tips for using less RAM&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;“If you can avoid putting it into RAM, do. Everything you load costs you RAM”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Numeric data: switch to using &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays&lt;/li&gt;
  &lt;li&gt;Very sparse arrays: SciPy’s sparse array functionality&lt;/li&gt;
  &lt;li&gt;Strings: stick to &lt;code class=&quot;highlighter-rouge&quot;&gt;str&lt;/code&gt; rather than &lt;code class=&quot;highlighter-rouge&quot;&gt;bytes&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Many Unicode objects in a static structure: DAWG and trie structures&lt;/li&gt;
  &lt;li&gt;Lots of bit strings: &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;bitarray&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;probabilistic-data-structures&quot;&gt;Probabilistic Data Structures&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Make trade-offs in accuracy for immense decrease in memory usage&lt;/li&gt;
  &lt;li&gt;The number of operations you can do on them is much more restricted&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Probabilistic data structures are fantastic when you have taken the time to understand the problem and need to put something into production that can answer a very small set of questions about a very large set of data”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;“lossy compression”: find an alternative representation for the data that is more compact and contains the relevant information for answering a certain set of questions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;morris-counter&quot;&gt;Morris counter&lt;/h3&gt;
&lt;p&gt;Keeps track of an exponent and models the counted state as &lt;code class=&quot;highlighter-rouge&quot;&gt;2^exponent&lt;/code&gt; -&amp;gt; provides an &lt;em&gt;order of magnitude&lt;/em&gt; estimate&lt;/p&gt;

&lt;h3 id=&quot;k-minimum-values&quot;&gt;K-Minimum values&lt;/h3&gt;
&lt;p&gt;If we keep the &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt; smallest unique hash values we have seen, we can &lt;strong&gt;approximate the overall spacing between hash values&lt;/strong&gt; and infer the total number of items&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;idempotence&lt;/em&gt;: if we do the same operation, with the same inputs, on the structure multiple times, the state will not be changed&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bloom-filters&quot;&gt;Bloom filters&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Answer the question of &lt;strong&gt;whether we’ve seen an item before&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Work by having multiple hash values in order to represent a value as multiple integers. If we later see something with the same set of integers, we can be reasonably confident that it is the same value&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No false negatives and a controllable rate of false positives&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Set to have error rates below 0.5%&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch12-lessons-from-the-field&quot;&gt;Ch12. Lessons from the field&lt;/h1&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/high_performance_python/high_performance_python.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/high_performance_python/high_performance_python.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Machine Learning: tests and production</title><link href="https://millengustavo.github.io/blog/tests/machine%20learning/data%20science/deploy/2020/06/01/ml-test-production.html" rel="alternate" type="text/html" title="Machine Learning: tests and production" /><published>2020-06-01T00:00:00-05:00</published><updated>2020-06-01T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/tests/machine%20learning/data%20science/deploy/2020/06/01/ml-test-production</id><content type="html" xml:base="https://millengustavo.github.io/blog/tests/machine%20learning/data%20science/deploy/2020/06/01/ml-test-production.html">&lt;blockquote&gt;
  &lt;p&gt;“Creating reliable, production-level machine learning systems brings on a host of concerns not found in small toy examples or even large offline research experiments. Testing and monitoring are key considerations for ensuring the production-readiness of an ML system, and for reducing technical debt of ML systems.” - &lt;a href=&quot;https://research.google/pubs/pub46555/&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I recently read the excellent book written by Emmanuel Ameisen: &lt;a href=&quot;http://shop.oreilly.com/product/0636920215912.do&quot;&gt;Building Machine Learning Powered Applications Going from Idea to Product&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I definitely recommend the book to people involved at any stage in the process of developing and implementing products that use Machine Learning.&lt;/p&gt;

&lt;h1 id=&quot;the-ml-test-score-a-rubric-for-ml-production-readiness-and-technical-debt-reduction&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/h1&gt;
&lt;p&gt;A good reference I found in chapter 6 of the book entitled: Debug your ML problems, was the article written by Google engineers: &lt;a href=&quot;https://research.google/pubs/pub46555/&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the article, the authors:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“(…) present 28 specific tests and monitoring needs, drawn from experience with a wide range of production ML systems to help quantify these issues and present an easy to follow road-map to improve production readiness and pay down ML technical debt.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a good practice presented by Ameisen in his book when referring to reproducing successful results from the past: &lt;strong&gt;“Stand on the shoulders of giants”&lt;/strong&gt;, I believe that we can learn from Google’s experience in building applications using Machine Learning.&lt;/p&gt;

&lt;h2 id=&quot;manually-coded-systems-vs-ml-based-systems&quot;&gt;Manually coded systems vs. ML-based systems&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/systems_comparison.PNG&quot; alt=&quot;systems_comparison&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Unlike manually coded systems, the behavior of machine learning systems depends on data and models that are not always possible to specify fully a priori&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“(…) training data needs testing like code, and a trained ML model needs production practices like a binary does, such as debuggability, rollbacks and monitoring”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;tests&quot;&gt;Tests&lt;/h2&gt;
&lt;h3 id=&quot;data&quot;&gt;Data&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/data.PNG&quot; alt=&quot;data&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;model&quot;&gt;Model&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/model.PNG&quot; alt=&quot;model&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;infrastructure&quot;&gt;Infrastructure&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/infra.PNG&quot; alt=&quot;infra&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/monitor.PNG&quot; alt=&quot;monitor&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;computing-an-ml-test-score&quot;&gt;Computing an ML Test Score&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/score.PNG&quot; alt=&quot;score&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;insights-from-applying-the-rubric-to-real-systems&quot;&gt;Insights from applying the rubric to real systems&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Checklists&lt;/strong&gt; are helpful even for expert teams&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data dependencies&lt;/strong&gt; can lead to outsourcing responsibility for fully understanding it&lt;/li&gt;
  &lt;li&gt;The importance of &lt;strong&gt;frameworks&lt;/strong&gt;: pipeline platforms may allow building generic integration tests&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Deploying a machine learning system with monitoring is a very complex task. This is a problem faced by virtually all players in the market who are starting their journey with data.&lt;/p&gt;

&lt;p&gt;A good first step on this journey is to organize your data pipeline and use managed environments in the cloud for the ML tasks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Amazon SageMaker&lt;/li&gt;
  &lt;li&gt;Google Cloud AI Platform&lt;/li&gt;
  &lt;li&gt;Azure Machine Learning Studio&lt;/li&gt;
  &lt;li&gt;Databricks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even if we do not face the scale of some problems mentioned in the article, it is worth reflecting on how we can improve what we do today to reduce technical debt in the future.&lt;/p&gt;

&lt;h1 id=&quot;further-reading&quot;&gt;Further reading&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://research.google/pubs/pub46555/&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://shop.oreilly.com/product/0636920215912.do&quot;&gt;Building Machine Learning Powered Applications Going from Idea to Product - Emmanuel Ameisen&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mlinproduction.com/&quot;&gt;ML in Production blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://speakerdeck.com/trallard/what-is-your-ml-test-score&quot;&gt;What is your machine learning test score?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/mlflow/mlflow&quot;&gt;MLflow: A Machine Learning Lifecycle Platform&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/solutions/machine-learning&quot;&gt;Databricks for Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">“Creating reliable, production-level machine learning systems brings on a host of concerns not found in small toy examples or even large offline research experiments. Testing and monitoring are key considerations for ensuring the production-readiness of an ML system, and for reducing technical debt of ML systems.” - The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/ml_test_production/systems_comparison.PNG" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/ml_test_production/systems_comparison.PNG" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Building Machine Learning Powered Applications: Going from Idea to Product</title><link href="https://millengustavo.github.io/blog/book/machine%20learning/data%20science/deploy/2020/05/22/build-ml-app.html" rel="alternate" type="text/html" title="Building Machine Learning Powered Applications: Going from Idea to Product" /><published>2020-05-22T00:00:00-05:00</published><updated>2020-05-22T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/machine%20learning/data%20science/deploy/2020/05/22/build-ml-app</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/machine%20learning/data%20science/deploy/2020/05/22/build-ml-app.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Author: Emmanuel Ameisen&lt;/p&gt;

&lt;h1 id=&quot;part-i-find-the-correct-ml-approach&quot;&gt;Part I. Find the Correct ML Approach&lt;/h1&gt;

&lt;h1 id=&quot;ch1-from-product-goal-to-ml-framing&quot;&gt;Ch1. From Product Goal to ML Framing&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;ML is particularly useful to build systems for which we are unable to define a heuristic solution&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Start from a concrete business problem, determine whether it requires ML, then work on finding the ML approach that will allow you to iterate as rapidly as possible&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Framing your product goal in an ML paradigm&lt;/li&gt;
  &lt;li&gt;Evaluating the feasibility of that ML task&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Estimating the challenge of data acquisition ahead of time is crucial in order to succeed&lt;/p&gt;

&lt;h2 id=&quot;data-availability-scenarios&quot;&gt;Data availability scenarios&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Labeled data exists&lt;/li&gt;
  &lt;li&gt;Weakly labeled data exists&lt;/li&gt;
  &lt;li&gt;Unlabeled data exists&lt;/li&gt;
  &lt;li&gt;We need to acquire data&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Having an imperfect dataset is entirely fine and shouldn’t stop you. The ML process is iterative in nature, so starting with a dataset and getting some initial results is the best way forward, regardless of the data quality.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-simplest-approach-being-the-algorithm&quot;&gt;The Simplest Approach: being the algorithm&lt;/h2&gt;
&lt;p&gt;Start with a human heuristic and then build a simple model: initial baseline = first step toward a solution -&amp;gt; Great way to inform what to build next&lt;/p&gt;

&lt;h2 id=&quot;what-to-focus-on-in-an-ml-project&quot;&gt;What to focus on in an ML project&lt;/h2&gt;
&lt;p&gt;Find the &lt;em&gt;impact bottleneck&lt;/em&gt;: piece of the pipeline that could provide the most value if improved&lt;/p&gt;

&lt;p&gt;Imagine that the impact bottleneck is solved: it was worth the effort you estimate it would take?&lt;/p&gt;

&lt;h2 id=&quot;which-modeling-techniques-to-use&quot;&gt;Which modeling techniques to use&lt;/h2&gt;
&lt;p&gt;Spend the manual effort to look at inputs and outputs of your model: see if anything looks weird. Looking at your data helps you think of good heuristics, models and ways to reframe the product&lt;/p&gt;

&lt;h1 id=&quot;ch2-create-a-plan&quot;&gt;Ch2. Create a Plan&lt;/h1&gt;

&lt;h2 id=&quot;measuring-success&quot;&gt;Measuring Success&lt;/h2&gt;
&lt;p&gt;First model: simplest model that could address a product’s needs -&amp;gt; generating and analyzing results is the fastest way to make progress in ML&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Baseline: heuristics based on domain knowledge&lt;/li&gt;
  &lt;li&gt;Simple model&lt;/li&gt;
  &lt;li&gt;Complex model&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;You don’t always need ML: even features that could benefit from ML can often simply use a heuristic for their first version (you may realize that you don’t need ML at all)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;business-performance&quot;&gt;Business Performance&lt;/h2&gt;
&lt;p&gt;Product metrics: goals of your product or feature. Ultimately the only ones that matter, all other metrics should be used as tools to improve product metrics&lt;/p&gt;

&lt;h3 id=&quot;updating-an-app-to-make-a-modeling-task-easier&quot;&gt;Updating an app to make a modeling task easier&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Change an interface so that a model’s results can be omitted if they are below a confidence threshold&lt;/li&gt;
  &lt;li&gt;Present a few other predictions or heuristics in addition to model’s top prediction&lt;/li&gt;
  &lt;li&gt;Communicate to users that model is still in an experimental phase and giving them opportunities to provide feedback&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“A product should be designed with reasonable assumptions of model performance in mind. If a product relies on a model being perfect to be useful, it is very likely to produce innacurate or even dangerous results”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;freshness-and-distribution-shift&quot;&gt;Freshness and Distribution Shift&lt;/h2&gt;
&lt;p&gt;Distribution of the data shifts -&amp;gt; model often needs to change in order to maintain the same level of performance&lt;/p&gt;

&lt;h2 id=&quot;leverage-domain-expertise&quot;&gt;Leverage Domain Expertise&lt;/h2&gt;
&lt;p&gt;Best way to devise heuristics -&amp;gt; see what experts are currently doing. Most practical applications are not entirely novel. How do people currently solve the problem you are trying to solve?&lt;/p&gt;

&lt;p&gt;Second best way -&amp;gt; look at your data. Based on your dataset, how would you solve this task if you were doing it manually?&lt;/p&gt;

&lt;h3 id=&quot;examining-the-data&quot;&gt;Examining the data&lt;/h3&gt;
&lt;p&gt;EDA: process of visualizing and exploring a dataset -&amp;gt; to get an intuition to a given business problem. Crucial part of building any data product&lt;/p&gt;

&lt;h2 id=&quot;stand-on-the-shoulders-of-giants&quot;&gt;Stand on the Shoulders of giants&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Reproduce existing results&lt;/li&gt;
  &lt;li&gt;Build on top of them&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;to-make-regular-progress-start-simple&quot;&gt;To make regular progress: start simple&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Start with the simplest model that could address your requirements&lt;/li&gt;
  &lt;li&gt;Build an end-to-end prototype including this model&lt;/li&gt;
  &lt;li&gt;Judge its performance: optimization metrics and product goal&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Looking at the performance of a simple model on an initial dataset is the best way to decide what task should be tackled next&lt;/p&gt;

&lt;h2 id=&quot;diagnose-problems&quot;&gt;Diagnose Problems&lt;/h2&gt;
&lt;p&gt;Write analysis and exploration functions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Visualize examples the model performs the best and worst on&lt;/li&gt;
  &lt;li&gt;Explore data&lt;/li&gt;
  &lt;li&gt;Explore model results&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;part-ii-build-a-working-pipeline&quot;&gt;Part II. Build a Working Pipeline&lt;/h1&gt;

&lt;h1 id=&quot;ch3-build-your-first-end-to-end-pipeline&quot;&gt;Ch3. Build your first end-to-end pipeline&lt;/h1&gt;
&lt;p&gt;First iteration: lackluster by design. Goal: allow us to have all the pieces of a pipeline in place:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;prioritize which ones to improve next&lt;/li&gt;
  &lt;li&gt;identify the impact bottleneck&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Frequently, your product is dead even if your model is successful” - Monica Rogati&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;test-your-workflow&quot;&gt;Test your workflow&lt;/h2&gt;
&lt;p&gt;Evaluate:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;usefulness of the current user experience&lt;/li&gt;
  &lt;li&gt;results of your handcrafted model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;finding-the-impact-bottleneck&quot;&gt;Finding the impact bottleneck&lt;/h2&gt;
&lt;p&gt;Next challenge to tackle next:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;iterating on the way we present results to the users or;&lt;/li&gt;
  &lt;li&gt;improving model performance by identifying key failure points&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch4-acquire-an-initial-dataset&quot;&gt;Ch4. Acquire an initial dataset&lt;/h1&gt;
&lt;p&gt;Understanding your data well leads to the biggest performance improvements&lt;/p&gt;

&lt;h2 id=&quot;iterate-on-datasets&quot;&gt;Iterate on datasets&lt;/h2&gt;
&lt;p&gt;Data gathering, preparation and labeling should be seen as an iterative process, just like modeling&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ML engineering&lt;/strong&gt;: engineering + ML = products&lt;/p&gt;

&lt;p&gt;Choosing an initial dataset, regularly updating it, and augmenting it is the majority of the work&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data&lt;/strong&gt;: best source of inspiration to develop new models and the first place to look for answers when things go wrong&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Models only serve as a way to extract trends and patterns from existing data. Don’t overestimate the impact of working on the model and underestimate the value of working on the data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Before noticing predictive trends, start by examining &lt;strong&gt;quality&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-quality-rubric&quot;&gt;Data quality rubric&lt;/h2&gt;

&lt;h3 id=&quot;format&quot;&gt;Format&lt;/h3&gt;
&lt;p&gt;Validate that you understand the way in which the data was processed&lt;/p&gt;

&lt;h3 id=&quot;quality&quot;&gt;Quality&lt;/h3&gt;
&lt;p&gt;Notice the quality &lt;strong&gt;ahead of time&lt;/strong&gt; -&amp;gt; missing labels, weak labels&lt;/p&gt;

&lt;h3 id=&quot;quantity-and-distribution&quot;&gt;Quantity and distribution&lt;/h3&gt;
&lt;p&gt;Estimate:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;enough data?&lt;/li&gt;
  &lt;li&gt;feature values are within reasonable range?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary-statistics&quot;&gt;Summary statistics&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Identifying differences in distributions between classes of data early: will either make our modeling task easier or prevent us from overestimating the performance of a model that may just be leveraging one particularly informative feature.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;data-leakage&quot;&gt;Data leakage&lt;/h3&gt;
&lt;p&gt;Using training and validation data for vectorizing/preprocessing can cause data leakage -&amp;gt; leveraging info from outside the training set to create training features&lt;/p&gt;

&lt;h2 id=&quot;clustering&quot;&gt;Clustering&lt;/h2&gt;
&lt;p&gt;As with dimensionality reduction: additional way to surface issues and interesting data points&lt;/p&gt;

&lt;h2 id=&quot;let-data-inform-features-and-models&quot;&gt;Let data inform features and models&lt;/h2&gt;
&lt;p&gt;The more data you have and the less noisy your data is, the less feature engineering work you usually have to do&lt;/p&gt;

&lt;h3 id=&quot;feature-crosses&quot;&gt;Feature crosses&lt;/h3&gt;
&lt;p&gt;Feature generated by multiplying (crossing) two or more features -&amp;gt; nonlinear combination of features -&amp;gt; allows our model to discriminate more easily&lt;/p&gt;

&lt;h3 id=&quot;giving-your-model-the-answer&quot;&gt;Giving your model the answer&lt;/h3&gt;
&lt;p&gt;New binary feature that takes a nonzero value only when relevant combination of values appear&lt;/p&gt;

&lt;h2 id=&quot;robert-munro-how-do-you-find-label-and-leverage-data&quot;&gt;Robert Munro: how do you find, label and leverage data&lt;/h2&gt;

&lt;h3 id=&quot;uncertainty-sampling&quot;&gt;Uncertainty sampling&lt;/h3&gt;
&lt;p&gt;Identify examples that your model is most uncertain about and find similar examples to add to the training set&lt;/p&gt;

&lt;h3 id=&quot;error-model&quot;&gt;“Error model”&lt;/h3&gt;
&lt;p&gt;Use the mistakes your model makes as labels: “predicted correctly” or “predicted incorrectly”. Use the trained error model on unlabeled data and label the examples that it predicts your model will fail on&lt;/p&gt;

&lt;h3 id=&quot;labeling-model&quot;&gt;“Labeling model”&lt;/h3&gt;
&lt;p&gt;To find the best examples to label next. Identify data points that are most different from what you’ve already labeled and label those&lt;/p&gt;

&lt;h3 id=&quot;validation&quot;&gt;Validation&lt;/h3&gt;
&lt;p&gt;While you should use strategies to gather data, you should always randomly sample from your test set to validate your model&lt;/p&gt;

&lt;h1 id=&quot;part-iii-iterate-on-models&quot;&gt;Part III. Iterate on Models&lt;/h1&gt;

&lt;h1 id=&quot;ch5-train-and-evaluate-your-model&quot;&gt;Ch5. Train and evaluate your model&lt;/h1&gt;

&lt;h2 id=&quot;the-simplest-appropriate-model&quot;&gt;The simplest appropriate model&lt;/h2&gt;
&lt;p&gt;Not the best approach: try every possible model, benchmark and pick the one with the best results on a test set&lt;/p&gt;

&lt;h3 id=&quot;simple-model&quot;&gt;Simple model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Quick to implement: won’t be your last&lt;/li&gt;
  &lt;li&gt;Understandable: debug easily&lt;/li&gt;
  &lt;li&gt;Deployable: fundamental requirement for a ML-powered application&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Model explainability and interpretability: ability for a model to expose reasons that caused it to make predictions&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;test-set&quot;&gt;Test set&lt;/h2&gt;
&lt;p&gt;“While using a test set is a best practice, practitioners sometimes use the validation set as a test set. This increases the risk of biasing a model toward the validation set but can be appropriate when running only a few experiments”&lt;/p&gt;

&lt;h2 id=&quot;data-leakage-1&quot;&gt;Data leakage&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Temporal data leakage&lt;/li&gt;
  &lt;li&gt;Sample contamination&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Always investigate the results of a model, especially if it shows surprisingly strong performance&lt;/p&gt;

&lt;h2 id=&quot;bias-variance-trade-off&quot;&gt;Bias variance trade-off&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Underfitting: weak performance on the training set = high bias&lt;/li&gt;
  &lt;li&gt;Overfitting: strong performance on the training set, but weak performance on the validation set = high variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluate-your-model-look-beyond-accuracy&quot;&gt;Evaluate your model: look beyond accuracy&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Contrast data and predictions&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Confusion matrix&lt;/strong&gt;: see whether our model is particularly successful on certain classes and struggles on some others&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ROC Curve&lt;/strong&gt;: plot a threshold on it to have a more concrete goal than simply getting the largest AUC score&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Calibration Curve&lt;/strong&gt;: whether our model’s outputed probability represents its confidence well. Shows the fraction of true positive examples as a function of the confidence of our classifier&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dimensionality reduction for errors&lt;/strong&gt;: identify a region in which a model performs poorly and visualize a few data points in it&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The top-k method&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;k best performing examples&lt;/strong&gt;: identify features that are successfully leveraged by a model&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;k worst performing examples&lt;/strong&gt;: on train: identify trends in data the model fails on, identify additional features that would make them easier for a model. On validation: identify examples that significantly differ from the train data&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;k most uncertain examples&lt;/strong&gt;: on train: often a symptom of conflicting labels. On validation: can help find gaps in your training data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Top-k implementation: &lt;a href=&quot;https://github.com/hundredblocks/ml-powered-applications/blob/master/ml_editor/model_evaluation.py#L250-L295&quot;&gt;book’s Github repository&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;evaluate-feature-importance&quot;&gt;Evaluate Feature Importance&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Eliminate or iterate on features that are currently not helping the model&lt;/li&gt;
  &lt;li&gt;Identify features that are suspiciously predictive, which is often a sign of data leakage&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;black-box-explainers&quot;&gt;Black-box explainers&lt;/h2&gt;
&lt;p&gt;Attempt to explain a model’s predictions independently of its inner workings, i.e. LIME and SHAP&lt;/p&gt;

&lt;h1 id=&quot;ch6-debug-your-ml-problems&quot;&gt;Ch6. Debug your ML problems&lt;/h1&gt;

&lt;h2 id=&quot;software-best-practices&quot;&gt;Software Best Practices&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;KISS principle&lt;/strong&gt;: building only what you need&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Most software applications: strong test coverage = high confidence app is functioning well. ML pipelines can pass many tests, but still give entirely incorrect results. Doesn’t have just to run, it should produce accurate predictive outputs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Progressive approach, validate:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Data flow&lt;/li&gt;
  &lt;li&gt;Learning capacity&lt;/li&gt;
  &lt;li&gt;Generalization and inference&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Make sure your pipeline works for a few examples, then write tests to make sure it keeps functioning as you make changes&lt;/p&gt;

&lt;h2 id=&quot;visualization-steps&quot;&gt;Visualization steps&lt;/h2&gt;
&lt;p&gt;Inspect changes at regular intervals&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data loading&lt;/strong&gt;: Verify data is formatted correctly&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cleaning and feature selection&lt;/strong&gt;: remove any unnecessary information&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Feature generation&lt;/strong&gt;: check that the feature values are populated and that the values seem reasonable&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data formatting&lt;/strong&gt;: shapes, vectors&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Model output&lt;/strong&gt;: first look if the predictions are the right type or shape, then check if the model is actually leveraging the input data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;separate-your-concerns&quot;&gt;Separate your concerns&lt;/h2&gt;
&lt;p&gt;Modular organization: separate each function so that you can check that it individually works before looking at the broader pipeline. Once broken down, you’ll be able to write tests&lt;/p&gt;

&lt;h2 id=&quot;test-your-ml-code&quot;&gt;Test your ML code&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hundredblocks/ml-powered-applications/tree/master/tests&quot;&gt;Source code on book’s Github repository&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Test data ingestion&lt;/li&gt;
  &lt;li&gt;Test data processing&lt;/li&gt;
  &lt;li&gt;Test model outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;debug-training-make-your-model-learn&quot;&gt;Debug training: make your model learn&lt;/h2&gt;
&lt;p&gt;Contextualize model performance: generate an estimate of what an acceptable error for the taks is by labeling a few examples yourself&lt;/p&gt;

&lt;h3 id=&quot;task-difficulty&quot;&gt;Task difficulty&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;The quantity and diversity of data you have&lt;/strong&gt;: more diverse/complex the problem = more data for the model to learn from it&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;How predictive the features are&lt;/strong&gt;: make the data more expressive to help the model learn better&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The complexity of your model&lt;/strong&gt;: simplest model is good to quickly iterate, but some tasks are entirely out of reach of some models&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;debug-generalization-make-your-model-useful&quot;&gt;Debug generalization: make your model useful&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Leakage&lt;/strong&gt;: if you are surprised by validation performance, inspect the features; fixing a leakage issue will lead to lower validation performance, but a better model&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt;: model performs drastically better on the training set than on the test set. Add regularization or data augmentation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dataset redesign&lt;/strong&gt;: use k-fold cross validation to alleviate concerns that data splits may be of unequal quality&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“If your models aren’t generalizing, your task may be too hard. There may not be enough information in your training examples to learn meaningful features that will be informative for future data points. If that is the case, then the problem you have is not well suited for ML”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch7-using-classifiers-for-writing-recommendations&quot;&gt;Ch7. Using classifiers for writing recommendations&lt;/h1&gt;

&lt;h1 id=&quot;part-iv-deploy-and-monitor&quot;&gt;Part IV. Deploy and Monitor&lt;/h1&gt;
&lt;p&gt;Production ML pipelines need to be able to detect data and model failures and handle them with grace -&amp;gt; &lt;strong&gt;proactively&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch8-considerations-when-deploying-models&quot;&gt;Ch8. Considerations when deploying models&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;How was the data you are using collected?&lt;/li&gt;
  &lt;li&gt;What assumptions is your model making by learning from this dataset?&lt;/li&gt;
  &lt;li&gt;Is this dataset representative enough to produce a useful model?&lt;/li&gt;
  &lt;li&gt;How could the results of your work be misused?&lt;/li&gt;
  &lt;li&gt;What is the intended use and scope of your model?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-concerns&quot;&gt;Data Concerns&lt;/h2&gt;

&lt;h3 id=&quot;data-ownership&quot;&gt;Data ownership&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Collection&lt;/li&gt;
  &lt;li&gt;Usage and permission&lt;/li&gt;
  &lt;li&gt;Storage&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-bias&quot;&gt;Data bias&lt;/h3&gt;
&lt;p&gt;Datasets: results of specific data collection decisions -&amp;gt; lead to datasets presenting a biased view of the world. ML models learn from datasets -&amp;gt; will reproduce these biases&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Measurement errors or corrupted data&lt;/li&gt;
  &lt;li&gt;Representation&lt;/li&gt;
  &lt;li&gt;Access&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;test-sets&quot;&gt;Test sets&lt;/h4&gt;
&lt;p&gt;Build a test set that is inclusive, representative, and realistic -&amp;gt; proxy for performance in production -&amp;gt; improve the chances that every user has an equally positive experience&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Models are trained on historical data -&amp;gt; state of the world in the past. Bias most often affects populations that are already disenfranchised. Working to eliminate bias -&amp;gt; help make systems fairer for the people who need it most&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;modeling-concerns&quot;&gt;Modeling Concerns&lt;/h2&gt;

&lt;h3 id=&quot;feedback-loops&quot;&gt;Feedback loops&lt;/h3&gt;
&lt;p&gt;User follow a model’s recommendation -&amp;gt; future models make the same recommendation -&amp;gt; models enter a self-reinforcing feedback loop&lt;/p&gt;

&lt;p&gt;To limit negative effects of feedback loops -&amp;gt; choose a label that is less prone to creating such a loop&lt;/p&gt;

&lt;h3 id=&quot;inclusive-model-performance&quot;&gt;Inclusive model performance&lt;/h3&gt;
&lt;p&gt;Look for performance on a segment of the data, instead of only comparing aggregate performance&lt;/p&gt;

&lt;h3 id=&quot;adversaries&quot;&gt;Adversaries&lt;/h3&gt;
&lt;p&gt;Regularly update models&lt;/p&gt;

&lt;p&gt;Some types of attacks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fool models into a wrong prediction (most common)&lt;/li&gt;
  &lt;li&gt;Use a trained model to learn about the data it was trained on&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;chris-harland-shipping-experiments&quot;&gt;Chris Harland: Shipping Experiments&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;When giving advice, the cost of being wrong is very high, so precision is the most useful&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch9-choose-your-deployment-option&quot;&gt;Ch9. Choose Your Deployment Option&lt;/h1&gt;

&lt;h2 id=&quot;server-side-deployment&quot;&gt;Server-side deployment&lt;/h2&gt;
&lt;p&gt;Setting up a web server that can accept requests from clients, run them through an inference pipeline, and return the results. The servers represents a central failure point for the application and can be costly if the product becomes popular&lt;/p&gt;

&lt;h3 id=&quot;streaming-api-workflow&quot;&gt;Streaming API workflow&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Endpoint approach&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quick to implement&lt;/li&gt;
  &lt;li&gt;Requires infrastructure to scale linearly with the current number of users (1 user = 1 separate inference call)&lt;/li&gt;
  &lt;li&gt;Required when strong latency constraints exist (info the model needs is available only at prediction time and model’s prediction is required immediately)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;batch-predictions&quot;&gt;Batch Predictions&lt;/h3&gt;
&lt;p&gt;Inference pipeline as a job that can be run on multiple examples at once. Store predictions so they can be used when needed&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Appropriate when you have access to the features need for a model before the model’s prediction is required&lt;/li&gt;
  &lt;li&gt;Easier to allocate and parallelize resources&lt;/li&gt;
  &lt;li&gt;Faster at inference time since results have been precomputed and only need to be retrieved (similar gains to caching)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hybrid-approach&quot;&gt;Hybrid Approach&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Precompute as many cases as possible&lt;/li&gt;
  &lt;li&gt;At inference either retrieve precomputed results or compute them on the spot if they are not available or are outdated&lt;/li&gt;
  &lt;li&gt;Have to maintain both a batch and streaming pipeline (more complexity of the system)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;client-side-deployment&quot;&gt;Client-side deployment&lt;/h2&gt;
&lt;p&gt;Run all computations on the client, eliminating the need for a server to run models. Models are still trained in the same manner and are sent to the device for inference&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reduces the need to build infra&lt;/li&gt;
  &lt;li&gt;Reduces the quantity of data that needs to be transferred between the device and the server
    &lt;ul&gt;
      &lt;li&gt;Reduces network latency (app may even run without internet)&lt;/li&gt;
      &lt;li&gt;Removes the need for sensitive information to be transferred to a remote server&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;If the time it would take to run inference on device is larger than the time it would take to transmit data to the server to be processed, consider running your model in the cloud&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On-device deployment is only worthwhile if the latency, infrastructure, and privacy benefits are valuable enough to invest the engineering effort (simplifying a model)&lt;/p&gt;

&lt;h2 id=&quot;browser-side&quot;&gt;Browser side&lt;/h2&gt;
&lt;p&gt;Some libraries use browsers to have the client perform ML tasks&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Tensorflow.js&lt;/code&gt;: train and run inference in JavaScript in the browser for most differentiable models, even trained in different languages such as Python&lt;/p&gt;

&lt;h2 id=&quot;federated-learning-a-hybrid-apporach&quot;&gt;Federated Learning: a hybrid apporach&lt;/h2&gt;
&lt;p&gt;Each client has their own model. Each model learns from their user’s data and send aggregated (and potentially anonymized) updates to the server. The server leverages all updates to improve its model and distills this new model back to individual clients. Each user receives a model personalized to their needs, while still benefiting from aggregate information about other users&lt;/p&gt;

&lt;h1 id=&quot;ch10-build-safeguards-for-models&quot;&gt;Ch10. Build Safeguards for Models&lt;/h1&gt;
&lt;p&gt;No matter how good a model is, it will fail on some examples -&amp;gt; engineer a system that can gracefully handle such features&lt;/p&gt;

&lt;h2 id=&quot;check-inputs&quot;&gt;Check inputs&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Very different data from train&lt;/li&gt;
  &lt;li&gt;Some features missing&lt;/li&gt;
  &lt;li&gt;Unexpected types&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Input checks are part of the pipeline -&amp;gt; change the control flow of a program based on the quality of inputs&lt;/p&gt;

&lt;h2 id=&quot;model-outputs&quot;&gt;Model outputs&lt;/h2&gt;
&lt;p&gt;Prediction falls outside an acceptable range -&amp;gt; consider not displaying it&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Acceptable outcome: not only if the outcome is plausible -&amp;gt; also depends if the outcome would be &lt;strong&gt;useful for the user&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;model-failure-fallbacks&quot;&gt;Model failure fallbacks&lt;/h2&gt;
&lt;p&gt;Flag cases that are too hard and encourage user to provide an easier input (e.g. well-lit photo)&lt;/p&gt;

&lt;p&gt;Detecting errors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Track the confidence of a model&lt;/li&gt;
  &lt;li&gt;Build an additional model tasked with detecting examples a main model is likely to fail on&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;filtering-model&quot;&gt;Filtering model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ML version of input tests&lt;/li&gt;
  &lt;li&gt;Binary classifier&lt;/li&gt;
  &lt;li&gt;Estimate how well a model will perform on an example without running the model on it&lt;/li&gt;
  &lt;li&gt;Decrease the likelihood of poor results and improve resource usage&lt;/li&gt;
  &lt;li&gt;Catch:
    &lt;ul&gt;
      &lt;li&gt;qualitatively different inputs&lt;/li&gt;
      &lt;li&gt;inputs the model struggled&lt;/li&gt;
      &lt;li&gt;adversarial inputs meant to fool the model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Minimum criteria:
    &lt;ul&gt;
      &lt;li&gt;should be fast (reduce the computational burden)&lt;/li&gt;
      &lt;li&gt;should be good at eliminating hard cases&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The faster your filtering model is, the less effective it needs to be&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;engineer-for-performance&quot;&gt;Engineer for Performance&lt;/h2&gt;
&lt;h3 id=&quot;scale-to-multiple-users&quot;&gt;Scale to multiple users&lt;/h3&gt;
&lt;p&gt;ML is horizontally scalable = more servers = keep response time reasonable when the number of requests increases&lt;/p&gt;

&lt;h3 id=&quot;caching-fo-ml&quot;&gt;Caching fo ML&lt;/h3&gt;
&lt;p&gt;Storing results to function calls -&amp;gt; future calls with same parameters simply retrieve the stored results&lt;/p&gt;

&lt;h4 id=&quot;caching-inference-results&quot;&gt;Caching inference results&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Least recently used (LRU) cache&lt;/strong&gt;: keep track the most recent inputs to a model and their corresponding outputs&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;not appropriate if each input is unique&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;functools&lt;/code&gt; Python module proposes a default implementation of an LRU cache that you can use with a simple decorator&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
from functools import lru_cache

@lru_cache(maxsize=128)
def run_model(data):
  # Insert slow model inference below
  pass

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;caching-by-indexing&quot;&gt;Caching by indexing&lt;/h4&gt;
&lt;p&gt;Cache other aspects of the pipeline that can be precomputed. Easy if a model does not only rely on user inputs&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Caching can improve performance, but it adds a layer of complexity. The size of the cache becomes an additional hyperparameter to tune depending on your application’s workload. In addition, any time a model or the underlying data is updated, the cache needs to be cleared in order to prevent it from serving outdated results”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;model-and-data-life-cycle-management&quot;&gt;Model and data life cycle management&lt;/h2&gt;
&lt;p&gt;ML application:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;produces reproducible results&lt;/li&gt;
  &lt;li&gt;is resilient to model updates&lt;/li&gt;
  &lt;li&gt;is flexible enough to handle significant modelling and data processing changes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reproducibility&quot;&gt;Reproducibility&lt;/h3&gt;
&lt;p&gt;Each model/dataset pair should be assigned an unique identifier -&amp;gt; should be logged each time a model is used in production&lt;/p&gt;

&lt;h3 id=&quot;resilience&quot;&gt;Resilience&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;production pipeline should aim to update models without significant downtime&lt;/li&gt;
  &lt;li&gt;if a new model performs poorly, we’d like to be able to roll back to the previous one&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-processing-and-dags&quot;&gt;Data Processing and DAGs&lt;/h2&gt;
&lt;p&gt;Directed acyclic graph (DAG): can be used to represent our process of going from raw data to trained model -&amp;gt; each node represent a processing step and each step represent a dependency between two nodes&lt;/p&gt;

&lt;p&gt;DAGs helps systematize, debug, and version a pipeline -&amp;gt; can become a crucial time saver&lt;/p&gt;

&lt;h2 id=&quot;ask-for-feedback&quot;&gt;Ask for feedback&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Explicity asking for feedback (display model’s prediction accompanying it with a way for users to judge and correct a prediction)&lt;/li&gt;
  &lt;li&gt;Measuring implicit signals&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;User feedback is a good source of training data and can be the first way to notice a degradation in performance&lt;/p&gt;

&lt;h2 id=&quot;chris-moody-empowering-data-scientist-to-deploy-models&quot;&gt;Chris Moody: Empowering Data Scientist to Deploy Models&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Make humans and algorithms work together: spend time thinking about the right way to present information&lt;/li&gt;
  &lt;li&gt;Canary development -&amp;gt; start deploying the new version to one instance and progressively update instances while monitoring performance&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Ownership of the entire pipeline leads individuals to optimize for impact and reliability, rather than model complexity”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch11-monitor-and-update-models&quot;&gt;Ch11. Monitor and update models&lt;/h1&gt;
&lt;h2 id=&quot;monitoring-saves-lives&quot;&gt;Monitoring saves lives&lt;/h2&gt;
&lt;p&gt;Monitoring: track the health of a system. For models: performance and quality of their predictions&lt;/p&gt;

&lt;h3 id=&quot;monitor-to-inform-refresh-rate&quot;&gt;Monitor to inform refresh rate&lt;/h3&gt;
&lt;p&gt;Detect when a model is not fresh anymore and needs to be retrained. Retraining events happen when accuracy dips below a threshold.&lt;/p&gt;

&lt;h3 id=&quot;monitor-to-detect-abuse&quot;&gt;Monitor to detect abuse&lt;/h3&gt;
&lt;p&gt;Anomaly detection to detect attacks&lt;/p&gt;

&lt;h2 id=&quot;choose-what-to-monitor&quot;&gt;Choose what to monitor&lt;/h2&gt;
&lt;p&gt;Commonly monitor metrics such as the average time it takes to process a request, the proportion of requests that fail to be processed, and the amount of available resources&lt;/p&gt;

&lt;h3 id=&quot;performance-metrics&quot;&gt;Performance Metrics&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Track changes in the input distribution (&lt;em&gt;feature drift&lt;/em&gt;)&lt;/li&gt;
  &lt;li&gt;Monitor the input distribution (summary statistics)&lt;/li&gt;
  &lt;li&gt;Monitor distribution shifts&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Conterfactual evaluation&lt;/strong&gt;: aims to evaluate what would have happened if we hadn’t actioned a model -&amp;gt; Not acting on a random subset of examples allow us to observe an unbiased distribution of the positive class. Comparing model predictions to true outcomes for the random data, we can begin to estimate a model’s precision and recall&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;business-metrics&quot;&gt;Business metrics&lt;/h3&gt;
&lt;p&gt;Product metrics should be closely monitored&lt;/p&gt;

&lt;h2 id=&quot;cicd-for-ml&quot;&gt;CI/CD for ML&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CI&lt;/strong&gt;: letting multiple developers regularly merge their code back into a central codebase&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CD&lt;/strong&gt;: improving the speed at which new versions of software can be released&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CI/CD for ML: make it easier to deploy new models or update existing ones&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Releasing updates quickly is easy; the challenge comes in guaranteeing their quality (…) There is no substitute for live performance to judge the quality of a model”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Shadow mode&lt;/strong&gt;: deploying a new model in parallel to an existing one. When running inference, both models’ predictions are computed and stored, but the application only uses the prediction of the existing model&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;estimate a new models’ performance in a production environment without changing the user experience&lt;/li&gt;
  &lt;li&gt;test the infrastructure required to run inference for a new model (may be more complex)&lt;/li&gt;
  &lt;li&gt;but can’t observe the user’s response to the new model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ab-testing-and-experimentation&quot;&gt;A/B Testing and Experimentation&lt;/h2&gt;
&lt;p&gt;Goal: maximize chances of using the best model, while minimizing the cost of trying out suboptimal models&lt;/p&gt;

&lt;p&gt;Expose a sample of users to a new model, and the rest to another. Larger control group (current model) and a smaller treatment group (new version we want to test). Run for a sufficient amount of time -&amp;gt; compare the results for both groups and choose the better model&lt;/p&gt;

&lt;h3 id=&quot;choosing-groups-and-duration&quot;&gt;Choosing groups and duration&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Users in both groups should be as similar as possible -&amp;gt; any difference in outcome = our model and not difference in cohorts&lt;/li&gt;
  &lt;li&gt;Treatment group should be:
    &lt;ul&gt;
      &lt;li&gt;large enough: statistically meaningful conclusion&lt;/li&gt;
      &lt;li&gt;small as possible: limit exposure to a potentially worse model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Duration of the test:
    &lt;ul&gt;
      &lt;li&gt;too short: not enough information&lt;/li&gt;
      &lt;li&gt;too long: risk losing users&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;estimating-the-better-variant&quot;&gt;Estimating the better variant&lt;/h3&gt;
&lt;p&gt;Decide on the size of each group and the length of the experiment before running it&lt;/p&gt;

&lt;h3 id=&quot;building-the-infrastructure&quot;&gt;Building the infrastructure&lt;/h3&gt;
&lt;p&gt;Branching logic: decides which model to run depending on a given field’s value (harder if a model is accessible to logged-out users)&lt;/p&gt;

&lt;h2 id=&quot;other-approaches&quot;&gt;Other approaches&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Multiarmed bandits&lt;/strong&gt;: more flexible approach, can test variants continually and on more than two alternatives. Dynamically update which model to serve based on how well each option in performing&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contextual multiarmed bandits&lt;/strong&gt;: go even further, by learning which model is a better option for each particular user&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The majority of work involved with building ML products consists of data and engineering work”&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/build_ml_app/build_ml_app.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/build_ml_app/build_ml_app.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Leadership Strategy and Tactics: Field Manual</title><link href="https://millengustavo.github.io/blog/book/leadership/management/2020/03/17/leadership.html" rel="alternate" type="text/html" title="Leadership Strategy and Tactics: Field Manual" /><published>2020-03-17T00:00:00-05:00</published><updated>2020-03-17T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/leadership/management/2020/03/17/leadership</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/leadership/management/2020/03/17/leadership.html">&lt;blockquote&gt;
  &lt;p&gt;What makes leadership so hard is dealing with people, and people are crazy. And the craziest person a leader has to deal with is themselves.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Those are the notes I took when reading the book “Leadership Strategy and Tactics: Field Manual” by Jocko Willink. I recommend reading the book for a more coherent view of the context in which each note is inserted.&lt;/p&gt;

&lt;h1 id=&quot;first-platoon-detach&quot;&gt;First Platoon: Detach&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Pay attention to yourself and what is happening around you.&lt;/li&gt;
  &lt;li&gt;Avoid being fully absorbed in the minute details of any situation.&lt;/li&gt;
  &lt;li&gt;Stay aware, check yourself, avoid getting tunnel vision.&lt;/li&gt;
  &lt;li&gt;Put the team and the mission above yourself.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Prioritize and Execute&lt;/strong&gt;. The most impactful task or the biggest problem must be addressed first&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Extreme Ownership&lt;/strong&gt; is a mind-set of not making excuses and not blaming anyone or anything else when problems occur.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Dichotomy of Leadership&lt;/strong&gt; describes opposing forces that are pulling leaders in contradictory directions at the same time. To lead properly, a leader must be balanced&lt;/li&gt;
  &lt;li&gt;Leadership requires relationships. The better the relationships, the more open and effective communication there is. The more communication there is, the stronger the team will be.&lt;/li&gt;
  &lt;li&gt;Communicate ideas in a simple, clear manner&lt;/li&gt;
  &lt;li&gt;Look people in the eye when talking to them, listen intently to what others say, and speak clearly with humble authority.&lt;/li&gt;
  &lt;li&gt;Pay attention to body language, facial expressions, and tone of voice.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“There is one type of person who can never become a good leader: a person who lacks humility. People who lack humility cannot improve because they don’t acknowledge their own weaknesses.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The good of the mission and the good of the team outweigh any personal concern a true leader has for themselves.&lt;/li&gt;
  &lt;li&gt;Good leaders do the right things for the right reasons; they work hard, support the team, and lead solid execution.&lt;/li&gt;
  &lt;li&gt;Ego is like reactive armor; the harder you push against it, the more it pushes back.&lt;/li&gt;
  &lt;li&gt;Subordinating your ego is actually the ultimate form of self-confidence. That level of confidence earns respect.&lt;/li&gt;
  &lt;li&gt;Communicate often so the bad news will sting less.&lt;/li&gt;
  &lt;li&gt;Lead from the front, especially when things are bad. As a leader, do the hard things. Don’t leave it to the troops.&lt;/li&gt;
  &lt;li&gt;Most criticism is best delivered indirectly, with the minimal amount of negativity needed to get the desired change.&lt;/li&gt;
  &lt;li&gt;A leader must be constantly improving and learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;core-tenets&quot;&gt;Core Tenets&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;If you need help with something, ask for it. Subordinates understand that their leaders might not know everything.&lt;/li&gt;
  &lt;li&gt;If you want to have influence over others, you need to allow them to have influence over you.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Preemptive ownership&lt;/strong&gt;: take ownership of things to prevent problems from unfolding in the first place&lt;/li&gt;
  &lt;li&gt;People tend to shy away from suffering; they will procrastinate and avoid getting started. But when the leader jumps in and starts attacking the job, others will jump in and get started as well.&lt;/li&gt;
  &lt;li&gt;The best ideas often come from the people on the team who are closest to the problem; those are the folks on the front line. Take a step back and let your team lead.&lt;/li&gt;
  &lt;li&gt;Overreaction is always bad.&lt;/li&gt;
  &lt;li&gt;Relationships do not mean preferential treatment.&lt;/li&gt;
  &lt;li&gt;Before diving into a problem: How will this problem impact the team’s strategic goals? Can it cause mission failure? Is it worth my time and effort to engage in it? How bad can it get if I leave it alone?&lt;/li&gt;
  &lt;li&gt;The goal is always to allow problems to get solved at the lowest level. When subordinates are solving low-level problems, it allows the leader to focus on more important, strategic issues.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;principles&quot;&gt;Principles&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Every person’s job is absolutely critical. Explain to them what happens if they don’t do their jobs well. How their jobs fit into the big picture and the strategic mission.&lt;/li&gt;
  &lt;li&gt;If you really want to take care of your people, you need to push them. You need to make sure they understand their jobs. You need to drive them toward their goals.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The easy path leads to misery. The path of discipline leads to freedom.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Optimal discipline in a team is not imposed by the leader; it is chosen by the team itself. Optimal discipline is self-discipline&lt;/li&gt;
  &lt;li&gt;A leader doesn’t have to constantly police infractions and motivate them to give their best; if there is pride, the team polices itself.&lt;/li&gt;
  &lt;li&gt;To build pride within a team, you have to put the members in situations that require unity, strength, and perseverance to get through.&lt;/li&gt;
  &lt;li&gt;No pride is built on easy wins, but a team has to win some to have some pride&lt;/li&gt;
  &lt;li&gt;Encourage the rest of your team to think and to question you. Don’t surround yourself with yes-men. They do nothing to help you or the team.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“There are no situations and no exceptions where a subordinate is ultimately responsible for the performance of a team. It is always the leader’s fault. The exception is that it is possible to have a good team that delivers outstanding performance despite a bad leader.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;becoming-a-leader&quot;&gt;Becoming a Leader&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Don’t make being chosen as a leader your goal. Instead, make your goal helping the team win.&lt;/li&gt;
  &lt;li&gt;Lack of preparation shows the team you don’t really care. So stay humble, study, ask questions, learn, and balance the dichotomy between too much humility and too much confidence.&lt;/li&gt;
  &lt;li&gt;Don’t be the leader with your hands in your pockets, but don’t be the leader with your hands in everything.&lt;/li&gt;
  &lt;li&gt;Don’t change things that are working, but don’t accept things that are not working&lt;/li&gt;
  &lt;li&gt;In everyday situations, overt leadership is not needed. It is better to give subtle direction and let the troops move forward based on their own ideas.&lt;/li&gt;
  &lt;li&gt;The best leaders usually led not by orders but by suggestion.&lt;/li&gt;
  &lt;li&gt;Indirect leadership almost always trumps direct leadership.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;leadership-skills&quot;&gt;Leadership Skills&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;“It was always safe to assume that when different people had different ideas, the idea that people liked the best was almost always their own.”&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Be decisive when you need to be, but try not to make decisions until you have to. Make smaller decisions with minimum commitment to move in the direction you most highly suspect is the right one.&lt;/li&gt;
    &lt;li&gt;Prevent giving your troops the impression that your delegation is avoidance of hard work is to take on some of the harshest jobs yourself. Do some of the nasty work.&lt;/li&gt;
    &lt;li&gt;Don’t alienate yourself from the group. Become part of it and earn your influence. This is the opposite of having an aggressive attitude and attacking the group’s beliefs head-on&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;maneuvers&quot;&gt;Maneuvers&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;One of the best tools a leader has to help shape others is leadership itself; giving people responsibility and putting them in leadership positions teaches them to be better in a multitude of ways.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Life is the ultimate teacher of humility. If a person lives long enough and takes on true challenges, eventually they will get humbled.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The medicine for a lack of confidence is very similar to the medicine for overconfidence: put the individual in charge.&lt;/li&gt;
  &lt;li&gt;Micromanagement is a tool, but it is not a permanent solution. Use it, but know when it has reached its limitations, and then remove or replace personnel to fix the problem.&lt;/li&gt;
  &lt;li&gt;It is always good to support your leader. If you undermine a leader, it not only hurts them, it also hurts the morale of the troops as well as you as a subordinate leader.&lt;/li&gt;
  &lt;li&gt;The best way to treat combat stress—and any stress—is to remove the affected individual from the stress-inducing environment.&lt;/li&gt;
  &lt;li&gt;To punish an individual for the infraction of an unwritten rule is usually inappropriate, unless the behavior is grievous enough that any reasonable person would deem it out of line.&lt;/li&gt;
  &lt;li&gt;No one should be surprised when they receive a punishment, and knowing what they are risking in terms of punishment will eliminate much of the need for it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;communication&quot;&gt;Communication&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;In any leadership situation, it is critical for the leader to keep everyone on the team as informed as possible.&lt;/li&gt;
  &lt;li&gt;You have to be proactive in updating your troops.&lt;/li&gt;
  &lt;li&gt;Get aggressive and attack rumors by getting ahead of the bad news and telling your team what is going on. Be truthful, be direct, and be timely.&lt;/li&gt;
  &lt;li&gt;Explaining why is important. But the why has to tie back and connect to everyone in the chain of command.&lt;/li&gt;
  &lt;li&gt;When delivering criticism, it is important to do it with consideration and delicacy.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“As a leader, you must remember you are being watched. And in everything you do, you must set the example.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Praise should be given when warranted. But it must be given judiciously, and it should be tempered with a goal that requires the team to still push.&lt;/li&gt;
  &lt;li&gt;Praise is a tool, but it is a tool that must be wielded with caution. Too much and it can cause people to let up and rest on their laurels. Too little and the team can lose hope.&lt;/li&gt;
  &lt;li&gt;Ultimatums are not optimal leadership tools. Like digging in, they allow no room to maneuver. No one likes being trapped and controlled.&lt;/li&gt;
  &lt;li&gt;A leader must have control over his or her emotions. Letting emotions drive decisions is a mistake.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reflect and Diminish&lt;/strong&gt; means to reflect the emotions you are seeing from your subordinate but diminish them to a more controlled level.&lt;/li&gt;
  &lt;li&gt;Patience is appreciated and respected much more than a hot temper.&lt;/li&gt;
  &lt;li&gt;The less you talk, the more people listen. Don’t be the person who is always talking. Speak when you need to, but don’t talk just to talk.&lt;/li&gt;
  &lt;li&gt;There is nothing wrong with apologizing when you make a mistake. That is part of taking ownership.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion-it-is-all-on-you-but-not-about-you&quot;&gt;Conclusion: It is All On You, But Not About You&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Leadership is all on you. But at the same time, leadership is not about you. Not at all. Leadership is about the team. The team is more important than you are. The moment you put your own interests above the team and above the mission is the moment you fail as a leader.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference:&lt;/h1&gt;

&lt;p&gt;Willink, Jocko. Leadership Strategy and Tactics: Field Manual. &lt;a href=&quot;https://www.amazon.com/Leadership-Strategy-Tactics-Field-Manual/dp/1250226848&quot;&gt;https://www.amazon.com/Leadership-Strategy-Tactics-Field-Manual/dp/1250226848&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">What makes leadership so hard is dealing with people, and people are crazy. And the craziest person a leader has to deal with is themselves.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/leadership/leadership_book_cover.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/leadership/leadership_book_cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Causal Impact: state-space models in settings where a randomized experiment is unavailable</title><link href="https://millengustavo.github.io/blog/data%20science/machine%20learning/causality/statistics/2020/02/19/causalimpact.html" rel="alternate" type="text/html" title="Causal Impact: state-space models in settings where a randomized experiment is unavailable" /><published>2020-02-19T00:00:00-06:00</published><updated>2020-02-19T00:00:00-06:00</updated><id>https://millengustavo.github.io/blog/data%20science/machine%20learning/causality/statistics/2020/02/19/causalimpact</id><content type="html" xml:base="https://millengustavo.github.io/blog/data%20science/machine%20learning/causality/statistics/2020/02/19/causalimpact.html">&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: There are ways of measuring the causal impact of some business intervention even in scenarios where a randomized experiment is unavailable. In this post we investigated the increase in Google trends popularity index of some search terms caused by different interventions. The same logic can be applied in business contexts such as the impact of a new product launch, the onset of an advertising campaign and other problems in economics, epidemiology, biology among others.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/millengustavo/trends-causal-impact/blob/master/causal-searches.ipynb&quot;&gt;Jupyter notebook with the code for this post&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;At work, you are responsible for making many decisions that can impact aspects of your business in different ways. Most of the time, there are simple approaches to measure the impact of these decisions.&lt;/p&gt;

&lt;p&gt;You launched an advertising campaign and, looking at sales that increased by 5% a month later, concluded that your campaign was a success. Right? Well, did you do a random experiment? Did you consider other factors such as seasonality or sales trend?&lt;/p&gt;

&lt;p&gt;Similar to this scenario, there are a plethora of other cases in which we may be interested in measuring the causal impact of the action.&lt;/p&gt;

&lt;h2 id=&quot;causal-impact-by-google&quot;&gt;Causal Impact by Google&lt;/h2&gt;

&lt;p&gt;There are some complex aspects of infering the causality of an intervention. In 2015 some awesome researchers from Google, published a paper entitled: “&lt;em&gt;INFERRING CAUSAL IMPACT USING BAYESIAN STRUCTURAL TIME-SERIES MODELS&lt;/em&gt;”.&lt;/p&gt;

&lt;p&gt;Along with the paper they also introduced &lt;a href=&quot;https://google.github.io/CausalImpact/CausalImpact.html&quot;&gt;CausalImpact&lt;/a&gt;, an R package (there is also a &lt;a href=&quot;https://github.com/dafiti/causalimpact&quot;&gt;Python port by Dafiti&lt;/a&gt;) that implements their approach. In this tutorial we are going to use the Python version.&lt;/p&gt;

&lt;p&gt;Quoting directly from the abstract of the paper:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;This paper proposes to infer causal impact on the basis of a diffusion-regression state-space model that &lt;strong&gt;predicts the counterfactual market response in a synthetic control that would have occurred had no intervention taken place&lt;/strong&gt;. In contrast to classical difference-in-differences schemes, state-space models make it possible to (i) infer the temporal evolution of attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) flexibly accommodate multiple sources of variation, including local trends, seasonality and the time-varying influence of contemporaneous covariates&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;measuring-the-causal-impact-of-mentioning-an-unusual-term-on-a-popular-brazilian-tv-show&quot;&gt;Measuring the causal impact of mentioning an unusual term on a popular brazilian TV show&lt;/h2&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;
&lt;p&gt;Big Brother Brasil (BBB) is an international TV show that is popular in Brazil and broadcast on prime time open television. One of the participants suggested, live, that another participant search Google for an unusual term that she had spoken. The unusual word was “sororidade” (“sorority”).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.uol.com.br/universa/noticias/redacao/2020/02/11/sororidade-buscas-no-google-crescem-250-apos-fala-de-manu-gavassi-no-bbb.htm&quot;&gt;Many&lt;/a&gt; &lt;a href=&quot;https://www.huffpostbrasil.com/entry/sororidade-manu-gavassi_br_5e442423c5b61b84d3438b88&quot;&gt;media&lt;/a&gt; &lt;a href=&quot;https://emais.estadao.com.br/noticias/tv,bbb-20-buscas-por-sororidade-no-google-sobem-250-apos-fala-de-manu-gavassi,70003193892&quot;&gt;outlets&lt;/a&gt; later reported that the episode caused searches for the term to increase 250%.&lt;/p&gt;

&lt;p&gt;The episode took place on February 9, 2020 between 9 pm and 10 pm Brazilian time.&lt;/p&gt;

&lt;p&gt;Let’s investigate the causality of the intervention in increasing interest in the term based on Google trends.&lt;/p&gt;

&lt;h2 id=&quot;1-gathering-the-data&quot;&gt;1. Gathering the data&lt;/h2&gt;

&lt;p&gt;We are going to download the data from Google Trends.&lt;/p&gt;

&lt;p&gt;There are two main ways of doing this:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We can navigate to the &lt;a href=&quot;https://trends.google.com/trends/?geo=BR&quot;&gt;website&lt;/a&gt; and specify which term we are looking for, the region and timeframe&lt;/li&gt;
  &lt;li&gt;We can do this directly in Python, using a third-party library such as &lt;a href=&quot;https://github.com/GeneralMills/pytrends&quot;&gt;pytrends&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To install &lt;code class=&quot;highlighter-rouge&quot;&gt;pytrends&lt;/code&gt;, switch to your preferred environment and run the command:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;pytrends
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From the presentation of the causal impact, the author of the package suggests that we use between 5 and 10 related time series that can help to model the behavior of our time series of interest.&lt;/p&gt;

&lt;p&gt;Therefore, we are going to download some common Brazilian terms in the same period that may help our Bayesian structural time series model to understand the search behavior of our target term.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pytrends.request&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TrendReq&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pytrends&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TrendReq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pt-BR'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;kw_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sororidade&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;futebol&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;carro&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;temperatura&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;restaurante&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pytrends&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kw_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeframe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2020-02-06T08 2020-02-13T07&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# the interest_over_time() method returns a pandas DataFrame
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pytrends&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interest_over_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;date&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sororidade&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;futebol&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;carro&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;temperatura&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;restaurante&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;isPartial&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2020-02-06 08:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2020-02-06 09:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2020-02-06 10:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2020-02-06 11:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2020-02-06 12:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;22&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;2-organizing-the-data&quot;&gt;2. Organizing the data&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;isPartial&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;despine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Interest over time (Google Trends)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rotation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/interest_over_time.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# changing the zeros to 0.1 so the model converge
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sororidade&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sororidade&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-causal-impact&quot;&gt;3. Causal Impact&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pre_period&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2020-02-09T22:00:00.000000000&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;post_period&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2020-02-09T23:00:00.000000000&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CausalImpact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre_period&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post_period&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Calling the summary method on the CausalImpact object we obtain a numerical summary of the analysis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/ci_summary.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'report'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For additional guidance about the correct interpretation of the summary table, the package provides a verbal interpretation, printed using the same method but with &lt;code class=&quot;highlighter-rouge&quot;&gt;output=&quot;report&quot;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/ci_report.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Explaining the plots, in the package documentation:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“By default, the plot contains three panels. The first panel shows the data and a counterfactual prediction for the post-treatment period. The second panel shows the difference between observed data and counterfactual predictions. This is the pointwise causal effect, as estimated by the model. The third panel adds up the pointwise contributions from the second panel, resulting in a plot of the cumulative effect of the intervention.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/sororidade_plots.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Just by looking at the &lt;em&gt;sorority&lt;/em&gt; interest over time plot we may have concluded that it was obvious the causal effect.&lt;/p&gt;

&lt;p&gt;In addition, the CausalImpact report is somewhat misleading: our series had a lot of zeros, as it is an unusual term and we have counted the metrics of interest from Google trends over time. Because of this, all changes are greatly expanded, and this reflects the increase of &lt;code class=&quot;highlighter-rouge&quot;&gt;+6735.8%&lt;/code&gt; in the response variable.&lt;/p&gt;

&lt;p&gt;Let’s look at another example to consolidate our understanding.&lt;/p&gt;

&lt;h1 id=&quot;another-example---amazon-rainforest-burns&quot;&gt;Another example - Amazon rainforest burns&lt;/h1&gt;

&lt;h2 id=&quot;context-1&quot;&gt;Context&lt;/h2&gt;
&lt;p&gt;From &lt;a href=&quot;https://pt.wikipedia.org/wiki/Inc%C3%AAndios_florestais_na_Amaz%C3%B4nia_em_2019&quot;&gt;wikipedia&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“The forest fires in the Amazon in 2019 were a series of forest fires that affected South America, mainly Brazil. At least 161.236 fires were recorded in the country from January to October 2019, 45% more compared to the same period in 2018, which reached 84% in August”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Also from the same article:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“&lt;strong&gt;On August 11, Amazonas declared a state of emergency&lt;/strong&gt;. NASA images showed that on August 13, smoke from fires was visible from space […]”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will set August 11, 2019 as the intervention period for our causality study.&lt;/p&gt;

&lt;h2 id=&quot;causal-impact&quot;&gt;Causal Impact&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;kw_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Amazônia&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Pantanal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Cerrado&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Caatinga&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Pampas&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pytrends&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kw_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeframe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'2019-03-01 2020-01-01'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pytrends&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interest_over_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;date&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Amazônia&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Pantanal&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Cerrado&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Caatinga&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Pampas&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;isPartial&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-03-03 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;39&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-03-10 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;42&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-03-17 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;43&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-03-24 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;42&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-03-31 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;42&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;False&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/iot_amazon.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;isPartial&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pre_period&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2019-08-11&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;post_period&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2019-09-22&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CausalImpact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre_period&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post_period&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/amazon_summary.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'report'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/amazon_report.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/causal_impact/amazon_plots.png&quot; alt=&quot;visual&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we have something closer to what we find on a daily basis, but still a little exaggerated.&lt;/p&gt;

&lt;p&gt;We see that the percentage increase in the response variable after the intervention was &lt;code class=&quot;highlighter-rouge&quot;&gt;+51.24%&lt;/code&gt; and this change was statistically significant.&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;The examples shown here help to illustrate the concept and API of the package.&lt;/p&gt;

&lt;p&gt;I invite you to go further and try to create business scenarios in which this type of report can be useful. At work, I had no trouble finding these scenarios and it is your duty, as a data scientist, to provide data-driven value where you deem it appropriate.&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://google.github.io/CausalImpact/CausalImpact.html&quot;&gt;https://google.github.io/CausalImpact/CausalImpact.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/dafiti/causalimpact&quot;&gt;https://github.com/dafiti/causalimpact&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.uol.com.br/universa/noticias/redacao/2020/02/11/sororidade-buscas-no-google-crescem-250-apos-fala-de-manu-gavassi-no-bbb.htm&quot;&gt;https://www.uol.com.br/universa/noticias/redacao/2020/02/11/sororidade-buscas-no-google-crescem-250-apos-fala-de-manu-gavassi-no-bbb.htm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.huffpostbrasil.com/entry/sororidade-manu-gavassi_br_5e442423c5b61b84d3438b88&quot;&gt;https://www.huffpostbrasil.com/entry/sororidade-manu-gavassi_br_5e442423c5b61b84d3438b88&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://emais.estadao.com.br/noticias/tv,bbb-20-buscas-por-sororidade-no-google-sobem-250-apos-fala-de-manu-gavassi,70003193892&quot;&gt;https://emais.estadao.com.br/noticias/tv,bbb-20-buscas-por-sororidade-no-google-sobem-250-apos-fala-de-manu-gavassi,70003193892&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pt.wikipedia.org/wiki/Inc%C3%AAndios_florestais_na_Amaz%C3%B4nia_em_2019&quot;&gt;https://pt.wikipedia.org/wiki/Inc%C3%AAndios_florestais_na_Amaz%C3%B4nia_em_2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">TL;DR: There are ways of measuring the causal impact of some business intervention even in scenarios where a randomized experiment is unavailable. In this post we investigated the increase in Google trends popularity index of some search terms caused by different interventions. The same logic can be applied in business contexts such as the impact of a new product launch, the onset of an advertising campaign and other problems in economics, epidemiology, biology among others.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/causal_impact/amazon_plots.png" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/causal_impact/amazon_plots.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Statistical forecasting: notes on regression and time series analysis</title><link href="https://millengustavo.github.io/blog/book/time%20series/forecasting/data%20science/machine%20learning/statistics/2020/02/03/statistical-forecasting.html" rel="alternate" type="text/html" title="Statistical forecasting: notes on regression and time series analysis" /><published>2020-02-03T00:00:00-06:00</published><updated>2020-02-03T00:00:00-06:00</updated><id>https://millengustavo.github.io/blog/book/time%20series/forecasting/data%20science/machine%20learning/statistics/2020/02/03/statistical-forecasting</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/time%20series/forecasting/data%20science/machine%20learning/statistics/2020/02/03/statistical-forecasting.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Author: Robert Nau&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://people.duke.edu/~rnau/411home.htm&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“This web site contains notes and materials for an advanced elective course on statistical forecasting that is taught at the Fuqua School of Business, Duke University. It covers linear regression and time series forecasting models as well as general principles of thoughtful data analysis.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I have seen the future and it is very much like the present, only longer.” 
– Kehlog Albran, &lt;em&gt;The Profit&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;1-get-to-know-your-data&quot;&gt;1. Get to know your data&lt;/h1&gt;
&lt;h2 id=&quot;principles-and-risks-of-forecasting&quot;&gt;Principles and risks of forecasting&lt;/h2&gt;
&lt;p&gt;Statistical forecasting: art and science of forecasting from data, with or without knowing in advance what equation you should use&lt;/p&gt;

&lt;h3 id=&quot;signal-vs-noise&quot;&gt;Signal vs. noise&lt;/h3&gt;
&lt;p&gt;Variable you want to predict = signal + noise&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Signal: predictable component&lt;/li&gt;
  &lt;li&gt;Noise: what is left over&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sensitive statistical tests are needed to get a better idea of whether the pattern you see in the data is really random or whether there is some signal yet to be extracted. If you fail to detect a signal that is really there, or falsely detect a signal that isn’t really there, your forecasts will be at best suboptimal and at worst dangerously misleading&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;random walk model&lt;/strong&gt;: the variable takes random steps up and down as it goes forward:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;if you transform by taking the period-to-period changes (the “first difference”) it becomes a time series that is described by the mean model&lt;/li&gt;
  &lt;li&gt;the confidence limits for the forecasts gets wider at longer forecast horizons&lt;/li&gt;
  &lt;li&gt;typical of random walk patterns -&amp;gt; they don’t look random as they are! -&amp;gt; analyze the statistical properties: momentum, mean-reversion, seasonality&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;risks-of-forecasting&quot;&gt;Risks of forecasting&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;“If you live by the crystal ball you end up eating broken glass”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Intrinsic risk&lt;/strong&gt;: random variation beyond explanation with the data and tools available&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parameter risk&lt;/strong&gt;: errors in estimating the parameters of the forecasting model, under the assumption that you are fitting the correct model to the data in the first place
    &lt;blockquote&gt;
      &lt;p&gt;When predicting time series, more sample data is not always better -&amp;gt; might include older data that is not as representative of current conditions. &lt;strong&gt;Blur of history&lt;/strong&gt; problem: no pattern really stays the same forever&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can’t eliminate instrinsic risk and parameter risk, &lt;em&gt;you can and should try to quantify&lt;/em&gt; them in relative terms -&amp;gt; so the appropriate risk-return tradeoffs can be made when decisions are based on the forecast&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Model risk&lt;/strong&gt;: risk of choosing the wrong model. &lt;em&gt;Most serious form of forecast error&lt;/em&gt; -&amp;gt; can be reduced by following good statistical practices: Follow good practices for exploring the data, understand the assumptions that are behind the models and test the assumptions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If the errors are not pure noise -&amp;gt; there is some pattern in them, and you could make them smaller by adjusting the model to explain that pattern&lt;/p&gt;

&lt;h2 id=&quot;get-to-know-your-data&quot;&gt;Get to know your data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Where did it come from?&lt;/li&gt;
  &lt;li&gt;Where has it been?&lt;/li&gt;
  &lt;li&gt;Is it clean or dirty?&lt;/li&gt;
  &lt;li&gt;In what units is it measured?&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Assembling, cleaning, adjusting and documenting the units of the data is often the most tedious step of forecasting&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;plot-the-data&quot;&gt;PLOT THE DATA!&lt;/h3&gt;
&lt;p&gt;You should graph your data to get a feel for its qualitative properties -&amp;gt; your model must accommodate these features and ideally it should shed light on their underlying causes&lt;/p&gt;

&lt;h2 id=&quot;inflation-adjustment-deflation&quot;&gt;Inflation adjustment (“deflation”)&lt;/h2&gt;
&lt;p&gt;Accomplished by dividing a monetary time series by a price index, such as the Consumer Price Index (CPI) -&amp;gt; uncover the real growth&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;original series: “nominal dollars” or “current dollars”&lt;/li&gt;
  &lt;li&gt;deflated series: “constant dollars”&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Not always necessary, sometimes forecasting the nominal data or log transforming for stabilizing the variance is simpler&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Inflation adjustment is only appropriated for money series. If a non-monetary series shows signs of exponential growth or increasing variance -&amp;gt; try a logarithm transformation&lt;/p&gt;

&lt;h2 id=&quot;seasonal-adjustment&quot;&gt;Seasonal adjustment&lt;/h2&gt;
&lt;h3 id=&quot;multiplicative-adjustment&quot;&gt;Multiplicative adjustment&lt;/h3&gt;
&lt;p&gt;Increasing amplitude of seasonal variations is suggestive of a multiplicative seasonal pattern -&amp;gt; can be removed by &lt;strong&gt;multiplicative seasonal adjustment&lt;/strong&gt;: dividing each value of the time series by a seasonal index that is representative of normal typically observed in that season&lt;/p&gt;

&lt;h3 id=&quot;additive-adjustment&quot;&gt;Additive adjustment&lt;/h3&gt;
&lt;p&gt;For time series whose seasonal variations are roughly constant in magnitude, independent of the current average level of the series -&amp;gt; adding or subtracting a quantity that represents the absolute amount by which the value in that season of the year tends to be below or above normal, as estimated from past data&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Additive seasonal patterns are somewhat rare, but if applying log transform -&amp;gt; you should use additive rather than multiplicative&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;acronyms&quot;&gt;Acronyms&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SA&lt;/strong&gt;: seasonally adjusted&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NSA&lt;/strong&gt;: not seasonally adjusted&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SAAR&lt;/strong&gt;: seasonally adjusted annual rate -&amp;gt; each period’s value has been adjusted for seasonality and then multiplied by the number of periods in a year, as though the same value had been obtained in every period for a whole year&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;stationarity-and-differencing&quot;&gt;Stationarity and differencing&lt;/h2&gt;
&lt;h3 id=&quot;statistical-stationarity&quot;&gt;Statistical stationarity&lt;/h3&gt;
&lt;p&gt;A stationary time series is one whose statistical properties such as mean, variance, autocorrelation, etc. are all constant over time. Most statistical forecasting methods are based on the assumption that the time series can be rendered approximately stationary (i.e., “stationarized”) through the use of mathematical transformations&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;trend-stationary&lt;/strong&gt;: series has a stable long-run rend and tends to revert to the trend line following a disturbance -&amp;gt; to stationarize it = detrending&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;difference-stationary&lt;/strong&gt;: if the mean, variance, and autocorrelations of the original series are not constant in time, even after detrending, perhaps the statistics of the changes in the series between periods or between seasons will be constant&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Unit root test&lt;/strong&gt;: to understand if a series is trend-stationary or difference-stationary&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;first-difference&quot;&gt;First-difference&lt;/h3&gt;
&lt;p&gt;Series of changes from one period to the next&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;random walk model&lt;/strong&gt;: if first-difference of a series is stationary and also completely random (not autocorrelated)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ETS or ARIMA&lt;/strong&gt;: can be used when the first-difference of a series is stationary but not completely random (its value at period t is autocorrelated with its value at earlier periods)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-logarithm-transformation&quot;&gt;The logarithm transformation&lt;/h2&gt;
&lt;h3 id=&quot;change-in-natural-log--percentage-change&quot;&gt;Change in natural log ≈ percentage change&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Small&lt;/strong&gt; changes in the natural log of a variable are directly interpretable as percentage changes to a very close approximation&lt;/p&gt;

&lt;h3 id=&quot;linearization-of-exponential-growth-and-inflation&quot;&gt;Linearization of exponential growth and inflation&lt;/h3&gt;
&lt;p&gt;The log transformation converts the exponential growth pattern to a linear growth pattern, and it simultaneously converts the multiplicative (proportional-variance) seasonal pattern to an additive (constant-variance) seasonal pattern&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Logging a series often has an effect very similar to deflating: it straightens out exponential growth patterns and reduces heteroscedasticity (i.e., stabilizes variance). Logging is therefore a “poor man’s deflator” which does not require any external data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Geometric random walk&lt;/strong&gt;: logging the data before fitting a random walk model -&amp;gt; commonly used for stock price data&lt;/p&gt;

&lt;h3 id=&quot;trend-measured-in-natural-log-units--percentage-growth&quot;&gt;Trend measured in natural-log units ≈ percentage growth&lt;/h3&gt;
&lt;p&gt;Usually the trend is estimated more precisely by fitting a statistical model that explicitly includes a local or global trend parameter, such as a linear trend or random-walk-with-drift or linear exponential smoothing model.  When a model of this kind is fitted in conjunction with a log transformation, its trend parameter can be interpreted as a percentage growth rate.&lt;/p&gt;

&lt;h3 id=&quot;errors-measured-in-natural-log-units--percentage-errors&quot;&gt;Errors measured in natural-log units ≈ percentage errors&lt;/h3&gt;
&lt;p&gt;If you look at the error statistics in logged units, you can interpret them as percentages if they are not too large – if the standard deviation is 0.1 or less&lt;/p&gt;

&lt;h3 id=&quot;coefficients-in-log-log-regressions--proportional-percentage-changes&quot;&gt;Coefficients in log-log regressions ≈ proportional percentage changes&lt;/h3&gt;
&lt;p&gt;In many economic situations (particularly price-demand relationships), the marginal effect of one variable on the expected value of another is linear in terms of percentage changes rather than absolute changes&lt;/p&gt;

&lt;h1 id=&quot;2-introduction-to-forecasting-the-simplest-models&quot;&gt;2. Introduction to forecasting: the simplest models&lt;/h1&gt;
&lt;h2 id=&quot;review-of-basic-statistics-and-the-simplest-forecasting-model-the-sample-mean&quot;&gt;Review of basic statistics and the simplest forecasting model: the sample mean&lt;/h2&gt;
&lt;p&gt;Historical sample mean (or constant model, or intercept-only regression): if the series consists of i.i.d. values, the sample mean should be the next value if the goal is to minimize MSE&lt;/p&gt;

&lt;h4 id=&quot;why-squared-error&quot;&gt;Why &lt;em&gt;squared&lt;/em&gt; error?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;the central value around which the um of squared deviations are minimized is the sample mean&lt;/li&gt;
  &lt;li&gt;variances are additive when random variables that are statistically independent are added together&lt;/li&gt;
  &lt;li&gt;large errors often have disproportionately worse consequences than small errors, hence the squared error is more representative of the economic consequences of error&lt;/li&gt;
  &lt;li&gt;variances and covariances play a key rola in normal distribution theory and regression analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;nonlinear transformations of the data (e.g., log or power transformations) can often be used to turn skewed distributions into symmetric (ideally normal) ones, allowing such data to be well fitted by models that focus on mean values.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;fundamental-law-of-forecasting-risk&quot;&gt;Fundamental law of forecasting risk&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Variance of forecasting risk = 
variance of intrinsic risk + 
variance of parameter risk
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Confidence intervals: sort like a probability, but not exactly -&amp;gt; there’s an x% probability that your future data will fall in your x% confidence interval for the forecast&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Confidence interval = 
forecast ± 
(critical t-value) × (standard error of forecast)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;95% confidence interval is (roughly) the forecat “plus-or-minus two standard errors”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A rule of thumb: when adjusted R-squared is fairly small (say, less than 20%), the percentage by which the standard error of the regression model is less than the standard error of the mean model is roughly one-half of adjusted R-squared.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;t-stats, P-values, and R-squared, and other test statistics are numbers you should know how to interpret and use, but they are not the most important numbers in your analysis and they are not the bottom line:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;what new things have you learned from your data?&lt;/li&gt;
  &lt;li&gt;what assumptions does your model make?&lt;/li&gt;
  &lt;li&gt;would these assumptions make sense to someone else?&lt;/li&gt;
  &lt;li&gt;would a simpler model perform almost as well?&lt;/li&gt;
  &lt;li&gt;how accurate are your model’s predictions?&lt;/li&gt;
  &lt;li&gt;how accurate it is likely to be to predict the future?&lt;/li&gt;
  &lt;li&gt;how good are the inferences and decisions?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notes-on-the-random-walk-model&quot;&gt;Notes on the random walk model&lt;/h2&gt;
&lt;p&gt;Model assumes that &lt;em&gt;in each period the variable takes a random step away from its previous value, and the steps are independently and identically distributed in size (“i.i.d.”)&lt;/em&gt;. This is equivalent to saying that the first difference of the variable is a series to which the mean model should be applied.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;if you begin with a series that wanders all over the map, the first difference looks i.i.d. sequence -&amp;gt; random walk model is a potentially good candidate&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;without drift: all future values will equal the last observed value&lt;/li&gt;
  &lt;li&gt;with drift: the average increase from one period to the next (estimated drift = slope = d)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Square root of time rule&lt;/strong&gt;: The confidence interval for a k-period-ahead random walk forecast is wider than that of a 1-period-ahead forecast by a factor of square-root-of-k&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Are the daily changes statistically independent as well having a mean of zero? autocorrelation plot -&amp;gt; &lt;strong&gt;random walk without drift&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-geometric-random-walk-model&quot;&gt;The geometric random walk model&lt;/h3&gt;
&lt;p&gt;The natural logarithm of the variable is assumed to walk a random walk, usually with drift&lt;/p&gt;

&lt;p&gt;Diff-logs are interpretable as (approximate) percentage changes&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;it is very hard to estimate the trend in a random-walk-with-drift model based on the mean growth that was observed in the sample of data unless the sample size is very large&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fitting a random-walk-with-drift model to the logged series is equivalent to fitting the geometric random walk model to the original series.&lt;/p&gt;

&lt;h3 id=&quot;reasons-for-using-the-random-walk-model&quot;&gt;Reasons for using the random walk model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;If you see what looks like pure noise (i.i.d. variations) after performing a 1st -difference or diff-log transformation, then your data is telling you that you that it is a random walk. This isn’t very exciting in terms of the point forecasts you should make (“next month will be the same as last month, plus average growth”), but it has very important implications in terms of how much uncertainty there is in forecasting more than one period ahead.&lt;/li&gt;
  &lt;li&gt;benchmark against which to compare more complicated time series models, particularly regression models&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mean-constant-model&quot;&gt;Mean (constant) model&lt;/h2&gt;
&lt;p&gt;Predicting a variable whose values are i.i.d.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sample mean&lt;/strong&gt;: by definition an unbiased predictor and minimizes the mean squared forecasting error regardless of the probability distribution -&amp;gt; it is the value around which the sum of squared deviations of the sample data is minimized&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Standard error of the mean&lt;/em&gt;: how accurate is the estimate of the sample mean -&amp;gt; equals the sample stdev divided by the sqrt of the sample size&lt;/p&gt;

&lt;p&gt;Central limit theorem -&amp;gt; large samples: 95% confidence interval = mean +- 2*stdev&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Standard error of the forecast&lt;/em&gt;: equal to the sample stdev * sqrt(1+1/n)&lt;/p&gt;

&lt;p&gt;Confidence interval for a forecast is the point forecast plus-or-minus the appropriate critical t-value times the standard error of the forecast&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The critical t-value for a 50% confidence interval is approximately 2/3, so a 50% confidence interval is one-third the width of a 95% confidence interval. The nice thing about a 50% confidence interval is that it is a &lt;strong&gt;“coin flip”&lt;/strong&gt; as to whether the true value will fall inside or outside of it, which is extremely easy to think about&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we can find some mathematical transformation (e.g., differencing, logging, deflating, etc.) that converts the original time series into a sequence of values that are i.i.d., we can use the mean model to obtain forecasts and confidence limits for the transformed series, and then reverse the transformation to obtain corresponding forecasts and confidence limits for the original series.&lt;/p&gt;

&lt;h2 id=&quot;linear-trend-model&quot;&gt;Linear trend model&lt;/h2&gt;
&lt;p&gt;aka trend-line model: special case of a simple regression model in which the independent variable is just a time index variable.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;R-squared = 0.143 -&amp;gt; the variance of the regression model’s errors is 14.3% less than the variance of the mean model’s errors, i.e., the model has “explained” 14.3% of the variance in the series&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If the model has succeeded in extracting all the “signal” from the data, there should be no pattern at all in the errors: the error in the next period should not be correlated with any previous errors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;lag-1 autocorrelation&lt;/strong&gt;: should be very close to zero&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Durbin-Watson statistic&lt;/strong&gt;: ought to be very close to 2&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;trend lines have their use as visual aids, but are often poor for forecasting&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;random-walk-model&quot;&gt;Random walk model&lt;/h2&gt;
&lt;p&gt;Time series with irregular growth -&amp;gt; predict the change from one period to the next (first difference)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;autocorrelation at lag k&lt;/strong&gt; -&amp;gt; correlation between the variable and itself lagged by k periods&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;random-walk-without-drift&lt;/strong&gt;: assumes that at each point, the series merely takes a random step away from its last recorded position, with steps whose mean value is zero -&amp;gt; values of the autocorrelations are not significantly different than zero (95% confidence interval), no change from one period to the next, because past data provides no information about the direction of future movements&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;random-walk-with-drift&lt;/strong&gt;: mean step size is some nonzero value&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the random-walk-without-drift model, the standard error of the 1-step ahead forecast is the root-mean-squared-value of the period-to-period changes&lt;/p&gt;

&lt;p&gt;For a random-walk-with-drift, the forecast standard error is the sample standard deviation of the period-to-period changes.&lt;/p&gt;

&lt;p&gt;“Square root of time” rule for the errors of random walk forecasts: the standard error of a k-step-ahead forecast is larger than that of the 1-step-ahead forecast by a factor of square-root-of-k. This explains the sideways-parabola shape of the confidence bands for long-term forecasts.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Random walk may look trivial -&amp;gt; naive model (always predict that tomorrow will be the same as today). The square-root-of-time pattern in its confidence bands for long-term forecasts is of profound importance in finance (it is the basis of the theory of options pricing), and the random walk model often provides a good benchmark against which to judge the performance of more complicated models&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;RWM -&amp;gt; special case of an ARIMA model -&amp;gt; ARIMA(0, 1, 0)&lt;/p&gt;

&lt;h2 id=&quot;geometric-random-walk-model&quot;&gt;Geometric random walk model&lt;/h2&gt;
&lt;p&gt;Natural logarithm transformation: linearize exponential growth and stabilize variance of changes (“diff-log”)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It can be dangerous to estimate the average rate of return to be expected in the future (let alone anticipate short-term changes in direction), by fitting straight lines to finite samples of data!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Geometric random walk model&lt;/strong&gt;:  Application of the random walk model to the logged series implies that the forecast for the next month’s value of the original series will equal the previous month’s value plus a constant percentage increase.&lt;/p&gt;

&lt;p&gt;In unlogged units, the 95% confidence limits for long-term forecasts are noticeably asymmetric&lt;/p&gt;

&lt;h3 id=&quot;more-general-random-walk-forecasting-models&quot;&gt;More general random walk forecasting models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;RW model 1: basic geometric random walk -&amp;gt; assumes series in different periods are statistically independent (uncorrelated) and also identically distributed&lt;/li&gt;
  &lt;li&gt;RW model 2: assumes the series in different periods are statistically independent but not identically distributed&lt;/li&gt;
  &lt;li&gt;RW model 3: assumes that returns in different periods are uncorrelated but not otherwise independent. The &lt;strong&gt;ARCH&lt;/strong&gt; (autoregressive conditional heteroscedasticity) and &lt;strong&gt;GARCH&lt;/strong&gt; (generalized ARCH) models assume that the local volatility follows an autoregressive process, which is characterized by sudden jumps in volatility with a slow reversion to an average volatility&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;three-types-of-forecasts-estimation-validation-and-the-future&quot;&gt;Three types of forecasts: estimation, validation, and the future&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Out-of-sample validation&lt;/strong&gt;: withhold some of the sample data from the model identification and estimation process, then use the model to make predictions for the hold-out data to see how accurate they are and to determine whether the statistics of their errors are similar to those that the model made within the sample of data that was fitted&lt;/p&gt;

&lt;p&gt;Overfitting (likely when):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;model with a large number of parameters fitted to a small sample of data&lt;/li&gt;
  &lt;li&gt;model has been selected from a large set of potential models precisely by minimizing the MSE in the estimation period&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Backtests: one-step-ahead forecasts in the validation period (held out during parameter estimation)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you test a great number of models and choose the model whose errors are smallest in the validation period, you may end up overfitting the data within the validation period as well as in the estimation period&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Holding data out for validation purposes&lt;/strong&gt; is probably the single most important diagnostic test of a model: it gives the best indication of the accuracy that can be expected when forecasting the future&lt;/li&gt;
  &lt;li&gt;When you’re ready to forecast the future in real time, you should of course use all the available data for estimation, so that the most recent data is used&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Forecasts into the future are “true” forecasts that are made for time periods beyond the end of the available data&lt;/p&gt;

&lt;p&gt;The model with the tightest confidence intervals is not always the best model -&amp;gt; a bad model not always know it is a bad model&lt;/p&gt;

&lt;h1 id=&quot;3-averaging-and-smoothing-models&quot;&gt;3. Averaging and smoothing models&lt;/h1&gt;
&lt;h2 id=&quot;simple-moving-averages&quot;&gt;Simple moving averages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;mean model: best predictor of tomorrow is the avg of everything that has happened until now&lt;/li&gt;
  &lt;li&gt;random walk model: best predictor of tomorrow is what happened today, ignoring previous history&lt;/li&gt;
  &lt;li&gt;moving average: take an average of what has happened in some window of the recent past&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;moving average model&lt;/strong&gt;: superior to the mean model in adapting to cyclical pattern and superior to the random walk model in not being too sensitive to random shocks from one period to the next&lt;/p&gt;

&lt;p&gt;Simple moving average (SMA):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Each of the past m observations gets a weight of &lt;code class=&quot;highlighter-rouge&quot;&gt;1/m&lt;/code&gt; in the averaging formula, so as &lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt; gets larger, each individual observation in the recent past receives less weight. This implies that larger values of &lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt; will filter out more of the period-to-period noise and yield &lt;em&gt;smoother-looking&lt;/em&gt; series of forecasts&lt;/li&gt;
  &lt;li&gt;average age of the data in the forecast is &lt;code class=&quot;highlighter-rouge&quot;&gt;(m+1)/2&lt;/code&gt; -&amp;gt; amount by which the forecasts will tend to lag behind in trying to follow trends or respond to turning points&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Value of &lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt; tradeoff: filtering out more noise vs. being too slow to respond to trends and turning points&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;comparing-measures-of-forecast-error-between-models&quot;&gt;Comparing measures of forecast error between models&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RMSE&lt;/strong&gt;: root mean squared error: (the most common standard of goodness-of-fit, penalizes big errors relatively more than small errors because it squares them first; it is approximately the standard deviation of the errors if the mean error is close to zero)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MAE&lt;/strong&gt;: mean absolute error (the average of the absolute values of the errors, more tolerant of the occasional big error because errors are not squared)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MAPE&lt;/strong&gt;: mean absolute percentage error (perhaps better to focus on if the data varies over a wide range due to compound growth or inflation or seasonality, in which case you may be more concerned about measuring errors in percentage terms)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ME&lt;/strong&gt;: mean error (this indicates whether forecasts are biased high or low—should be close to 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MPE&lt;/strong&gt;: mean percentage error (ditto in percentage terms)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Best measure for size of error = RMSE&lt;/p&gt;

&lt;p&gt;Easier for non-specialists to understand = MAE and MAPE&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SMA with a trend = SMD + drift&lt;/code&gt; (add a constant to the SMA forecasting equation)&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Tapered Moving Average&lt;/code&gt;: put only half as much weight on the newest and oldest values -&amp;gt; more robust to outliers in the data&lt;/p&gt;

&lt;h2 id=&quot;simple-exponential-smoothing&quot;&gt;Simple exponential smoothing&lt;/h2&gt;
&lt;p&gt;SMA problems:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;putting equal weight on the last m observations and no weight on any previous observations is usually not the best way to average values that are arriving consecutively in time&lt;/li&gt;
  &lt;li&gt;would make more sense to gradually decrease the weights placed on the older values&lt;/li&gt;
  &lt;li&gt;its confidence intervals for long-horizon forecasts do not widen at all&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Simple exponential smoothing (SES) aka Exponentially weighted moving average model&lt;/strong&gt;: addresses these shortcomings of SMA&lt;/p&gt;

&lt;p&gt;most used time series model in business applications:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;good forecast under a wide range of conditions&lt;/li&gt;
  &lt;li&gt;computationally it is extremely simple&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;the SES model is an interpolation between the mean model and the random walk model with respect to the way it responds to new data. As such it might be expected to do better than either of them in situations where the random walk model over-responds and the mean model under-responds, and indeed it does&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Overall the SES model is superior to the SMA model in responding a bit more quickly to the newest data while treating older data more even-handedly, when the models otherwise yield the same average age&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;all models are based on assumptions about how the world works, and you need to understand what the assumptions are and (ideally) you should believe in the assumptions of your chosen model and be able to explain and defend them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;linear-exponential-smoothing-les&quot;&gt;Linear Exponential Smoothing (LES)&lt;/h2&gt;
&lt;p&gt;Generalization of the SES to obtain a model that computes local estimates of both level and trend -&amp;gt; same basic logic, but now you have two smoothing constants, one for the level and one for the trend&lt;/p&gt;

&lt;p&gt;Any smoothing model will lag behind to some extent in responding to unforeseen changes in level or trend&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;many time series that arise in business and economics (as well as engineering and the natural sciences) which are inherently non-seasonal or which have been seasonally adjusted display a pattern of &lt;strong&gt;random variations around a local mean value or a local trend line that changes slowly with time&lt;/strong&gt;. The first difference of such a series is negatively autocorrelated at lag 1: a positive change tends to be followed by a (smaller) negative one. For time series of this type, a smoothing or averaging model is the appropriate forecasting model.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;out-of-sample-validation&quot;&gt;Out-of-sample validation&lt;/h2&gt;
&lt;p&gt;Aka “backtesting”: holding out some of the data while estimating parameters of alternative models, then freezing those parameter estimates and using them to make predictions for the hold-out data&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;You hope to find the statistics of the errors of the predictions for the hold-out data look very similar to those of the predictions for the sample data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If the data exhibits exponential growth due to compounding or inflation, then it will display greater volatility in absolute terms toward the end of the series, even if the volatility is constant in percentage terms. In situations like this you may want to use a nonlinear transformation such as logging or deflating as part of your model&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;it is usually best to look at &lt;strong&gt;MAPE’s&lt;/strong&gt; rather than RMSE’s when asking whether a given model performed about as well in the validation period as in the estimation period.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;moving-average-and-exponential-smoothing-models&quot;&gt;Moving average and exponential smoothing models&lt;/h2&gt;
&lt;p&gt;Moving beyond mean models, random walk models, and linear trend models, nonseasonal patterns and trends can be extrapolated using a moving-average or smoothing model.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Which type of trend-extrapolation is best: horizontal or linear? Empirical evidence suggests that, if the data have already been adjusted (if necessary) for inflation, then it may be imprudent to extrapolate short-term linear trends very far into the future. Trends evident today may slacken in the future due to varied causes such as product obsolescence, increased competition, and cyclical downturns or upturns in an industry. For this reason, simple exponential smoothing often performs better out-of-sample than might otherwise be expected, despite its “naive” horizontal trend extrapolation.  Damped trend modifications of the linear exponential smoothing model are also often used in practice to introduce a note of conservatism into its trend projections.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;forecasting-with-adjustments-for-inflation-and-seasonality&quot;&gt;Forecasting with adjustments for inflation and seasonality&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Deflation with prices indices&lt;/li&gt;
  &lt;li&gt;Seasonal decompositon&lt;/li&gt;
  &lt;li&gt;Time series forecasting models for seasonal data
    &lt;ul&gt;
      &lt;li&gt;Averaging and smoothing combined with seasonal adjustment&lt;/li&gt;
      &lt;li&gt;Winters seasonal exponential smoothing model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;modeling-the-effect-of-inflation&quot;&gt;Modeling the effect of inflation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;to measure real growth and estimate its dependence on other real factors&lt;/li&gt;
  &lt;li&gt;to remove much of the trend and stabilize variance before fitting the model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;to “deflate” a variable, you divide it by an appropriate price index variable&lt;/li&gt;
  &lt;li&gt;e.g.: general price index, product-specific index&lt;/li&gt;
  &lt;li&gt;to “re-inflate” forecasts of a deflated series, you multiply the forecasts and confidence limits by a forecast of the price index&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Log vs. deflate&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Deflation should be used when you are interested in knowing the forecast in “real” terms and/or if the inflation rate is expected to change&lt;/li&gt;
  &lt;li&gt;Logging is sufficient if you just want a forecast in “nominal” terms and inflation is expected to remain constant—inflation just gets lumped with other sources of compound growth in the model.&lt;/li&gt;
  &lt;li&gt;Logging also ensures that forecasts and confidence limits have positive values, even in the presence of downward trends and/or high volatility.&lt;/li&gt;
  &lt;li&gt;If inflation has been minimal and/or there is little overall trend or change in volatility, neither may be necessary&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;seasonality&quot;&gt;Seasonality&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;repeating, preiodic pattern in the data that is keyed to the calendar of the clock&lt;/li&gt;
  &lt;li&gt;!= than “cyclality”, which do not have a predictable periodicity&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Seasonal patterns are complex, because the calendar is not rational: months and years don’t have whole numbers of weeks, a given month does not always have the same number of trading days/weekends, Christmans day can fall on any day of the week, some major holidays are “moveable feasts” that do not occur on the same calendar dates each year&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Quarterly data is easiest to handle: 4 quarters in a year, 3 months in a quarter, trading day adjustments have only minor effects.&lt;/li&gt;
  &lt;li&gt;Monthly data is more complicated: 12 months in a year, but not 4 weeks in a month; trading day adjustments may be important.&lt;/li&gt;
  &lt;li&gt;Weekly data requires special handling because a year is not exactly 52 weeks.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiplicative-seasonality&quot;&gt;Multiplicative seasonality&lt;/h3&gt;
&lt;p&gt;Most natural seasonal patterns are multiplicative&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Seasonal variations are roughly constant in percentage terms&lt;/li&gt;
  &lt;li&gt;Seasonal swings get larger or smaller in absolute magnitude as the average level of the series rises or falls due to long-term trends and/or business cycle effects&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;additive-seasonality&quot;&gt;Additive seasonality&lt;/h3&gt;
&lt;p&gt;Additive seasonal pattern has constant-amplitude seasonal swings in the presence of trends and cycles.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A log transformation converts a multiplicative pattern to an additive one, so if your model includes a log transformation, use additive rather than multiplicative seasonal adjustment.&lt;/li&gt;
  &lt;li&gt;If the historical data sample has little trend and seasonal variations are not large in relative terms, additive and multiplicative adjustment yield very similar results&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;seasonal-index&quot;&gt;Seasonal index&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Represents the expected percentage of “normal” in a given month or quarter&lt;/li&gt;
  &lt;li&gt;When the seasonal indices are assumed to be stable over time, they can be estimated by the “ratio to moving average” (RMA) method&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;winters-seasonal-smoothing&quot;&gt;Winters’ Seasonal Smoothing&lt;/h3&gt;
&lt;p&gt;The logic of Holt’s LES model can be extended to recursively estimate time-varying seasonal indices as well as level and trend.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Issues&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Estimation of Winters’ model is tricky&lt;/li&gt;
  &lt;li&gt;There are three separate smoothing constants to be jointly estimated by nonlinear least squares.&lt;/li&gt;
  &lt;li&gt;Initialization is also tricky, especially for the seasonal indices.&lt;/li&gt;
  &lt;li&gt;Confidence intervals sometimes come out extremely wide because the model “lacks confidence in itself.”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In practice&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The Winters model is popular in “automatic forecasting” software, because it has a little of everything (level, trend, seasonality).&lt;/li&gt;
  &lt;li&gt;Often it works very well, but difficulties in initialization &amp;amp; estimation can lead to strange results in some cases.&lt;/li&gt;
  &lt;li&gt;It responds to recent changes in the seasonal pattern as well as the trend, but with some danger of unstable long-term trend projections.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;4-linear-regression-models&quot;&gt;4. Linear regression models&lt;/h1&gt;
&lt;h2 id=&quot;introduction-to-linear-regression&quot;&gt;Introduction to linear regression&lt;/h2&gt;
&lt;p&gt;Regression analysis: art and science of fitting straight lines to patterns of data&lt;/p&gt;

&lt;p&gt;Assumptions:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The expected value of Y is a linear function of the X variables&lt;/li&gt;
  &lt;li&gt;The unexplained variations of Y are independent random variables (in particular, not “autocorrelated” if the variables are time series)&lt;/li&gt;
  &lt;li&gt;The all have the same variance (“homoscedasticity”)&lt;/li&gt;
  &lt;li&gt;They are normally distributed&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;No model is perfect - these assumptions will never be exactly satisfied by real-world messy data - but you hope that they are not badly wrong. The art of regression modeling is to (most importantly!) collect data that is relevant and informative with respect to your decision or inference problem, and then define your variables and construct your model in such a way that the assumptions listed above are plausible, at least as a first-order approximation to what is really happening&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;correlation-and-regression-to-mediocrity&quot;&gt;Correlation and regression-to-mediocrity&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Regression-to-mediocrity aka regression to the mean&lt;/strong&gt;: Purely statistical phenomenon that can be viewed as a form of selection bias. Every quantitative measurement is a combination of signal and noise. When a value above the mean is observed, it is probable that the value of the signal was above average and the value of the noise was above average. Now suppose there is some other quantity (say, some measurable trait of the offspring—not necessarily the same one) whose value depends only on the signal, not the noise, in the first quantity. Then a measurement of the second quantity should also be expected to be above the mean, but less so in relative terms, because only the above-average signal is passed on; the above-average noise is not. In fact, it is the independent noise in the second quantity that prevents variations from ever dying out over generations.&lt;/p&gt;

&lt;p&gt;The coefficient of correlation between X and Y is the average product of their standardized values&lt;/p&gt;

&lt;p&gt;It is a number that lies somewhere between -1 and +1, where -1 indicates a perfect negative linear relationship, +1 indicates a perfect positive linear relationship, and zero indicates no linear relationship.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A correlation of zero between X and Y does not necessarily mean that there is no relationship, just that there is no linear relationship within the historical sample of data that is being analyzed. e.g., y = xˆ2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When we speak of “regressing” one variable on a group of others, we mean the fitting of a linear equation that minimizes the sum of squared errors in predicting that variable from the others.&lt;/p&gt;

&lt;h2 id=&quot;mathematics-of-a-regression-model&quot;&gt;Mathematics of a regression model&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;The coefficients and error measures for a regression model are entirely determined by the following summary statistics: means, standard deviations, and correlations of the variables, and the sample size&lt;/li&gt;
  &lt;li&gt;The correlation between Y and X is equal to the average product of their standardized values&lt;/li&gt;
  &lt;li&gt;The slope coefficient in a simple regression of Y on X is the correlation between Y and X multiplied by the ratio of their standard deviations&lt;/li&gt;
  &lt;li&gt;In a simple regression model, the percentage of variance “explained” by the model, which is called R-squared, is the square of the correlation between Y and X&lt;/li&gt;
  &lt;li&gt;The sample standard deviation of the errors is a downward-biased estimate of the size of the true unexplained deviations in Y because it does not adjust for the additional “degree of freedom” used up by estimating the slope coefficient&lt;/li&gt;
  &lt;li&gt;Adjusted R-squared, which is obtained by adjusting R-squared for the degrees if freedom for error in exactly the same way, is an unbiased estimate of the amount of variance explained&lt;/li&gt;
  &lt;li&gt;For models fitted to the same sample of the same dependent variable, adjusted R-squared always goes up when the standard error of the regression goes down. A model does not always improve when more variables are added: adjusted R-squared can go down (even go negative) if irrelevant variables are added&lt;/li&gt;
  &lt;li&gt;The standard error of a coefficient estimate is the estimated standard deviation of the error in measuring it. And the estimated height of the regression line for a given value of X has its own standard error, which is called the standard error of the mean at X. All of these standard errors are proportional to the standard error of the regression divided by the square root of the sample size&lt;/li&gt;
  &lt;li&gt;The standard error of the forecast for Y for a given value of X is the square root of the sum of squares of the standard error of the regression and the standard error of the mean at X&lt;/li&gt;
  &lt;li&gt;Two-sided confidence limits for coefficient estimates, means, and forecasts are all equal to their point estimates plus-or-minus the appropriate critical t-value times their respective standard errors.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;what-to-look-for-in-regression-model-output&quot;&gt;What to look for in regression model output&lt;/h2&gt;

&lt;h3 id=&quot;standard-error-of-the-regression-root-mean-squared-error-adjusted-for-degrees-of-freedom&quot;&gt;Standard error of the regression (root-mean-squared error adjusted for degrees of freedom)&lt;/h3&gt;
&lt;p&gt;It is a lower bound on the standard error of any forecast generated from the model&lt;/p&gt;

&lt;p&gt;In time series forecasting, also common to look the mean absolute error (MAE) and, for positive data, the mean absolute percentage error (MAPE)&lt;/p&gt;

&lt;p&gt;Mean absolute scaled error -&amp;gt; measures improvement in mean absolute error relative to a random-walk-without-drift model&lt;/p&gt;

&lt;h3 id=&quot;adjusted-r-squared&quot;&gt;Adjusted R-squared&lt;/h3&gt;
&lt;p&gt;R-squared (the fraction by which the variance of the errors is less than the variance of the dependent variable) adjusted for the number of coefficients in the model relative to the sample size in order to correct it for bias.&lt;/p&gt;

&lt;p&gt;Adjusted R-squared is the fraction by which the square of the standard error of the regression is less than the variance of the dependent variable&lt;/p&gt;

&lt;p&gt;Unitless statistic, but there is no absolute standard for what is a “good” value&lt;/p&gt;

&lt;h3 id=&quot;significance-of-the-estimated-coefficients&quot;&gt;Significance of the estimated coefficients&lt;/h3&gt;
&lt;p&gt;Are the t-statistics greater than 2 in magnitude, corresponding to p-values less than 0.05?  If they are not, you should probably try to refit the model with the least significant variable excluded, which is the “backward stepwise” approach to model refinement.&lt;/p&gt;

&lt;h3 id=&quot;values-of-the-estimated-coefficients&quot;&gt;Values of the estimated coefficients&lt;/h3&gt;
&lt;p&gt;In general you are interested not only in the statistical significance of an independent variable, you are also interested in its practical significance. In theory, the coefficient of a given independent variable is its proportional effect on the average value of the dependent variable, others things being equal -&amp;gt; “bang for the buck”.&lt;/p&gt;

&lt;h3 id=&quot;plots-of-forecasts-and-residuals&quot;&gt;Plots of forecasts and residuals&lt;/h3&gt;
&lt;p&gt;DO NOT FAIL TO LOOK AT PLOTS OF THE FORECASTS AND ERRORS. Do the forecasts “track” the data in a satisfactory way, apart from the inevitable regression-to-the mean? (In the case of time series data, you are especially concerned with how the model fits the data at the “business end”, i.e., the most recent values.) Do the residuals appear random, or do you see some systematic patterns in their signs or magnitudes?  Are they free from trends, autocorrelation, and heteroscedasticity? Are they normally distributed? There are a variety of statistical tests for these sorts of problems, but the best way to determine whether they are present and whether they are serious is to look at the pictures.&lt;/p&gt;

&lt;h3 id=&quot;out-of-sample-validation-1&quot;&gt;Out-of-sample validation&lt;/h3&gt;
&lt;p&gt;A good model should have small error measures in both the estimation and validation periods, compared to other models, and its validation period statistics should be similar to its own estimation period statistics. Regression models with many independent variables are especially susceptible to overfitting the data in the estimation period, so watch out for models that have suspiciously low error measures in the estimation period and disappointingly high error measures in the validation period.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Be aware that if you test a large number of models and rigorously rank them on the basis of their validation period statistics, you may end up with just as much “data snooping bias” as if you had only looked at estimation-period statistics–i.e., you may end up picking a model that is more lucky than good! &lt;strong&gt;The best defense against this is to choose the simplest and most intuitively plausible model that gives comparatively good results.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;whats-the-bottom-line-how-to-compare-models&quot;&gt;What’s the bottom line? How to compare models&lt;/h2&gt;
&lt;p&gt;After fitting a number of different regression or time series forecasting models to a given data set, you have many criteria by which they can be compared:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Error measures in the estimation period: root mean squared error, mean absolute error, mean absolute percentage error, mean absolute scaled error, mean error, mean percentage error&lt;/li&gt;
  &lt;li&gt;Error measures in the validation period (if you have done out-of-sample testing): Ditto&lt;/li&gt;
  &lt;li&gt;Residual diagnostics and goodness-of-fit tests: plots of actual and predicted values; plots of residuals versus time, versus predicted values, and versus other variables; residual autocorrelation plots, cross-correlation plots, and tests for normally distributed errors; measures of extreme or influential observations; tests for excessive runs, changes in mean, or changes in variance (lots of things that can be “OK” or “not OK”)&lt;/li&gt;
  &lt;li&gt;Qualitative considerations: intuitive reasonableness of the model, simplicity of the model, and above all, usefulness for decision making!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The bottom line is that you should put the most weight on the error measures in the estimation period–most often the RMSE, but sometimes MAE or MAPE–when comparing among models.&lt;/p&gt;

&lt;p&gt;The MASE statistic provides a very useful reality check for a model fitted to time series data: is it any better than a naive model?&lt;/p&gt;

&lt;p&gt;You may also want to look at Cp, AIC or BIC, which more heavily penalize model complexity. But you should keep an eye on the residual diagnostic tests, cross-validation tests (if available), and qualitative considerations such as the intuitive reasonableness and simplicity of your model.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K.I.S.S. (keep it simple…)&lt;/strong&gt;: If two models are generally similar in terms of their error statistics and other diagnostics, you should prefer the one that is simpler and/or easier to understand.&lt;/p&gt;

&lt;h1 id=&quot;5-arima-models-for-time-series-forecasting&quot;&gt;5. ARIMA models for time series forecasting&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;uto-&lt;strong&gt;R&lt;/strong&gt;egressive &lt;strong&gt;I&lt;/strong&gt;ntegrated &lt;strong&gt;M&lt;/strong&gt;oving &lt;strong&gt;A&lt;/strong&gt;verage&lt;/p&gt;

&lt;h2 id=&quot;what-arima-stands-for&quot;&gt;What ARIMA stands for&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Series which needs to be differenced to be made stationary = an “integrated” (&lt;strong&gt;I&lt;/strong&gt;) series&lt;/li&gt;
  &lt;li&gt;Lags of the stationarized series are called “auto-regressive” (&lt;strong&gt;AR&lt;/strong&gt;) terms&lt;/li&gt;
  &lt;li&gt;Lags of the forecast errors are called “moving average” (&lt;strong&gt;MA&lt;/strong&gt;) terms&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;arima-models-put-it-all-together&quot;&gt;ARIMA models put it all together&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Generalized random walk models fine-tuned to eliminate all residual autocorrelation&lt;/li&gt;
  &lt;li&gt;Generalized exponential smoothing models that can incorporate long-term trends and seasonality&lt;/li&gt;
  &lt;li&gt;Stationarized regression models that use lags of the dependent variables and/or lags of the forecast errors as regressors&lt;/li&gt;
  &lt;li&gt;The most general class of forecasting models for time series that can be stationarized* by transformations such as differencing, logging, and or deflating&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;construction-of-an-arima-model&quot;&gt;Construction of an ARIMA model&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Stationarize the series, if necessary, by differencing (&amp;amp; perhaps also logging, deflating, etc.)&lt;/li&gt;
  &lt;li&gt;Study the pattern of autocorrelations and partial autocorrelations to determine if lags of the stationarized series and/or lags of the forecast errors should be included in the forecasting equation&lt;/li&gt;
  &lt;li&gt;Fit the model that is suggested and check its residual diagnostics, particularly the residual ACF and PACF plots, to see if all coefficients are significant and all of the pattern has been explained.&lt;/li&gt;
  &lt;li&gt;Patterns that remain in the ACF and PACF may suggest the need for additional AR or MA terms&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;arima-terminology&quot;&gt;ARIMA terminology&lt;/h2&gt;
&lt;p&gt;ARIMA(p,d,q) -&amp;gt; non-seasonal ARIMA:&lt;/p&gt;

&lt;p&gt;p = number of autoregressive terms&lt;/p&gt;

&lt;p&gt;q = number of non-seasonal differences&lt;/p&gt;

&lt;p&gt;d = number of moving-average terms&lt;/p&gt;

&lt;h2 id=&quot;do-you-need-both-ar-and-ma-terms&quot;&gt;Do you need both AR and MA terms?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;in general, you don’t&lt;/li&gt;
  &lt;li&gt;If the stationarized series has positive autocorrelation at lag 1, AR terms often work best. If it has negative autocorrelation at lag 1, MA terms often work best.&lt;/li&gt;
  &lt;li&gt;An MA(1) term often works well to fine-tune the effect of a nonseasonal difference, while an AR(1) term often works well to compensate for the lack of a nonseasonal difference, so the choice between them may depend on whether a difference has been used.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;interpretation-of-ar-terms&quot;&gt;Interpretation of AR terms&lt;/h2&gt;
&lt;p&gt;Autoregressive (AR) behavior: apparently feels a “restoring force” that tends to pull it back toward its mean&lt;/p&gt;

&lt;h2 id=&quot;interpretation-of-ma-terms&quot;&gt;Interpretation of MA terms&lt;/h2&gt;
&lt;p&gt;Moving average (MA) behavior: apparently undergoes random “shocks” whose effects are felt in two or more consecutive periods&lt;/p&gt;

&lt;h2 id=&quot;tools-for-identifying-arima-models-acf-and-pacf-plots&quot;&gt;Tools for identifying ARIMA models: ACF and PACF plots&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Autocorrelation function (ACF) plot: shows the correlation of the series with itself at different lags&lt;/li&gt;
  &lt;li&gt;Partial autocorrelation function (PACF) plot: shows the amount of autocorrelation at lag &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt; that is not explained by lower-order autocorrelations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ar-and-ma-signatures&quot;&gt;AR and MA “signatures”&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ACF that dies out gradually and PACF that cuts off sharply after a few lags -&amp;gt; &lt;strong&gt;AR signature&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;AR series is usually &lt;em&gt;positive autocorrelated at lag 1&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ACF that cuts off sharply after a few lags and PACF that dies out more gradually -&amp;gt; &lt;strong&gt;MA signature&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;MA series is usually &lt;em&gt;negatively autocorrelated at lag 1&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Whether a series displays AR or MA behavior often depends on the extent to which it has been differenced. “Underdifferenced” series -&amp;gt; AR signature (positive autocorrelation). After one or more orders of differencing, the autocorrelation will become more negative and an MA signature will emerge&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;model-fitting-steps&quot;&gt;Model-fitting steps&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Determine the order of differencing&lt;/li&gt;
  &lt;li&gt;Determine the numbers of AR &amp;amp; MA terms&lt;/li&gt;
  &lt;li&gt;Fit the model—check to see if residuals are “white noise,” highest-order coefficients are significant (w/ no “unit “roots”), and forecasts look reasonable. If not, return to step 1 or 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;technical-issues&quot;&gt;Technical issues&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Backforecasting&lt;/strong&gt;: Estimation algorithm begins by forecasting backward into the past to get start-up values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Unit roots&lt;/strong&gt;: Look at sum of AR coefficients and sum of MA coefficients—if they are too close to 1 you may want to consider higher or lower of differencing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overdifferencing&lt;/strong&gt;: A series that has been differenced one too many times will show very strong negative autocorrelation and a strong MA signature, probably with a unit root in MA coefficients&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;seasonal-arima-models&quot;&gt;Seasonal ARIMA models&lt;/h2&gt;
&lt;p&gt;Rely on seasonal lags and differences to fit the seasonal pattern. Generalizes the regression approach.&lt;/p&gt;

&lt;h3 id=&quot;terminology&quot;&gt;Terminology&lt;/h3&gt;
&lt;p&gt;Seasonal part of an ARIMA model is summarized by three additional numbers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;P = # of seasonal autoregressive terms&lt;/li&gt;
  &lt;li&gt;D = # of seasonal differences&lt;/li&gt;
  &lt;li&gt;Q = # of seasonal moving average terms&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;“ARIMA(p,d,q)x(P,D,Q)” model&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;P, D and Q should never be larger than 1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;model-fitting-steps-1&quot;&gt;Model fitting steps&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Start by trying various combinations of one seasonal difference and/or one non-seasonal difference to stationarize the series and remove gross features of seasonal pattern.&lt;/li&gt;
  &lt;li&gt;If the seasonal pattern is strong and stable, you MUST use a seasonal difference (otherwise it will “die out” in long-term forecasts)&lt;/li&gt;
  &lt;li&gt;After differencing, inspect the ACF and PACF at
multiples of the seasonal period (s):
    &lt;ul&gt;
      &lt;li&gt;Positive spikes in ACF at lag s, 2s, 3s…, single positive spike in PACF at lag s -&amp;gt; SAR=1&lt;/li&gt;
      &lt;li&gt;Negative spike in ACF at lag s, negative spikes in PACF at lags s, 2s, 3s,… -&amp;gt; SMA=1&lt;/li&gt;
      &lt;li&gt;SMA=1 often works well in conjunction with a seasonal difference.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Same principles as for non-seasonal models, except focused on what happens at multiples of lag &lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt; in ACF and PACF.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;bottom-line-suggestion&quot;&gt;Bottom-line suggestion&lt;/h2&gt;
&lt;p&gt;Strong seasonal pattern, try:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ARIMA(0,1,q)x(0,1,1) model (q=1 or 2)&lt;/li&gt;
  &lt;li&gt;ARIMA(p,0,0)x(0,1,1)+c model (p=1, 2 or 3)&lt;/li&gt;
  &lt;li&gt;If there is a significant trend and/or the seasonal pattern is multiplicative, you should also try a natural log transformation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;take-aways&quot;&gt;Take-aways&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Advantages&lt;/strong&gt;: solid underlying theory, stable estimation of time-varying trends and seasonal patterns, relatively few parameters.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Drawbacks&lt;/strong&gt;: no explicit seasonal indices, hard to interpret coefficients or explain “how the model works”, danger of overfitting or mis-identification if not used with care.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;seasonal-differencing-in-arima-models&quot;&gt;Seasonal differencing in ARIMA models&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Seasonal difference&lt;/strong&gt;: series of changes from one season to the next. i.e. 12 periods in a season -&amp;gt; seasonal difference = &lt;code class=&quot;highlighter-rouge&quot;&gt;Y(t)-Y(t-12)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Usually removes the gross features of seasonality from a series, as well as most of the trend.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;First difference of the seasonal difference&lt;/strong&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;(Y(t)-Y(t-12))-(Y(t-1)-Y(t-13))&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary-of-rules-for-identifying-arima-models&quot;&gt;Summary of rules for identifying ARIMA models&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://people.duke.edu/~rnau/arimrule.htm&quot;&gt;Direct Source for the text below&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;identifying-the-order-of-differencing-and-the-constant&quot;&gt;Identifying the order of differencing and the constant:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Rule 1&lt;/strong&gt;: If the series has positive autocorrelations out to a high number of lags (say, 10 or more), then it probably needs a higher order of differencing.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 2&lt;/strong&gt;: If the lag-1 autocorrelation is zero or negative, or the autocorrelations are all small and patternless, then the series does not need a higher order of differencing. If the lag-1 autocorrelation is -0.5 or more negative, the series may be overdifferenced. &lt;strong&gt;BEWARE OF OVERDIFFERENCING&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 3&lt;/strong&gt;: The optimal order of differencing is often the order of differencing at which the standard deviation is lowest. (Not always, though. Slightly too much or slightly too little differencing can also be corrected with AR or MA terms. See rules 6 and 7.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 4&lt;/strong&gt;: A model with no orders of differencing assumes that the original series is stationary (among other things, mean-reverting). A model with one order of differencing assumes that the original series has a constant average trend (e.g. a random walk or SES-type model, with or without growth). A model with two orders of total differencing assumes that the original series has a time-varying trend (e.g. a random trend or LES-type model).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 5&lt;/strong&gt;: A model with no orders of differencing normally includes a constant term (which allows for a non-zero mean value). A model with two orders of total differencing normally does not include a constant term. In a model with one order of total differencing, a constant term should be included if the series has a non-zero average trend.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;identifying-the-numbers-of-ar-and-ma-terms&quot;&gt;Identifying the numbers of AR and MA terms:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Rule 6&lt;/strong&gt;: If the partial autocorrelation function (PACF) of the differenced series displays a sharp cutoff and/or the lag-1 autocorrelation is positive–i.e., if the series appears slightly “underdifferenced”–then consider adding one or more AR terms to the model. The lag beyond which the PACF cuts off is the indicated number of AR terms.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 7&lt;/strong&gt;: If the autocorrelation function (ACF) of the differenced series displays a sharp cutoff and/or the lag-1 autocorrelation is negative–i.e., if the series appears slightly “overdifferenced”–then consider adding an MA term to the model. The lag beyond which the ACF cuts off is the indicated number of MA terms.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 8&lt;/strong&gt;: It is possible for an AR term and an MA term to cancel each other’s effects, so if a mixed AR-MA model seems to fit the data, also try a model with one fewer AR term and one fewer MA term–particularly if the parameter estimates in the original model require more than 10 iterations to converge. &lt;strong&gt;BEWARE OF USING MULTIPLE AR TERMS AND MULTIPLE MA TERMS IN THE SAME MODEL&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 9&lt;/strong&gt;: If there is a unit root in the AR part of the model–i.e., if the sum of the AR coefficients is almost exactly 1–you should reduce the number of AR terms by one and increase the order of differencing by one.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 10&lt;/strong&gt;: If there is a unit root in the MA part of the model–i.e., if the sum of the MA coefficients is almost exactly 1–you should reduce the number of MA terms by one and reduce the order of differencing by one.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 11&lt;/strong&gt;: If the long-term forecasts* appear erratic or unstable, there may be a unit root in the AR or MA coefficients.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;identifying-the-seasonal-part-of-the-model&quot;&gt;Identifying the seasonal part of the model:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Rule 12&lt;/strong&gt;: If the series has a strong and consistent seasonal pattern, then you must use an order of seasonal differencing (otherwise the model assumes that the seasonal pattern will fade away over time). However, never use more than one order of seasonal differencing or more than 2 orders of total differencing (seasonal+nonseasonal).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 13&lt;/strong&gt;: If the autocorrelation of the appropriately differenced series is positive at lag s, where s is the number of periods in a season, then consider adding an SAR term to the model. If the autocorrelation of the differenced series is negative at lag s, consider adding an SMA term to the model. The latter situation is likely to occur if a seasonal difference has been used, which should be done if the data has a stable and logical seasonal pattern. The former is likely to occur if a seasonal difference has not been used, which would only be appropriate if the seasonal pattern is not stable over time. You should try to avoid using more than one or two seasonal parameters (SAR+SMA) in the same model, as this is likely to lead to overfitting of the data and/or problems in estimation.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;A caveat about long-term forecasting in general&lt;/strong&gt;: linear time series models such as ARIMA and exponential smoothing models predict the more distant future by making a series of one-period-ahead forecasts and plugging them in for unknown future values as they look farther ahead. However, the models are identified and optimized based on their one-period-ahead forecasting performance, and rigid extrapolation of them may not be the best way to forecast many periods ahead (say, more than one year when working with monthly or quarterly business data), particularly when the modeling assumptions are at best only approximately satisfied (which is nearly always the case). If one of your objectives is to generate long-term forecasts, it would be good to also draw on other sources of information during the model selection process and/or to optimize the parameter estimates for multi-period forecasting if your software allows it and/or use an auxiliary model (possibly one that incorporates expert opinion) for long-term forecasting.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;6-choosing-the-right-forecasting-model&quot;&gt;6. Choosing the right forecasting model&lt;/h1&gt;
&lt;h2 id=&quot;steps-in-choosing-a-forecasting-model&quot;&gt;Steps in choosing a forecasting model&lt;/h2&gt;
&lt;h3 id=&quot;deflation&quot;&gt;Deflation?&lt;/h3&gt;
&lt;p&gt;If the series show inflationary growth. Help to account for the growth pattern and reduce heteroscedasticity in the residuals.&lt;/p&gt;
&lt;h3 id=&quot;logarithm-transformation&quot;&gt;Logarithm transformation?&lt;/h3&gt;
&lt;p&gt;If the series shows compound growth and/or a multiplicative seasonal pattern, a logarithm transformation may be helpful in addition to or lieu of deflation. Logging the data will not flatten an inflationary growth pattern, but it will straighten it out it so that it can be fitted by a linear model (e.g., a random walk or ARIMA model with constant growth, or a linear exponential smoothing model).&lt;/p&gt;

&lt;p&gt;Convert multiplicative seasonal patterns to additive patterns, so that if you perform seasonal adjustment after logging, you should use the additive type.&lt;/p&gt;

&lt;p&gt;Another important use for the log transformation is linearizing relationships among variables in a regression model&lt;/p&gt;

&lt;h3 id=&quot;seasonal-adjustment-1&quot;&gt;Seasonal adjustment?&lt;/h3&gt;
&lt;p&gt;If the series has a strong seasonal pattern which is believed to be constant from year to year, seasonal adjustment may be an appropriate way to estimate and extrapolate the pattern.&lt;/p&gt;

&lt;p&gt;The advantage of seasonal adjustment is that it models the seasonal pattern explicitly, giving you the option of studying the seasonal indices and the seasonally adjusted data.&lt;/p&gt;

&lt;p&gt;The disadvantage is that it requires the estimation of a large number of additional parameters (particularly for monthly data), and it provides no theoretical rationale for the calculation of “correct” confidence intervals&lt;/p&gt;

&lt;h3 id=&quot;independent-variables&quot;&gt;Independent variables?&lt;/h3&gt;
&lt;p&gt;If there are other time series which you believe to have explanatory power with respect to your series of interest (e.g., leading economic indicators or policy variables such as price, advertising, promotions, etc.)&lt;/p&gt;

&lt;h3 id=&quot;smoothing-averaging-or-random-walk&quot;&gt;Smoothing, averaging, or random walk?&lt;/h3&gt;
&lt;p&gt;If you have chosen to seasonally adjust the data–or if the data are not seasonal to begin with–then you may wish to use an &lt;strong&gt;averaging or smoothing model&lt;/strong&gt; to fit the nonseasonal pattern which remains in the data at this point&lt;/p&gt;

&lt;p&gt;If smoothing or averaging does not seem to be helpful–i.e., if the best predictor of the next value of the time series is simply its previous value–then a &lt;strong&gt;random walk model&lt;/strong&gt; is indicated.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Brown’s linear exponential smoothing&lt;/strong&gt; can be used to fit a series with slowly time-varying linear trends, but be cautious about extrapolating such trends very far into the future.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Holt’s linear smoothing&lt;/strong&gt; also estimates time-varying trends, but uses separate parameters for smoothing the level and trend, which usually provides a better fit to the data than Brown’s model.&lt;/p&gt;

&lt;h3 id=&quot;winters-seasonal-exponential-smoothing&quot;&gt;Winters Seasonal Exponential Smoothing?&lt;/h3&gt;
&lt;p&gt;Extension of exponential smoothing that simultaneously estimates time-varying level, trend, and seasonal factors using recursive equations. (Thus, if you use this model, you would not first seasonally adjust the data.)&lt;/p&gt;

&lt;p&gt;The Winters seasonal factors can be either multiplicative or additive: normally you should choose the multiplicative option unless you have logged the data. Although the Winters model is clever and reasonably intuitive, it can be tricky to apply in practice: it has three smoothing parameters–alpha, beta, and gamma–for separately smoothing the level, trend, and seasonal factors, which must be estimated simultaneously.&lt;/p&gt;

&lt;h3 id=&quot;arima&quot;&gt;ARIMA?&lt;/h3&gt;
&lt;p&gt;If you do not choose seasonal adjustment (or if the data are non-seasonal), you may wish to use the ARIMA model framework.&lt;/p&gt;

&lt;p&gt;ARIMA models are a very general class of models that includes random walk, random trend, exponential smoothing, and autoregressive models as special cases.&lt;/p&gt;

&lt;p&gt;The conventional wisdom is that a series is a good candidate for an ARIMA model if:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(i) it can be stationarized by a combination of differencing and other mathematical transformations such as logging, and&lt;/li&gt;
  &lt;li&gt;(ii) you have a substantial amount of data to work with: at least 4 full seasons in the case of seasonal data. (If the series cannot be adequately stationarized by differencing–e.g., if it is very irregular or seems to be qualitatively changing its behavior over time–or if you have fewer than 4 seasons of data, then you might be better off with a model that uses seasonal adjustment and some kind of simple averaging or smoothing.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;steps&quot;&gt;Steps&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Determine the appropriate order of differencing needed to stationarize the series and remove the gross features of seasonality&lt;/li&gt;
  &lt;li&gt;Determine whether to include a constant term in the model: usually you do include a constant term if the total order of differencing is 1 or less, otherwise you don’t&lt;/li&gt;
  &lt;li&gt;Choose the numbers of autoregressive and moving average parameters (p, d, q, P, D, Q) that are needed to eliminate any autocorrelation that remains in the residuals of the naive model (i.e., any correlation that remains after mere differencing).&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is usually better to proceed in a forward stepwise rather than backward stepwise fashion when tweaking the model specifications: start with simpler models and only add more terms if there is a clear need.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;forecasting-flow-chart&quot;&gt;Forecasting Flow Chart&lt;/h2&gt;
&lt;p&gt;Source: &lt;a href=&quot;https://people.duke.edu/~rnau/411flow.gif&quot;&gt;https://people.duke.edu/~rnau/411flow.gif&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://people.duke.edu/~rnau/411flow.gif&quot; title=&quot;flow_chart&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;automatic-forecasting-software&quot;&gt;Automatic Forecasting Software&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Properly used, and guided by experience with “manual” model-fitting, the best of such software can put more data-analysis power at your fingertips and speed up routine forecasting applications. Carelessly used, it merely allows you to foul things up in a bigger way, obtaining results without insight while getting a false sense of security that “the computer knows best.” &lt;strong&gt;Automatic forecasting software is a complement to, not a substitute for, your own forecasting expertise.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;how-to-avoid-trouble-principles-of-good-data-analysis&quot;&gt;How to avoid trouble: principles of good data analysis&lt;/h2&gt;
&lt;p&gt;Source: &lt;a href=&quot;https://people.duke.edu/~rnau/notroubl.htm&quot;&gt;https://people.duke.edu/~rnau/notroubl.htm&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Do some background research before running any numbers.  Be sure you understand the objective, the theory, the jargon, and the conventional wisdom. Ask others what they know about the problem. Do more of the same web-searching that brought you to this site, and be critical of everything you find.&lt;/li&gt;
  &lt;li&gt;Be thorough in your search for data.  In the end, your forecasts will contain no information that is not hidden in it somewhere.  In some cases (say, designed experiments) the data may be limited in scope and already in hand, but in many cases it will be up to you to identify and collect it, and this may the most important and time-consuming part of the project.  We now live in the era of “megadata”, but often the data that you need is not so easy to find.&lt;/li&gt;
  &lt;li&gt;Check the data carefully once you have it:  make sure you know where the numbers came from, what they mean, how they were measured, how they are aligned in time, and whether they are accurate. A lot of cleaning and merging of data may be needed before any analysis can begin, and you should know how to do it. You may find that you need yet-more-data or better-quality data to answer the key questions, and sometimes the most useful lesson is that the organization will need to do a better job of managing its data in the future.&lt;/li&gt;
  &lt;li&gt;Use descriptive, self-explanatory names for your variables (not Y’s and X’s or cryptological character strings) so that their meaning and units are clear and so that your computer output is self-documenting to the greatest extent possible.&lt;/li&gt;
  &lt;li&gt;Once you begin your analysis, follow good modeling practices:  perform exploratory data analysis, use appropriate model types, interpret their estimated parameters, check their residual diagnostics, question their assumptions, and validate them with out-of-sample testing where possible.&lt;/li&gt;
  &lt;li&gt;Make effective use of statistical graphics in your own analysis and in your presentation of your results to others, and follow rules of good graphics.  Among other things: graphs should be self-explanatory and not contain visual puzzles, they should have titles that are specific to the variables and models, axes should be well-scaled and well-labeled, the data area should have a white background, grid lines (if any are needed) should not be too dark, point and line widths should be sized appropriately for the density of the data, self-promoting artwork (3-D perspective, etc.) should be avoided, and above all, the data should tell its own story.&lt;/li&gt;
  &lt;li&gt;Keep in mind that not all relationships are linear and additive, not all randomness is normally distributed, and regression models are not magic boxes that can predict anything from anything.  Be aware that it may be necessary to transform some of your variables (through deflating, logging, differencing, etc.) in order to match their patterns up with each other in the way that linear models require.&lt;/li&gt;
  &lt;li&gt;When comparing models, focus on the right objectives, which are usually making the smallest possible errors in the future and deriving inferences that are genuinely useful for decision making.  A good fit to past data does not always guarantee an equally good prediction of what will happen next, and statistical significance is not always the same as practical significance.&lt;/li&gt;
  &lt;li&gt;Other things being equal, KEEP IT SIMPLE and intuitively reasonable. If others don’t understand the model, they may not use it, and perhaps they shouldn’t: simple models often outperform complicated models in practice.&lt;/li&gt;
  &lt;li&gt;If you use automatic forecasting software, you are still responsible for the model that is chosen, and you should be able to explain its logic to others.  The availability of such software does not make it unnecessary to know how the models work.  Rather, it makes that knowledge even more important. Be aware that in automatic rankings of models, there may be only tiny differences in error stats between the winner and its near competitors, and you may need to take other factors into account in your final selection, such as simplicity, clarity, and intuition. And again, your software cannot make something out of nothing. If your data is not informative or not properly organized to begin with, automatic methods will not turn it into gold.&lt;/li&gt;
  &lt;li&gt;Leave a paper trail, i.e., keep well-annotated records of your model-fitting efforts.  Don’t just save your computer files:  write up notes as you go along.  Someone else (who may be a sharp-penciled auditor or perhaps only yourself 12 months hence) may need to reconstruct what you did and why you did it. Intelligent naming of variables and labeling of tables and charts will make this easier.&lt;/li&gt;
  &lt;li&gt;Neither overstate nor understate the accuracy of your forecast, and do not merely give a point value. Always report standard errors and/or confidence intervals.&lt;/li&gt;
  &lt;li&gt;If different forecasting approaches lead to different results, focus on differences in their underlying assumptions, their sources of data, their intrinsic biases, and their respective margins for error.  Don’t just argue over the outputs.  Look for opportunities to combine independent viewpoints and information.&lt;/li&gt;
  &lt;li&gt;After all has been said, if you believe your model is more useful and better supported than the alternatives, stand up for it.  The future may still be very uncertain, but decisions ought to be based on the best understanding of that uncertainty. If you don’t have confidence in your model (or anyone else’s), admit it, and keep digging.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/statistical_forecasting/statistical_forecasting.gif" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/statistical_forecasting/statistical_forecasting.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Introduction to Machine Learning with Python: A Guide for Data Scientists</title><link href="https://millengustavo.github.io/blog/book/machine%20learning/data%20science/2020/01/22/intro-ml-python.html" rel="alternate" type="text/html" title="Introduction to Machine Learning with Python: A Guide for Data Scientists" /><published>2020-01-22T00:00:00-06:00</published><updated>2020-01-22T00:00:00-06:00</updated><id>https://millengustavo.github.io/blog/book/machine%20learning/data%20science/2020/01/22/intro-ml-python</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/machine%20learning/data%20science/2020/01/22/intro-ml-python.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Authors: Andreas C. Müller and Sarah Guido&lt;/p&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;
&lt;h2 id=&quot;why-ml&quot;&gt;Why ML?&lt;/h2&gt;
&lt;p&gt;Using handcoded rules to make decisions has two disadvantages:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;logic is specific to a domain and task. Change the task slightly -&amp;gt; rewrite the whole system&lt;/li&gt;
  &lt;li&gt;designing rules requires a deep understanding of how a decision should be made by a human expert&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;knowing-your-task-and-knowing-your-data&quot;&gt;Knowing your task and knowing your data&lt;/h2&gt;
&lt;p&gt;When building a ML solution:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;What question(s) am I trying to answer? Do I think the data collected can answer that question?&lt;/li&gt;
  &lt;li&gt;What is the best way to phrase my question(s) as a machine learning problem?&lt;/li&gt;
  &lt;li&gt;Have I collected enough data to represent the problem I want to solve?&lt;/li&gt;
  &lt;li&gt;What features of the data did I extract, and will these enable the right predictions?&lt;/li&gt;
  &lt;li&gt;How will I measure success in my application?&lt;/li&gt;
  &lt;li&gt;How will the machine learning solution interact with other parts of my research or business product?&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Many spend a lot of time building complex ML solutions, only to find out they don’t solve the right problem. When going deep into the technical aspects of ML, it is easy to lose sight of the ultimate goals&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;jupyter-notebook&quot;&gt;Jupyter notebook&lt;/h3&gt;
&lt;p&gt;Interactive environment for running code in the browser&lt;/p&gt;

&lt;h3 id=&quot;numpy&quot;&gt;NumPy&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ndarray&lt;/code&gt;: multidimensional (&lt;em&gt;n&lt;/em&gt;) array with elements of the same type&lt;/li&gt;
  &lt;li&gt;high-level mathematical functions, such as linear algebra, Fourier transform, pseudorandom number generators&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scipy&quot;&gt;SciPy&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;scipy.sparse&lt;/code&gt;: provides sparse matrices&lt;/li&gt;
  &lt;li&gt;advanced linear algebra routines, mathematical function optimization, signal processing, statistical distributions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;matplotlib&quot;&gt;Matplotlib&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;On jupyter: &lt;code class=&quot;highlighter-rouge&quot;&gt;%matplotlib inline&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Primary scientific plotting library in Python&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pandas&quot;&gt;Pandas&lt;/h3&gt;
&lt;p&gt;Library for data wrangling and analysis&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt;: allows each column to have a separate type&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mglearn&quot;&gt;mglearn&lt;/h3&gt;
&lt;p&gt;Library of utility functions wrote for this specific book. Avoid boilerplate with plotting and loading data&lt;/p&gt;

&lt;h2 id=&quot;first-things-first-look-at-your-data&quot;&gt;First things first: look at your data&lt;/h2&gt;
&lt;p&gt;Before building a ML model, inspect the data:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;task easily solvable without ML&lt;/li&gt;
  &lt;li&gt;desired information may not be contained in the data&lt;/li&gt;
  &lt;li&gt;find abnormalities and peculiarities&lt;/li&gt;
  &lt;li&gt;real world: inconsistencies in the data and unexpected measurements are very common&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;scatter plot&lt;/em&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;pd.scatter_matrix&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;2-supervised-learning&quot;&gt;2. Supervised Learning&lt;/h1&gt;

&lt;h1 id=&quot;3-unsupervised-learning-and-preprocessing&quot;&gt;3. Unsupervised Learning and Preprocessing&lt;/h1&gt;

&lt;h1 id=&quot;4-representing-data-and-engineering-features&quot;&gt;4. Representing Data and Engineering Features&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Feature engineering&lt;/strong&gt;: how to represent your data best for a particular application -&amp;gt; can have a bigger influence on the performance of a model than the exact parameters you choose&lt;/p&gt;

&lt;h2 id=&quot;categorical-variables&quot;&gt;Categorical Variables&lt;/h2&gt;
&lt;h3 id=&quot;one-hot-encoding-dummy-variables&quot;&gt;One-Hot Encoding (Dummy Variables)&lt;/h3&gt;
&lt;p&gt;Replace a categorical variable with one or more features that can have the values 0 and 1 -&amp;gt; introduce a new feature per category&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In pandas &lt;code class=&quot;highlighter-rouge&quot;&gt;pd.get_dummies(data)&lt;/code&gt; automatically transform all columns that have object type or are categorical&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;numbers-can-encode-categoricals&quot;&gt;Numbers Can Encode Categoricals&lt;/h3&gt;
&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;get_dummies&lt;/code&gt; function in pandas treats all numbers as continuous and will not create dummy variables for them. To get around this, use scikit-learn’s &lt;code class=&quot;highlighter-rouge&quot;&gt;OneHotEncoder&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;binning-discretization-linear-models-and-trees&quot;&gt;Binning, Discretization, Linear Models and Trees&lt;/h3&gt;
&lt;p&gt;One way to make linear models more powerful on continuous data is to use &lt;em&gt;binning&lt;/em&gt; (aka &lt;em&gt;discretization&lt;/em&gt;) of the feature to split it up into multiple features&lt;/p&gt;

&lt;p&gt;Binning features generally has no beneficial effect for tree-based models, as these models can learn to split up the data anywhere&lt;/p&gt;

&lt;h3 id=&quot;interactions-and-polynomials&quot;&gt;Interactions and Polynomials&lt;/h3&gt;
&lt;p&gt;Enrich a feature representation, particularly for linear models, is adding &lt;em&gt;interaction features&lt;/em&gt; and &lt;em&gt;polynomial features&lt;/em&gt; of the original data&lt;/p&gt;

&lt;h3 id=&quot;univariate-nonlinear-transformations&quot;&gt;Univariate Nonlinear Transformations&lt;/h3&gt;
&lt;p&gt;Applying mathematical functions like:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;log&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;exp&lt;/code&gt;: help adjusting the relative scales in the data&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sin&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;cos&lt;/code&gt;: dealing with data that encodes periodic patterns&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most models work best when each feature (and in regression also the target) is loosely Gaussian distributed -&amp;gt; histogram should have something resembling the familiar “bell curve” shape. Using &lt;code class=&quot;highlighter-rouge&quot;&gt;log&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;exp&lt;/code&gt; is a hacky but simple and efficient way to achieve this -&amp;gt; helpful when dealing with integer count data&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;These kind of transformations are irrelevant for tree-based models, but might be essential for linear models. Sometimes it’s also a good idea to transform the target variable in regression&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;automatic-feature-selection&quot;&gt;Automatic Feature Selection&lt;/h2&gt;
&lt;p&gt;Adding more features makes all models more complex, and so increases the chance of overfitting&lt;/p&gt;

&lt;p&gt;It can be good idea to reduce the number of features to only the most useful ones, and discard the rest&lt;/p&gt;

&lt;h3 id=&quot;univariate-statistics&quot;&gt;Univariate Statistics&lt;/h3&gt;
&lt;p&gt;Compute whether there is a statistically significant relationship between each feature and the target -&amp;gt; the features with highest confidence are selected. Also know as &lt;em&gt;analysis of variance&lt;/em&gt; (ANOVA) for classification&lt;/p&gt;

&lt;p&gt;Only consider each feature individually. &lt;em&gt;f_classify&lt;/em&gt; or &lt;em&gt;f_regression&lt;/em&gt; tests in scikit-learn and then &lt;em&gt;SelectKBest&lt;/em&gt; or &lt;em&gt;SelectPercentile&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;model-based-feature-selection&quot;&gt;Model-Based Feature Selection&lt;/h3&gt;
&lt;p&gt;Uses a supervised ML model to judge the importance of each feature, and keeps only the most important ones&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Decision tree-based models: &lt;em&gt;feature_importances_&lt;/em&gt; attribute&lt;/li&gt;
  &lt;li&gt;Linear models: coefficients can capture feature importances&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Model-based considers all features at once, so can capture interactions. &lt;em&gt;SelectFromModel&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SelectFromModel&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.ensemble&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SelectFromModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;RandomForestClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;median&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;iterative-feature-selection&quot;&gt;Iterative Feature Selection&lt;/h3&gt;
&lt;p&gt;A series of models are built, with varying numbers of features. Two methods:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;starting with no features and adding one by one&lt;/li&gt;
  &lt;li&gt;starting with all features and removing one by one&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More computationally expensive&lt;/p&gt;

&lt;p&gt;&lt;em&gt;recursive feature elimination&lt;/em&gt; (RFE): starts with all features, builds a model, and discards the least important feature according to the model -&amp;gt; repeat&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Feature Selection&lt;/strong&gt;: Can speed up prediction, allow for more interpretable model. In most real-world cases, is unlikely to provide large gains in performance&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;utilizing-expert-knowledge&quot;&gt;Utilizing Expert Knowledge&lt;/h2&gt;
&lt;p&gt;Prior knowledge about the nature of the task can be encoded in the features to aid a ML algorithm&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Adding a feature does not force a machine learning algorithm to use it, and even if the holiday information turns out to be noninformative for flight prices, augmenting the data with this information doesn’t hurt.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;COOL example with bike rental on the book -&amp;gt; check to see the coefficients learned by the linear model&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;5-model-evaluation-and-improvement&quot;&gt;5. Model Evaluation and Improvement&lt;/h1&gt;
&lt;h2 id=&quot;cross-validation&quot;&gt;Cross-Validation&lt;/h2&gt;
&lt;p&gt;Data is split repeatedly and multiple models are trained. Most common: &lt;em&gt;k-fold cross-validation&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Scikit-learn: &lt;code class=&quot;highlighter-rouge&quot;&gt;cross_val_score&lt;/code&gt; from the &lt;em&gt;model_seleciton&lt;/em&gt; module&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;High variance in the metric (e.g., accuracy) between folds -&amp;gt; model is very dependent on the particular folds for train, or it could also be consequence of the small size of the dataset&lt;/p&gt;

&lt;h3 id=&quot;benefits-of-cross-validation&quot;&gt;Benefits of Cross-Validation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;avoid “lucky”/”unlucky” random train_test_split&lt;/li&gt;
  &lt;li&gt;in cross-validation each example will be in the training set exactly once: each example is in one of the folds, and each fold is the test set once -&amp;gt; the model needs to generalize well to all of the samples in the dataset for all of the cross-validation scores to be high&lt;/li&gt;
  &lt;li&gt;multiple splits provides information about how sensitive the model is to the selection of the training set -&amp;gt; idea of the best/worst case scenarios&lt;/li&gt;
  &lt;li&gt;use data more effectively: more data usually leads to more accurate models&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Disadvantage: increased computational cost -&amp;gt; train &lt;em&gt;k&lt;/em&gt; models instead of one&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Cross-validation does not return a model, its purpose is only to evaluate how well a given algorithm will generalize when trained on a specific dataset&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;stratified-k-fold-cross-validation&quot;&gt;Stratified k-Fold Cross-Validation&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Stratified k-fold cross-validation&lt;/em&gt;: split the data such that the proportions between classes are the same in each fold as they are in the whole dataset&lt;/p&gt;

&lt;p&gt;Results in more reliable estimates of generalization performance&lt;/p&gt;

&lt;p&gt;For regression scikit-learn uses the standard &lt;em&gt;k-fold cross-validation&lt;/em&gt; by default&lt;/p&gt;

&lt;h3 id=&quot;leave-one-out-cross-validation&quot;&gt;Leave-one-out cross-validation&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;k-fold cross-validation&lt;/em&gt; where each fold is a single sample. &lt;code class=&quot;highlighter-rouge&quot;&gt;LeaveOneOut&lt;/code&gt; on sklearn.model_selection&lt;/p&gt;

&lt;p&gt;Can be very time consuming for large datasets, but sometimes provides better estimates on small datasets&lt;/p&gt;

&lt;h3 id=&quot;shuffle-split-cross-validation&quot;&gt;Shuffle-split cross-validation&lt;/h3&gt;
&lt;p&gt;Each split samples train_size many points for the training set and test_size many (disjoint) points for the test set. This splitting is repeated n_iter times&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;allows for control over the number of iterations independently of the training and test sizes&lt;/li&gt;
  &lt;li&gt;allows for using only part of the data in each iteration by providing train_size and test_size that don’t add up to one -&amp;gt; subsampling like that can be useful for experimenting with large datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleSplit&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;StratifiedShuffleSplit&lt;/code&gt; on sklearn&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;cross-validation-with-groups&quot;&gt;Cross-validation with groups&lt;/h3&gt;
&lt;p&gt;When there are groups in the data that are highly related&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GroupKFold&lt;/code&gt;: takes an array of groups as arguments -&amp;gt; indicates groups in the data that should not be split when creating the training and test sets, and should not be confused with the class label&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;GroupKFold: important for medical applications (multiple samples for same patient), also speech recognition&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;grid-search&quot;&gt;Grid Search&lt;/h2&gt;
&lt;p&gt;Trying all possible combinations of the parameters of interest&lt;/p&gt;

&lt;h3 id=&quot;the-danger-of-overfitting-the-parameters-and-the-validation-set&quot;&gt;The danger of overfitting the parameters and the validation set&lt;/h3&gt;
&lt;p&gt;To avoid this split the data in three sets: the training set to build the model, the validation (or development) set to select the parameters of the model, and the test set to evaluate the performance of the selected parameters&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;After selecting the best parameters using the validation set, rebuild the model using the parameter settings found, but now training on both the training data and the validation data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Important to keep the distinction of training, validation and test sets clear!&lt;/strong&gt; Evaluating more than one model on the test set and choosing the better of the two will result in an overly optimistic estimate of how accurate the model is -&amp;gt; “Leak” information from the test set into the model&lt;/p&gt;

&lt;h3 id=&quot;grid-search-with-cross-validation&quot;&gt;Grid Search with Cross-Validation&lt;/h3&gt;
&lt;p&gt;Beautiful plot from &lt;code class=&quot;highlighter-rouge&quot;&gt;mglearn&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mglearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plots&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_cross_val_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GridSearchCV&lt;/code&gt; on sklearn: implemented in the form of an estimator -&amp;gt; not only searchs for the best parameters, but also automatically fits a new model on the whole training dataset with the parameters that yielded the best CV performance&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;best_score_&lt;/code&gt; != &lt;code class=&quot;highlighter-rouge&quot;&gt;score&lt;/code&gt;: first stores the mean CV accuracy performed in the training set, second evaluate the output of the predict method of the model trained on the whole training set!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;analyzing-the-result-of-cross-validation&quot;&gt;Analyzing the result of cross-validation&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# cool example of a heatmap using SVM
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mglearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heatmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gamma'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xticklabels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gamma'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'C'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yticklabels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'C'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;viridis&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Optimum values for each parameter on the edges of the plot: parameters not large enough!&lt;/p&gt;

&lt;h2 id=&quot;nested-cross-validation&quot;&gt;Nested cross-validation&lt;/h2&gt;
&lt;p&gt;An outer loop over splits of the data into training and test sets. For each of them, a grid search is run (which might result in different best parameters for each split in the outer loop). Then, for each outer split, the test set score using the best settings is reported&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Rarely used in practice&lt;/li&gt;
  &lt;li&gt;Useful for evaluating how well a given model works on a particular dataset&lt;/li&gt;
  &lt;li&gt;Computationally expensive procedure&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# example of nested CV
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross_val_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;evaluation-metrics-and-scoring&quot;&gt;Evaluation Metrics and Scoring&lt;/h2&gt;
&lt;h3 id=&quot;keep-the-end-goal-in-mind&quot;&gt;Keep the end goal in mind&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Business metric&lt;/em&gt;: We are interested in using the predictions as part of a larger decision-making process, you should think about the high-level goal of the application&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Business impact&lt;/em&gt;: consequences of choosing a particular algorithm for a ML application&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When choosing a model or adjusting parameters, you should pick the model or parameter values that have the most positive influence on the business metric&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sometimes infeasible to put models in production just for testing purposes (high business risk): find some surrogate evaluation procedure (as close as possible to the business goal), using an evaluation metric that is easier to compute&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;metrics-for-binary-classification&quot;&gt;Metrics for binary classification&lt;/h2&gt;
&lt;h3 id=&quot;kinds-of-errors&quot;&gt;Kinds of errors&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;false positive&lt;/strong&gt;: incorrect positive prediction, &lt;strong&gt;type I error&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;false negative&lt;/strong&gt;: incorrect negative prediction, &lt;strong&gt;type II error&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;imbalanced-datasets&quot;&gt;Imbalanced datasets&lt;/h3&gt;
&lt;p&gt;Accuracy is an inadequate measure for quantifying predictive performance in most imbalanced settings&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pred_most_frequent&lt;/code&gt;: model that make predictions to the most frequent class&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pred_dummy&lt;/code&gt;: random predictions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;confusion-matrices&quot;&gt;Confusion matrices&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;confusion_matrix&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;rows: true classes&lt;/li&gt;
  &lt;li&gt;columns: predicted classes&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;negative class&lt;/td&gt;
      &lt;td&gt;TN&lt;/td&gt;
      &lt;td&gt;FP&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;positive class&lt;/td&gt;
      &lt;td&gt;FN&lt;/td&gt;
      &lt;td&gt;TP&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;predicted negative&lt;/td&gt;
      &lt;td&gt;predicted positive&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Accuracy = (TP+TN)/(TP+TN+FP+FN)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Precision = (TP)/(TP+FP)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Precision is used when the goal is to limit the number of false positives. AKA &lt;em&gt;positive predictive value (PPV)&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recall = (TP)/(TP+FN)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recall is used when we need to identify all positive samples; that is, when it is important to avoid false negatives. AKA &lt;em&gt;sensitivity&lt;/em&gt;, &lt;em&gt;hit rate&lt;/em&gt;, or &lt;em&gt;true positive rate (TPR)&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;F-score or f-measure or f1-score -&amp;gt; F = 2&lt;em&gt;(precision&lt;/em&gt;recall)/(precision+recall)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Harmonic mean of precision and recall&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification_report&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;taking-uncertainty-into-account&quot;&gt;Taking uncertainty into account&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;You can change the decision threshold depending on the problem&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;calibration&lt;/em&gt;: a calibrated model is a model that provides an accurate measure of its uncertainty&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;precision-recall-curves-and-roc-curves&quot;&gt;Precision-recall curves and ROC curves&lt;/h3&gt;
&lt;p&gt;Setting a requirement on a classifier like 90% recall is often called setting the &lt;em&gt;operation point&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Precision-recall curve: look at all possible thresholds, or all possible trade-offs of precision and recalls at once. &lt;code class=&quot;highlighter-rouge&quot;&gt;precision_recall_curve&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Average precision&lt;/em&gt;: Area under the precision-recall curve. &lt;code class=&quot;highlighter-rouge&quot;&gt;average_precision_score&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Receiver operating characteristics (ROC) curve: consider all possible thresholds for a given classifier, shows the &lt;em&gt;false positive rate (FPR)&lt;/em&gt; against the &lt;em&gt;true positive rate (TPR)&lt;/em&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;roc_curve&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TPR = recall = (TP)/(TP+FN)&lt;/li&gt;
  &lt;li&gt;FPR = (FP)/(FP+TN)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Average precision always returns a value between 0 (worst) and 1 (best). Predicting randomly always produces an AUC of 0.5 -&amp;gt; AUC is much better than accuracy as a metric for imbalanced datasets&lt;/p&gt;

&lt;p&gt;AUC: evaluating the ranking of positive samples. Probability that a randomly picked point of the positive class will have a higher score according to the classifier than a randomly picked point from the negative class&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;AUC does not make use of the default threshold, so adjusting the decision threshold might be necessary to obtain useful classification results from a model with a high AUC&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;metrics-for-multiclass-classification&quot;&gt;Metrics for Multiclass Classification&lt;/h2&gt;
&lt;p&gt;Metrics for multiclass classification are derived from binary, but averaged over all classes&lt;/p&gt;

&lt;p&gt;For imbalanced datasets: multiclass f-score -&amp;gt; one binary f-score per class (that being the positive) and others being the negative -&amp;gt; then average these per-class f-scores&lt;/p&gt;

&lt;h2 id=&quot;regression-metrics&quot;&gt;Regression metrics&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Rˆ2 is enough for most applications&lt;/li&gt;
  &lt;li&gt;Mean squared error (MSE)&lt;/li&gt;
  &lt;li&gt;Mean absolute error (MAE)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;using-evaluation-metrics-in-model-selection&quot;&gt;Using evaluation metrics in model selection&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;scoring&lt;/code&gt; parameters for classification:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;accuracy&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;roc_auc&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;average_precision&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;f1&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;f1_macro&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;f1_micro&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;f1_weighted&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;for regression:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;r2&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mean_squared_error&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mean_absolute_error&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;for more, see: &lt;code class=&quot;highlighter-rouge&quot;&gt;sklearn.metrics.scores&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&quot;6-algorithm-chains-and-pipelines&quot;&gt;6. Algorithm Chains and Pipelines&lt;/h1&gt;
&lt;p&gt;ML algorithms requires chaining together many different processing steps and ML models. &lt;code class=&quot;highlighter-rouge&quot;&gt;Pipeline&lt;/code&gt; class simplify the process of building chains of transformations and models&lt;/p&gt;

&lt;h2 id=&quot;parameter-selection-with-preprocessing&quot;&gt;Parameter selection with preprocessing&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mglearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plots&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_improper_processing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Splitting the dataset during cross-validation should be done &lt;em&gt;before doing any preprocessing&lt;/em&gt;. Any process that extracts knowledge from the dataset should only ever be applied to the training portion of the dataset, so any CV should be the “outermost loop” in your processing&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;building-pipelines&quot;&gt;Building Pipelines&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.pipeline&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pipeline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;scaler&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StandardScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;lr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;reduce the code needed for “preprocessing + classification”&lt;/li&gt;
  &lt;li&gt;main benefit: now you can use this single estimator in &lt;code class=&quot;highlighter-rouge&quot;&gt;cross_val_score&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;GridSearchCV&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;For each split in the CV, the Scaler is refit with only the training splits and no information is leaked from the test split in to the parameter search&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;information-leakage&quot;&gt;Information Leakage&lt;/h2&gt;
&lt;p&gt;The impact varies depending on the preprocessing step:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;estimating the scale of the data using the test fold usually doesn’t have a terrible impact&lt;/li&gt;
  &lt;li&gt;using the test fold in feature extraction and feature selection can lead to &lt;strong&gt;substantial differences&lt;/strong&gt; in outcomes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-general-pipeline-interface&quot;&gt;The General Pipeline Interface&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;not restricted to preprocessing and classification&lt;/li&gt;
  &lt;li&gt;only requirement: all estimators but the last step need to have a transform method&lt;/li&gt;
  &lt;li&gt;during &lt;code class=&quot;highlighter-rouge&quot;&gt;Pipeline.fit&lt;/code&gt;, the pipeline calls fit and then transform on each step; for the last step, just fit is called&lt;/li&gt;
  &lt;li&gt;when predicting, we similarly transform the data using all but the last step, and then call predict on the last step&lt;/li&gt;
  &lt;li&gt;there is no requirement to have predict in the last step; the last step is only required to have a fit method&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;convenient-pipeline-creation-with-make_pipeline&quot;&gt;Convenient pipeline creation with make_pipeline&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.pipeline&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_pipeline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pipe_short&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StandardScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;accessing-step-attributes&quot;&gt;Accessing step attributes&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;named_steps&lt;/code&gt; attribute -&amp;gt; dictionary from the step names to estimators&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;named_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pca&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;components_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_estimator_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;named_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;logisticregression&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;grid-searching-which-model-to-use&quot;&gt;Grid-Searching Which Model to Use&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;preprocessing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StandardScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;classifier&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())])&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.ensemble&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RandomForestClassifier&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'classifier'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'preprocessing'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StandardScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
     &lt;span class=&quot;s&quot;&gt;'classifier__gamma'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
     &lt;span class=&quot;s&quot;&gt;'classifier__C'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'classifier'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RandomForestClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
     &lt;span class=&quot;s&quot;&gt;'preprocessing'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'classifier__max_features'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cancer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cancer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;7-working-with-text-data&quot;&gt;7. Working with Text Data&lt;/h1&gt;

&lt;h1 id=&quot;8-wrapping-up&quot;&gt;8. Wrapping Up&lt;/h1&gt;
&lt;h2 id=&quot;approaching-a-ml-problem&quot;&gt;Approaching a ML problem&lt;/h2&gt;
&lt;p&gt;It may be tempting to jump in and starting solving you data-related problem by running your favorite algorithm&lt;/p&gt;

&lt;p&gt;To make effective use of ML, we need to take a step back and consider the problem at large. First, you should think what kind of question you want to answer&lt;/p&gt;

&lt;p&gt;It is best if you can measure the performance of your algorithm directly using a business metric&lt;/p&gt;

&lt;p&gt;Collecting more or different data or changing the task formulation slightly might provide a much higher payoff than running endless grid searches to tune parameters&lt;/p&gt;

&lt;h3 id=&quot;humans-in-the-loop&quot;&gt;Humans in the loop&lt;/h3&gt;
&lt;p&gt;Many applications are dominated by “simple cases”, for which an algorithm can make a decision, with relatively few “complicated cases”, which can be rerouted to a human&lt;/p&gt;

&lt;h2 id=&quot;from-prototype-to-production&quot;&gt;From prototype to production&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Production systems have differente requirements from one-off analysis scripts&lt;/li&gt;
  &lt;li&gt;reliability, predictability, runtime, and memory requirements gain relevance&lt;/li&gt;
  &lt;li&gt;simplicity is key&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;testing-production-systems&quot;&gt;Testing production systems&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;offline evaluation: test set collected beforehand&lt;/li&gt;
  &lt;li&gt;online/live testing: consequences of employing the algorithm in the overall system are evaluated&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;A/B testing&lt;/strong&gt;: enables us to evaluate the algorithms “in the wild”, which might help us to discover unexpected consequences when users are interacting with our model&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bandit algorithms&lt;/strong&gt;: more elaborate mechanisms for online testing that go beyond A/B testing&lt;/p&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/intro_ml_python/intro_ml_python.jpeg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/intro_ml_python/intro_ml_python.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>