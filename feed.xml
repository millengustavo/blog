<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://millengustavo.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://millengustavo.github.io/blog/" rel="alternate" type="text/html" /><updated>2021-04-05T07:04:48-05:00</updated><id>https://millengustavo.github.io/blog/feed.xml</id><title type="html">Gustavo Millen</title><subtitle>Data Science and Machine Learning blog.</subtitle><entry><title type="html">IBGE Censo - Associando Localização com Setores Censitários</title><link href="https://millengustavo.github.io/blog/dados%20p%C3%BAblicos/machine%20learning/python/data%20science/2021/04/04/ibge-censo-cep-coordenadas.html" rel="alternate" type="text/html" title="IBGE Censo - Associando Localização com Setores Censitários" /><published>2021-04-04T00:00:00-05:00</published><updated>2021-04-04T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/dados%20p%C3%BAblicos/machine%20learning/python/data%20science/2021/04/04/ibge-censo-cep-coordenadas</id><content type="html" xml:base="https://millengustavo.github.io/blog/dados%20p%C3%BAblicos/machine%20learning/python/data%20science/2021/04/04/ibge-censo-cep-coordenadas.html">&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ibge_censo/geospatial_plot.png&quot; alt=&quot;geospatial_plot&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;o-censo-do-ibge&quot;&gt;O Censo do IBGE&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Em 2010, o IBGE realizou o XII Censo Demográfico, que se constituiu no grande retrato em extensão e profundidade da população brasileira e das suas características sócio-econômicas e, ao mesmo tempo, na base sobre a qual deverá se assentar todo o planejamento público e privado da próxima década. 
O Censo 2010 é um retrato de corpo inteiro do país com o perfil da população e as características de seus domicílios, ou seja, ele nos diz como somos, onde estamos e como vivemos.” - &lt;a href=&quot;https://censo2010.ibge.gov.br/sobre-censo.html&quot;&gt;https://censo2010.ibge.gov.br/sobre-censo.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para tomar decisões mais assertivas baseadas em dados, dependemos de informações diversas e ricas. Um dado que é comumente requisitado ao usuário para o fornecimento de serviços é o código postal (CEP) ou algum identificador de localização (coordenadas geográficas, endereço, etc). Esse dado deve ser armazenado com precisão reduzida para preservar a privacidade do usuário, mas ainda tem muito valor por levar a associações esclarecedoras, ainda que aproximadas.&lt;/p&gt;

&lt;p&gt;Do Censo de 2010 do IBGE, temos os códigos dos setores censitários, seus polígonos baseados em coordenadas que delimitam regiões brasileiras, e as mais variadas respostas a perguntas sócio-econômicas. Entre essas respostas temos por exemplo a renda, o número de pessoas, o número de banheiros nos domicílios, entre outros. Essas informações são de 2010, portanto alguns ajustes devem ser feitos nas análises.&lt;/p&gt;

&lt;h1 id=&quot;geopandas&quot;&gt;GeoPandas&lt;/h1&gt;

&lt;p&gt;Para utilizarmos os dados do Censo com dados de localização podemos utilizar uma ferramenta poderosa, o &lt;em&gt;GeoPandas&lt;/em&gt;. Ele permite que façamos o &lt;a href=&quot;https://geopandas.org/gallery/spatial_joins.html&quot;&gt;Spatial Join&lt;/a&gt;, associando pontos de coordenadas (longitude e latitude) aos seus respectivos polígonos e consequentemente ao seu código de setor censitário.&lt;/p&gt;

&lt;p&gt;Com os códigos para cada localização, as análises posteriores podem ser feitas com um simples join dos agregados usando o código de setor censitário como chave.&lt;/p&gt;

&lt;h1 id=&quot;dataset-no-kaggle&quot;&gt;Dataset no Kaggle&lt;/h1&gt;

&lt;p&gt;Disponibilizei no Kaggle um exemplo de aplicação com CEP, coordenadas, código de setor censitário e renda per capita aproximada. 
&lt;a href=&quot;https://www.kaggle.com/silveiragustavo/ibge-censo-cep-coordenadas-renda-per-capita&quot;&gt;https://www.kaggle.com/silveiragustavo/ibge-censo-cep-coordenadas-renda-per-capita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;O código usado para construir essa base também está aberto no meu Github:
&lt;a href=&quot;https://github.com/millengustavo/ibge-censo-cep-coordenadas&quot;&gt;https://github.com/millengustavo/ibge-censo-cep-coordenadas&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;fairness-em-machine-learning&quot;&gt;Fairness em Machine Learning&lt;/h1&gt;

&lt;p&gt;É sempre válido lembrar que o analista/cientista que manipula esses dados tem a responsabilidade moral e ética de tratar os indivíduos de forma igualitária ou de forma correta/razoável, o chamado &lt;strong&gt;Fairness&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Isso é especialmente importante para algoritmos de Machine Learning cujas decisões podem privar determinados indivíduos do acesso a serviços ou oportunidades. Esse tema é crucial para a construção de um futuro mais justo. Como introdução aos estudos no tema recomendo a talk da Tatyana Zabanova, &lt;a href=&quot;https://www.youtube.com/watch?v=LWt4LZmpasc&quot;&gt;“Fairness em Machine Learning Nubank ML Meetup”&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/ibge_censo/geospatial_plot.png" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/ibge_censo/geospatial_plot.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Federated Learning of Cohorts (FLoC) - Google’s solution for interest based advertising in a world without third-party cookies</title><link href="https://millengustavo.github.io/blog/advertising/machine%20learning/python/data%20science/2021/03/14/floc-experiment.html" rel="alternate" type="text/html" title="Federated Learning of Cohorts (FLoC) - Google's solution for interest based advertising in a world without third-party cookies" /><published>2021-03-14T00:00:00-06:00</published><updated>2021-03-14T00:00:00-06:00</updated><id>https://millengustavo.github.io/blog/advertising/machine%20learning/python/data%20science/2021/03/14/floc-experiment</id><content type="html" xml:base="https://millengustavo.github.io/blog/advertising/machine%20learning/python/data%20science/2021/03/14/floc-experiment.html">&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/floc_experiment/food-photographer-jennifer-pallian-OfdDiqx8Cz8-unsplash.jpg&quot; alt=&quot;cookie_photo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@foodess?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Food Photographer | Jennifer Pallian&lt;/a&gt; on &lt;a href=&quot;/s/photos/cookie?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The code is available here &lt;a href=&quot;https://github.com/millengustavo/floc-experiment&quot;&gt;https://github.com/millengustavo/floc-experiment&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-end-of-third-party-cookies-for-advertisers&quot;&gt;The end of third-party cookies for advertisers&lt;/h1&gt;

&lt;p&gt;Third-party cookies have (since 1994) been a key enabler of the commercial Internet and &lt;strong&gt;fine-grained digital ad targeting&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;They have helped achieve &lt;strong&gt;unprecedented audience segmentation and attribution&lt;/strong&gt; - helping to connect marketing tactics with results in ways that were virtually impossible in the most traditional forms of media.&lt;/p&gt;

&lt;p&gt;To bring users more transparency and better consent management, most browsers are ending support for third-party cookies.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://venturebeat.com/2020/08/04/mozilla-firefox-79/&quot;&gt;Firefox 79 clears redirect tracking cookies every 24 hours&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.theverge.com/2020/6/22/21299407/apple-ios-14-new-privacy-features-data-location-tracking-premissions-wwdc-2020&quot;&gt;Apple teases new tracking protections and an approximate location feature in iOS 14&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.chromium.org/2020/01/building-more-private-web-path-towards.html&quot;&gt;Google has announced plans to stop supporting third-party cookies on its Chrome browser in 2021&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some alternatives are being proposed to replace the need for third-party cookies, ensuring users’ privacy, but without loss of performance for advertisers.&lt;/p&gt;

&lt;p&gt;In this post you will learn a little more about &lt;strong&gt;Federated Learning of Cohorts (FLoC)&lt;/strong&gt;, an alternative proposed by Google, and we will navigate through a simplified demonstration of the algorithm using a public dataset.&lt;/p&gt;

&lt;h1 id=&quot;federated-learning-of-cohorts-floc&quot;&gt;Federated Learning of Cohorts (FLoC)&lt;/h1&gt;

&lt;h2 id=&quot;goal&quot;&gt;Goal&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;“Preserve interest based advertising, but in a privacy-preserving manner”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Relies on a &lt;strong&gt;cohort&lt;/strong&gt; assigning mechanism: a function that allocates a cohort id to a user based on their &lt;strong&gt;browsing history&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;This cohort id &lt;strong&gt;must be shared by at least k distinct users&lt;/strong&gt; for privacy&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;privacy-x-utility&quot;&gt;Privacy x Utility&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;“The more users share a cohort id, the &lt;strong&gt;harder it is to derive individual&lt;/strong&gt; user’s behavior from across the web. On the other hand, a large cohort is more likely to have a diverse set of users, thus making it harder to use this information for &lt;strong&gt;fine-grained ads personalization&lt;/strong&gt; purposes.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Ideal cohort assignment&lt;/strong&gt;: group together a large number of users interested in similar things&lt;/p&gt;

&lt;h2 id=&quot;intersections-with-data-science&quot;&gt;Intersections with Data Science&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://federated.withgoogle.com/&quot;&gt;Federated Learning&lt;/a&gt;: machine learning technique that trains an algorithm across multiple decentralized edge devices or servers holding local data samples, &lt;strong&gt;without exchanging them&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Cohort assignment algorithm should be &lt;strong&gt;unsupervised&lt;/strong&gt;, since each provider has their own optimization function&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;evaluating-googles-approach-on-a-public-dataset&quot;&gt;Evaluating Google’s approach on a public dataset&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Let’s evaluate &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/pt-BR//pubs/archive/33026.pdf&quot;&gt;SimHash&lt;/a&gt; (originally developed to identify near duplicate documents quickly) proposed in the FLoC whitepaper as a cohort assignment mechanism using the dataset &lt;strong&gt;MovieLens 25M&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“MovieLens 25M movie ratings. Stable benchmark dataset. 25 million ratings and one million tag applications applied to 62,000 movies by 162,000 users.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;installing-the-simhash-python-package&quot;&gt;Installing the SimHash Python package&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scrapinghub&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simhash&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simhash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiLabelBinarizer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;wordcloud&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WordCloud&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;simhash&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weighted_fingerprint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fnvhash&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;downloading-movielens-25m&quot;&gt;Downloading MovieLens 25m&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grouplens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movielens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ml&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;certificate&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unzip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ml&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ml-25m/movies.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ratings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ml-25m/ratings.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# join movie genres with user ratings
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;movieId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;rating&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;movieId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;genres&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;movieId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;genres&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;genres&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;|&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create a genre per column dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mlb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiLabelBinarizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparse_output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_spmatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mlb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;genres&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mlb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# multiply user rating to each genre to give us an idea of a weighted genre vector for each user
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_genres&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;movieId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;rating&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;genre&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_genres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;genre&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;rating&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;genre&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;genre&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;genre&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;int8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute each users' mean genre vector
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;rating&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;movieId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;simhash&quot;&gt;SimHash&lt;/h2&gt;

&lt;p&gt;Having computed each users’ mean genre vector preferences, we can compute the SimHash on this vector, so each user interest will be represented by some hash of all of his preferences combined (with collisions).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;simhash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weighted_fingerprint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fnvhash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hash'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simhash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;We can see that we have a lot of collisions using SimHash, but this is expected, since many users share similar preferences and our choice of hashing algorithm is intentional&lt;/li&gt;
  &lt;li&gt;SimHash is computationally inexpensive by design, not caring too much about hash collisions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;defining-a-limited-number-of-cohorts-for-demonstration-purposes&quot;&gt;Defining a limited number of cohorts for demonstration purposes&lt;/h2&gt;

&lt;p&gt;Ideally, a cohort groups together a large number of users interested in similar things so that we can correctly target advertising that interests that group of people.&lt;/p&gt;

&lt;p&gt;Next, we will limit the number of cohorts arbitrarily to five so that we can visually identify common preferences. In a real scenario, we would have another type of “hash grouping” to meet privacy and performance requirements.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cluster&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hash&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformed_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hash'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cluster'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weighted_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;visualizing-the-cohorts&quot;&gt;Visualizing the cohorts&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;plot_cluster_wordcloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cluster_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weighted_results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weighted_results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'records'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;wordcloud&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WordCloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;450&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;background_color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;white&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generate_from_frequencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wordcloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;off&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;cohort-1&quot;&gt;Cohort 1&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Action, Adventure, Western, IMAX&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plot_cluster_wordcloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/floc_experiment/cluster_1.png&quot; alt=&quot;cluster_1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cohort-2&quot;&gt;Cohort 2&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Drama, Romance&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plot_cluster_wordcloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/floc_experiment/cluster_2.png&quot; alt=&quot;cluster_2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cohort-3&quot;&gt;Cohort 3&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Crime, Documentary, Mistery, Film-Noir&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plot_cluster_wordcloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/floc_experiment/cluster_3.png&quot; alt=&quot;cluster_3&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cohort-4&quot;&gt;Cohort 4&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Horror, Sci-Fi, Thriller&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plot_cluster_wordcloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/floc_experiment/cluster_4.png&quot; alt=&quot;cluster_4&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cohort-5&quot;&gt;Cohort 5&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Animation, Children, Comedy, Fantasy, Musical&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plot_cluster_wordcloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/floc_experiment/cluster_5.png&quot; alt=&quot;cluster_5&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;With the growing concern for users’ privacy, some machine learning techniques have shown promise. &lt;strong&gt;Federated learning&lt;/strong&gt; seems to be an interesting alternative for this type of application and it is worth studying it further.&lt;/p&gt;

&lt;p&gt;I recommend that you read more about &lt;a href=&quot;https://blog.google/products/ads-commerce/2021-01-privacy-sandbox&quot;&gt;Privacy Sandbox&lt;/a&gt;, Chrome’s initiative to, according to Google, “help publishers and advertisers succeed, while protecting people’s privacy.”&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.deloittedigital.com/us/en/blog-list/2020/what-the-end-of-third-party-cookies-means-for-advertisers.html&quot;&gt;https://www.deloittedigital.com/us/en/blog-list/2020/what-the-end-of-third-party-cookies-means-for-advertisers.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://venturebeat.com/2020/08/04/mozilla-firefox-79/&quot;&gt;https://venturebeat.com/2020/08/04/mozilla-firefox-79/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.theverge.com/2020/6/22/21299407/apple-ios-14-new-privacy-features-data-location-tracking-premissions-wwdc-2020&quot;&gt;https://www.theverge.com/2020/6/22/21299407/apple-ios-14-new-privacy-features-data-location-tracking-premissions-wwdc-2020&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.chromium.org/2020/01/building-more-private-web-path-towards.html&quot;&gt;https://blog.chromium.org/2020/01/building-more-private-web-path-towards.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/google/ads-privacy/blob/master/proposals/FLoC/FLOC-Whitepaper-Google.pdf&quot;&gt;https://github.com/google/ads-privacy/blob/master/proposals/FLoC/FLOC-Whitepaper-Google.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.google/products/ads-commerce/2021-01-privacy-sandbox&quot;&gt;https://blog.google/products/ads-commerce/2021-01-privacy-sandbox&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/scrapinghub/python-simhash&quot;&gt;https://github.com/scrapinghub/python-simhash&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/federated-learning-of-cohorts-googles-cookie-killer-7f63b2395173&quot;&gt;https://towardsdatascience.com/federated-learning-of-cohorts-googles-cookie-killer-7f63b2395173&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/floc_experiment/cookie.png" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/floc_experiment/cookie.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Machine Learning Engineering</title><link href="https://millengustavo.github.io/blog/book/machine%20learning%20engineering/python/data%20science/2021/01/30/ml-engineering.html" rel="alternate" type="text/html" title="Machine Learning Engineering" /><published>2021-01-30T00:00:00-06:00</published><updated>2021-01-30T00:00:00-06:00</updated><id>https://millengustavo.github.io/blog/book/machine%20learning%20engineering/python/data%20science/2021/01/30/ml-engineering</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/machine%20learning%20engineering/python/data%20science/2021/01/30/ml-engineering.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Author: Andriy Burkov&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.mlebook.com/&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch1-introduction&quot;&gt;Ch1. Introduction&lt;/h1&gt;

&lt;p&gt;When we deploy a model in production, we usually deploy an entire pipeline&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Machine learning engineering (MLE)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;encompasses data collection, model training, making the model available for use&lt;/li&gt;
  &lt;li&gt;includes any activity that lets ML algorithms be implemented as a part of an effective production system&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ML Engineer&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;concerned with sourcing the data (from multiple locations), preprocessing it, programming features, training an effective model that will coexist in production with other processes&lt;/li&gt;
  &lt;li&gt;stable, maintanable and easily accessible&lt;/li&gt;
  &lt;li&gt;ML systems “fail silently” -&amp;gt; must be capable of preventing such failures or to know how to detect and handle them&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;when-to-use-ml&quot;&gt;When to use ML&lt;/h2&gt;
&lt;p&gt;Your problem:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;too complex for coding&lt;/li&gt;
  &lt;li&gt;constantly changing&lt;/li&gt;
  &lt;li&gt;perceptive (image, text, etc)&lt;/li&gt;
  &lt;li&gt;unstudied phenomenon&lt;/li&gt;
  &lt;li&gt;has a simple objective&lt;/li&gt;
  &lt;li&gt;it is cost-effective&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;when-not-to-use-ml&quot;&gt;When not to use ML&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;explainability is needed&lt;/li&gt;
  &lt;li&gt;errors are intolerable&lt;/li&gt;
  &lt;li&gt;traditional SWE is a less expensive option&lt;/li&gt;
  &lt;li&gt;all inputs and outputs can be enumerated and saved in a DB&lt;/li&gt;
  &lt;li&gt;data is hard to get or too expensive&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ml-project-life-cycle&quot;&gt;ML Project Life Cycle&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ab34d2-0b33-4814-bc70-07c1bed10d42_2056x1068.png&quot; title=&quot;diagram&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch2-before-the-project-starts&quot;&gt;Ch2. Before the Project Starts&lt;/h1&gt;

&lt;h2 id=&quot;impact-of-ml&quot;&gt;Impact of ML&lt;/h2&gt;
&lt;p&gt;High when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ML can replace a complex part of your engineering project&lt;/li&gt;
  &lt;li&gt;there’s great benefit in getting inexpensive (but probably imperfect) predictions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cost-of-ml&quot;&gt;Cost of ML&lt;/h2&gt;
&lt;p&gt;Factors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;difficulty of the problem&lt;/li&gt;
  &lt;li&gt;cost of data&lt;/li&gt;
  &lt;li&gt;need for accuracy&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;nonlinear-progress&quot;&gt;Nonlinear progress&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Progress in ML is nonlinear. Prediction error decreases fast in the beginning, but then gradually slows down&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Make sure the PO (or client) understands the constraints and risks&lt;/li&gt;
  &lt;li&gt;Log every activity and track the time it took (helps with reporting and estimations of complexity in the future)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-ml-projects-fail&quot;&gt;Why ML projects fail&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;lack of experienced talent&lt;/li&gt;
  &lt;li&gt;lack of support by the leadership&lt;/li&gt;
  &lt;li&gt;missing data infrastructure&lt;/li&gt;
  &lt;li&gt;data labeling challenge&lt;/li&gt;
  &lt;li&gt;siloed organizations and lack of collaboration&lt;/li&gt;
  &lt;li&gt;technically infeasible projects&lt;/li&gt;
  &lt;li&gt;lack of alignment between technical and business teams&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch3-data-collections-and-preparation&quot;&gt;Ch3. Data Collections and Preparation&lt;/h1&gt;

&lt;h2 id=&quot;train-validation-and-test-sets-partition&quot;&gt;Train, Validation and Test sets partition&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Data was randomized before the split&lt;/li&gt;
  &lt;li&gt;Split was applied to raw data&lt;/li&gt;
  &lt;li&gt;Validation and test sets follow the same distribution&lt;/li&gt;
  &lt;li&gt;Leakage was avoided&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-sampling-strategies&quot;&gt;Data Sampling strategies&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;random sampling&lt;/li&gt;
  &lt;li&gt;systematic sampling&lt;/li&gt;
  &lt;li&gt;stratified sampling&lt;/li&gt;
  &lt;li&gt;cluster sampling&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Data versioning is a critical element in supervised learning when the labeling is done by multiple labelers&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;dataset-documentation&quot;&gt;Dataset Documentation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;what the data means&lt;/li&gt;
  &lt;li&gt;how it was collected&lt;/li&gt;
  &lt;li&gt;methods used to creat it&lt;/li&gt;
  &lt;li&gt;details of train-validation-test splits&lt;/li&gt;
  &lt;li&gt;details of all pre-processing steps&lt;/li&gt;
  &lt;li&gt;explanation of any data that were excluded&lt;/li&gt;
  &lt;li&gt;format used to store it&lt;/li&gt;
  &lt;li&gt;types of attributes/features&lt;/li&gt;
  &lt;li&gt;number of examples&lt;/li&gt;
  &lt;li&gt;possible values for labels / allowable range for a numerical target&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch4-feature-engineering&quot;&gt;Ch4. Feature Engineering&lt;/h1&gt;

&lt;h2 id=&quot;good-features&quot;&gt;Good features&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;high predictive power&lt;/li&gt;
  &lt;li&gt;can be computed fast&lt;/li&gt;
  &lt;li&gt;reliable&lt;/li&gt;
  &lt;li&gt;uncorrelated&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The distribution of feature values in the training set should be similar to the distribution of values the production model will receive&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;feature-selection-techniques&quot;&gt;Feature selection techniques&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Cutting the long tail&lt;/li&gt;
  &lt;li&gt;Boruta&lt;/li&gt;
  &lt;li&gt;L1 regularization&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;best-practices&quot;&gt;Best practices&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;scale features&lt;/li&gt;
  &lt;li&gt;store and document in schema files or feature stores&lt;/li&gt;
  &lt;li&gt;keep code, model and training data in sync&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Feature extraction code is one of the most important parts of a machine learning system. It must be extensively and systematically tested”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch5-supervised-model-training-part-1&quot;&gt;Ch5. Supervised Model Training (Part 1)&lt;/h1&gt;

&lt;h2 id=&quot;baseline&quot;&gt;Baseline&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Baseline&lt;/strong&gt;: a model or algorithm that provides a reference point for comparison. Establish a baseline performance on your problem before start working on a predictive model.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;simple learning algorithm or&lt;/li&gt;
  &lt;li&gt;rule-based or heuristic algorithm (simple statistic)
    &lt;ul&gt;
      &lt;li&gt;random prediction&lt;/li&gt;
      &lt;li&gt;zero rule algorithm (e.g., always predict the most common class in the training set / average if regression)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;human baseline: Amazon Mechanical Turk (MT) service -&amp;gt; web-platform where people solve simple tasks for a reward&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;in-memory-vs-out-of-memory&quot;&gt;In-memory vs. out-of-memory&lt;/h2&gt;

&lt;p&gt;If the dataset can’t be fully loaded in RAM -&amp;gt; &lt;strong&gt;incremental learning algorithms&lt;/strong&gt;: can improve the model by reading data gradually (Naive Bayes, neural networks)&lt;/p&gt;

&lt;h2 id=&quot;precision-and-recall&quot;&gt;Precision and Recall&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Precision&lt;/strong&gt;: ratio of true positive predictions to the overall number of positive PREDICTIONS&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Recall&lt;/strong&gt;: ratio of true positive predictions to the overall number of positive EXAMPLES&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;f-measure&quot;&gt;F-measure&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;positive real &lt;em&gt;beta&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;beta = 2&lt;/strong&gt; -&amp;gt; weighs recall twice as high as precision&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;beta = 0.5&lt;/strong&gt; -&amp;gt; weighs recall twice as low as precision&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;precision-recall-and-bias-variance-tradeoffs&quot;&gt;Precision-recall and bias-variance tradeoffs&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;By varying the complexity of the model, we can reach the so-called “zone of solutions”, a situation in which both bias and variance of the model are relatively low. The solution that optimizes the performance metric is usually found inside that zone&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch6-supervised-model-training-part-2&quot;&gt;Ch6. Supervised Model Training (Part 2)&lt;/h1&gt;

&lt;p&gt;-&lt;/p&gt;

&lt;h1 id=&quot;ch7-model-evaluation&quot;&gt;Ch7. Model Evaluation&lt;/h1&gt;

&lt;h2 id=&quot;tasks&quot;&gt;Tasks&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;estimate legal &lt;strong&gt;risks&lt;/strong&gt; of putting the model in production&lt;/li&gt;
  &lt;li&gt;understand the &lt;strong&gt;distribution of the data&lt;/strong&gt; used to train the model&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;evaluate&lt;/strong&gt; the performance of the model prior to deployment&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;monitor&lt;/strong&gt; the performance of the deployed model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ab-testing&quot;&gt;A/B Testing&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;A: served the old model&lt;/li&gt;
  &lt;li&gt;B: served the new model&lt;/li&gt;
  &lt;li&gt;apply a statistical significance test to decide whether the new model is statistically different from the old model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;multi-armed-bandit&quot;&gt;Multi-armed bandit&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;start by randomly exposing all models to the users&lt;/li&gt;
  &lt;li&gt;gradually reduce the exposure of the least-performing models until only one (the best performing) gets served most of the time&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bootstrapping&quot;&gt;Bootstrapping&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;technique (statistical procedure) to compute a statistical interval for any metric&lt;/li&gt;
  &lt;li&gt;consists of building N samples of a dataset&lt;/li&gt;
  &lt;li&gt;then training a model&lt;/li&gt;
  &lt;li&gt;and computing some statistic using each of those N samples&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch8-model-deployment&quot;&gt;Ch8. Model Deployment&lt;/h1&gt;

&lt;h2 id=&quot;deployment-patterns&quot;&gt;Deployment patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;statically
    &lt;ul&gt;
      &lt;li&gt;installable binary of the entire software&lt;/li&gt;
      &lt;li&gt;positive: fast execution time for the user; don’t have to upload user data to server (user privacy); can be called when the user is offline; keeping the model operation is user’s responsibility&lt;/li&gt;
      &lt;li&gt;negative: hard to upgrade model without upgrading whole app; may have messy computational requirements; difficult to monitor the model performance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;dynamically on the user’s device
    &lt;ul&gt;
      &lt;li&gt;similar to static (user runs part of the system on their device), but the model is not a part of the binary code of the app&lt;/li&gt;
      &lt;li&gt;positive: better separation of concerns (easier to update); fast for the user (cheaper for the org’s servers)&lt;/li&gt;
      &lt;li&gt;negative: varies depending on strategy; difficult to monitor the model performance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;dynamically on a server:
    &lt;ul&gt;
      &lt;li&gt;place the model on servers and make it available as REST API or gRPC service&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;model streaming&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deployment-strategies&quot;&gt;Deployment strategies&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;single: simplest -&amp;gt; serialize new model to file, replace the old one&lt;/li&gt;
  &lt;li&gt;silent: new and old version runs in parallel during the switch&lt;/li&gt;
  &lt;li&gt;canary: pushes new version to a small fraction of users, while keep the old one running for most&lt;/li&gt;
  &lt;li&gt;multi-armed bandit (MAB): way to compare one or more versions of the model in the production env, and select the best performing one&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The model must be applied to the end-to-end and confidence test data by simulating a regular call from the outside”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;algorithmic-efficiency&quot;&gt;Algorithmic efficiency&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;important consideration in model deployment&lt;/li&gt;
  &lt;li&gt;you should only write your own code when it’s absolutely necessary&lt;/li&gt;
  &lt;li&gt;caching speeds up the application when it contains resource-consuming functions frequently called with the same parameter values&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch9-model-serving-monitoring-and-maintenance&quot;&gt;Ch9. Model Serving, Monitoring, and Maintenance&lt;/h1&gt;

&lt;h2 id=&quot;effective-runtime&quot;&gt;Effective runtime&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;secure&lt;/li&gt;
  &lt;li&gt;correct&lt;/li&gt;
  &lt;li&gt;ensures ease of deployment and recovery&lt;/li&gt;
  &lt;li&gt;provides guarantees of model validity&lt;/li&gt;
  &lt;li&gt;avoids training/serving skew and hidden feedback loops&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;serving-modes&quot;&gt;Serving modes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;batch: when applied to big data and some latency is tolerable&lt;/li&gt;
  &lt;li&gt;on-demand: wrapped into a REST API&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-can-go-wrong-with-the-model-in-production&quot;&gt;What can go wrong with the model in production&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;more training data made the model worse&lt;/li&gt;
  &lt;li&gt;properties of the production data changed&lt;/li&gt;
  &lt;li&gt;updated feature extraction code&lt;/li&gt;
  &lt;li&gt;resource needed for feature changed/unavailable&lt;/li&gt;
  &lt;li&gt;model is abused or under an adversarial attack&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;automated value calculation for the performance metrics -&amp;gt; send alert if change significantly&lt;/li&gt;
  &lt;li&gt;distribution shift&lt;/li&gt;
  &lt;li&gt;numerical instability&lt;/li&gt;
  &lt;li&gt;decreasing computational performance&lt;/li&gt;
  &lt;li&gt;logs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;maintenance&quot;&gt;Maintenance&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Most ML models must be regularly or occasionally updated”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;how often?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;error rate / how critical&lt;/li&gt;
  &lt;li&gt;only useful if fresh&lt;/li&gt;
  &lt;li&gt;new training data available fast&lt;/li&gt;
  &lt;li&gt;time it takes to retrain&lt;/li&gt;
  &lt;li&gt;cost to train / deploy the model&lt;/li&gt;
  &lt;li&gt;importance of update for improving the metrics&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-conclusion&quot;&gt;Ch10. Conclusion&lt;/h1&gt;

&lt;p&gt;-&lt;/p&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/ml_engineering/ml_eng_cover.png" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/ml_engineering/ml_eng_cover.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Learning Python Design Patterns</title><link href="https://millengustavo.github.io/blog/book/software%20engineering/python/design%20patterns/2020/08/22/python-design-patterns.html" rel="alternate" type="text/html" title="Learning Python Design Patterns" /><published>2020-08-22T00:00:00-05:00</published><updated>2020-08-22T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/software%20engineering/python/design%20patterns/2020/08/22/python-design-patterns</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/software%20engineering/python/design%20patterns/2020/08/22/python-design-patterns.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Author: Chetan Giridhar&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Learning-Python-Design-Patterns-Second-ebook/dp/B018XYKNOM&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch1-introduction-to-design-patterns&quot;&gt;Ch1. Introduction to design patterns&lt;/h1&gt;

&lt;h2 id=&quot;understanding-object-oriented-programming&quot;&gt;Understanding object-oriented programming&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Concept of &lt;em&gt;objects&lt;/em&gt; that have attributes (data members) and procedures (member functions)&lt;/li&gt;
  &lt;li&gt;Procedures are responsible for manipulating the attributes&lt;/li&gt;
  &lt;li&gt;Objects, which are instances of classes, interact among each other to serve the purpose of an application under development&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;classes&quot;&gt;Classes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Define objects in attributes and behaviors (methods)&lt;/li&gt;
  &lt;li&gt;Classes consist of constructors that provide the initial state for these objects&lt;/li&gt;
  &lt;li&gt;Are like templates and hence can be easily reused&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;methods&quot;&gt;Methods&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Represent the behavior of the object&lt;/li&gt;
  &lt;li&gt;Work on attributes and also implement the desired functionality&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;major-aspects-of-oop&quot;&gt;Major aspects of OOP&lt;/h2&gt;

&lt;h3 id=&quot;encapsulation&quot;&gt;Encapsulation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An object’s behavior is kept hidden from the outside world or objects keep their state information private&lt;/li&gt;
  &lt;li&gt;Clients can’t change the object’s internal state by directly acting on them&lt;/li&gt;
  &lt;li&gt;Clients request the object by sending requests. Based on the type, objects may respond by changing their internal state using special member functions such as &lt;code class=&quot;highlighter-rouge&quot;&gt;get&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;set&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;polymorphism&quot;&gt;Polymorphism&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Can be of two types:
    &lt;ul&gt;
      &lt;li&gt;An object provides different implementations of the method based on input parameters&lt;/li&gt;
      &lt;li&gt;The same interface can be used by objects of different types&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In Python polymorphism is a feature built-in for the language (e.g. + operator)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inheritance&quot;&gt;Inheritance&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Indicates that one class derives (most of) its functionality from the parent class&lt;/li&gt;
  &lt;li&gt;An option to reuse functionality defined in the base class and allow independent extensions of the original software implementation&lt;/li&gt;
  &lt;li&gt;Creates hierarchy via the relationships among objects of different classes&lt;/li&gt;
  &lt;li&gt;Python supports multiple inheritance (multiple base classes)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;abstraction&quot;&gt;Abstraction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Provides a simple interface to the clients. Clients can interact with class objects and call methods defined in the interface&lt;/li&gt;
  &lt;li&gt;Abstracts the complexity of internal classes with an interface so that the client need not be aware of internal implementations&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;composition&quot;&gt;Composition&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Combine objects or classes into more complex data structures or software implementations&lt;/li&gt;
  &lt;li&gt;An object is used to call member functions in other modules thereby making base functionality available across modules without inheritance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;object-oriented-design-principles&quot;&gt;Object-oriented design principles&lt;/h2&gt;

&lt;h3 id=&quot;the-openclose-principle&quot;&gt;The open/close principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Classes or objects and methods should be open for extension but closed for modifications&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Make sure you write your classes or modules in a generic way&lt;/li&gt;
  &lt;li&gt;Existing classes are not changed reducing the chances of regression&lt;/li&gt;
  &lt;li&gt;Helps maintain backward compatibility&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-inversion-of-control-principle&quot;&gt;The inversion of control principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;High-level modules shouldn’t be dependent on low-level modules; they should be dependent on abstractions. Details should depend on abstractions and not the other way round&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The base module and dependent module should be decoupled with an abstraction layer in between&lt;/li&gt;
  &lt;li&gt;The details of your class should represent the abstractions&lt;/li&gt;
  &lt;li&gt;The tight coupling of modules is no more prevalent and hence no complexity/rigidity in the system&lt;/li&gt;
  &lt;li&gt;Easy to deal with dependencies across modules in a better way&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-interface-segregation-principle&quot;&gt;The interface segregation principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Clients should not be force to depend on interfaces they don’t use&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Forces developers to write thin interfaces and have methods that are specific to the interface&lt;/li&gt;
  &lt;li&gt;Helps you not to populate interfaces by adding unintentional methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-single-responsibility-principle&quot;&gt;The single responsibility principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;A class should have only one reason to change&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;If a class is taking care of two functionalities, it is better to split them&lt;/li&gt;
  &lt;li&gt;Functionality = a reason to change&lt;/li&gt;
  &lt;li&gt;Whenever there is a change in one functionality, this particular class needs to change, and nothing else&lt;/li&gt;
  &lt;li&gt;If a class has multiple functionalities, the dependent classes will have to undergo changes for multiple reasons, which gets avoided&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-substitution-principle&quot;&gt;The substitution principle&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Derived classes must be able to completely substitute the base classes&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-concept-of-design-patterns&quot;&gt;The concept of design patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Solutions to given problems&lt;/li&gt;
  &lt;li&gt;Design patterns are discoveries and not a invention in themselves&lt;/li&gt;
  &lt;li&gt;Is about learning from others’ successes rather than your own failures!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;advantages-of-design-patterns&quot;&gt;Advantages of design patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Reusable across multiple projects&lt;/li&gt;
  &lt;li&gt;Architectural level of problems can be solved&lt;/li&gt;
  &lt;li&gt;Time-tested and well-proven, which is the experience of developers and architects&lt;/li&gt;
  &lt;li&gt;They have reliability and dependence&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;patterns-for-dynamic-languages&quot;&gt;Patterns for dynamic languages&lt;/h3&gt;
&lt;p&gt;Python:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Types or classes are objects at runtime&lt;/li&gt;
  &lt;li&gt;Variables can have type as a value and can be modified at runtime&lt;/li&gt;
  &lt;li&gt;Dynamic languages have more flexibility in terms of class restrictions&lt;/li&gt;
  &lt;li&gt;Everything is public by default&lt;/li&gt;
  &lt;li&gt;Design patterns can be easily implemented in dynamic languages&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;classifying-patterns&quot;&gt;Classifying patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Creational&lt;/li&gt;
  &lt;li&gt;Structural&lt;/li&gt;
  &lt;li&gt;Behavioral&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Classification of patterns is done based primarily on how the objects get created, how classes and objects are structured in a software application, and also covers the way objects interact among themselves&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;creational-patterns&quot;&gt;Creational patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Work on the basis of how objects can be created&lt;/li&gt;
  &lt;li&gt;Isolate the details of object creation&lt;/li&gt;
  &lt;li&gt;Code is independent of the type of object to be created&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;structural-patterns&quot;&gt;Structural patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Design the structure of objects and classes so that they can compose to achieve larger results&lt;/li&gt;
  &lt;li&gt;Focus on simplifying the structure and identifying the relationship between classes and objects&lt;/li&gt;
  &lt;li&gt;Focus on class inheritance and composition&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;behavioral-patterns&quot;&gt;Behavioral patterns&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Concerned with the interaction among objects and responsibilities of objects&lt;/li&gt;
  &lt;li&gt;Objects should be able to interact and still be loosely coupled&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-the-singleton-design-pattern&quot;&gt;Ch2. The singleton design pattern&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Typically used in logging or database operations, printer spoolers, thread pools, caches, dialog boxes, registry settings, and so on&lt;/li&gt;
  &lt;li&gt;Ensure that only one object of the class gets created&lt;/li&gt;
  &lt;li&gt;Provide an access point for an object that is global to the program&lt;/li&gt;
  &lt;li&gt;Control concurrent access to resources that are shared&lt;/li&gt;
  &lt;li&gt;Make the constructor private and create a static method that does the object initialization&lt;/li&gt;
  &lt;li&gt;Override the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method (Python’s special method to instantiate objects) to control the object creation&lt;/li&gt;
  &lt;li&gt;Another use case: &lt;strong&gt;lazy instantiation&lt;/strong&gt;. Makes sure that the object gets created when it’s actually needed&lt;/li&gt;
  &lt;li&gt;All modules are Singletons by default because of Python’s importing behavior&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;monostate-singleton-pattern&quot;&gt;Monostate Singleton pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;All objects share the same state&lt;/li&gt;
  &lt;li&gt;Assign the &lt;code class=&quot;highlighter-rouge&quot;&gt;__dict__&lt;/code&gt; variable with the &lt;code class=&quot;highlighter-rouge&quot;&gt;__shared_state&lt;/code&gt; class variable. Python uses &lt;code class=&quot;highlighter-rouge&quot;&gt;__dict__&lt;/code&gt; to store the state of every object of a class&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;singletons-and-metaclasses&quot;&gt;Singletons and metaclasses&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;A metaclass is a class of a class&lt;/li&gt;
  &lt;li&gt;The class is an instance of its metaclass&lt;/li&gt;
  &lt;li&gt;Programmers get an opportunity to create classes of their own type from the predefined Python classes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;drawbacks&quot;&gt;Drawbacks&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Singletons have a global point of access&lt;/li&gt;
  &lt;li&gt;Al classes that are dependent on global variables get tightly coupled as a change to the global data by one class can inadvertently impact the other class&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch3-the-factory-pattern---building-factories-to-create-objects&quot;&gt;Ch3. The factory pattern - building factories to create objects&lt;/h1&gt;

&lt;h2 id=&quot;understanding-the-factory-pattern&quot;&gt;Understanding the factory pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Factory = a class that is responsible for creating objects of other types&lt;/li&gt;
  &lt;li&gt;The class that acts as a factory has an object and methods associated with it&lt;/li&gt;
  &lt;li&gt;The client calls this method with certain parameters; objects of desired types are created in turn and returned to the client by the factory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Loose coupling: object creation can be independent of the class implementation&lt;/li&gt;
  &lt;li&gt;The client only needs to know the interface, methods, and parameters that need to be passed to create objects of the desired type (simplifies implementations for the client)&lt;/li&gt;
  &lt;li&gt;Adding another class to the factory to create objects of another type can be easily done without the client changing the code&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-simple-factory-pattern&quot;&gt;The simple factory pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Not a pattern in itself&lt;/li&gt;
  &lt;li&gt;Helps create objects of different types rather than direct object instantiation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-factory-method-pattern&quot;&gt;The factory method pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;We define an interface to create objects, but instead of the factory being responsible for the object creation, the responsibility is deferred to the subclass that decides the class to be instantiated&lt;/li&gt;
  &lt;li&gt;Creation is through inheritance and not through instantiation&lt;/li&gt;
  &lt;li&gt;Makes the design more customizable. It can return the same instance or subclass rather than an object of a certain type&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The factory method pattern defines an interface to create an object, but defers the decision ON which class to instantiate to its subclasses&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Makes the code generic and flexible, not being tied to a certain class for instantiation. We’re dependent on the interface (Product) and not on the ConcreteProduct class&lt;/li&gt;
  &lt;li&gt;Loose coupling: the code that creates the object is separate from the code that uses it&lt;/li&gt;
  &lt;li&gt;The client don’t need to bother about what argument to pass and which class to instantiate -&amp;gt; the addition of new classes is easy and involves low maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-abstract-factory-pattern&quot;&gt;The abstract factory pattern&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Provide an interface to create families of related objects without specifying the concrete class&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Makes sure that the client is isolated from the creation of objects but allowed to use the objects created&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;factory-method-versus-abstract-factory-method&quot;&gt;Factory method versus abstract factory method&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;Factory method&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;Abstract Factory method&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Exposes a method to the client to create the objects&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Contains one or more factory methods of another class&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Uses inheritance and subclass to decide which object to create&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Uses composition to delegate responsibility to create objects of another class&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Is used to create one product&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Is about creating families of related products&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;ch4-the-façade-pattern---being-adaptive-with-façade&quot;&gt;Ch4. The façade pattern - being adaptive with façade&lt;/h1&gt;

&lt;h2 id=&quot;understanding-structural-design-patterns&quot;&gt;Understanding Structural design patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Describe how objects and classes can be combined to form larger structures. Structural patterns are a combination of class and object patterns&lt;/li&gt;
  &lt;li&gt;Ease the design by identifying simpler ways to realize or demonstrate relationships between entities&lt;/li&gt;
  &lt;li&gt;Class patterns: describe abstraction with the help of inheritance and provide a more useful program interface&lt;/li&gt;
  &lt;li&gt;Object patterns: describe how objects can be associated and composed to form larger objects&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;understanding-the-façade-design-pattern&quot;&gt;Understanding the Façade design pattern&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Façade hides the complexities of the internal system and provides an interface to the client that can access the system in a very simplified way&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Provides an unified interface to a set of interfaces in a subsystem and defines a high-level interface that helps the client use the subsystem in an easy way&lt;/li&gt;
  &lt;li&gt;Discusses representing a complex subsystem with a single interface object -&amp;gt; it doesn’t encapsulate the subsystem, but actually combines the underlying subsystems&lt;/li&gt;
  &lt;li&gt;Promotes the decoupling of the implementation with multiple clients&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;main-participants&quot;&gt;Main participants&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Façade&lt;/strong&gt;: wrap up a complex group of subsystems so that it can provide a pleasing look to the outside world&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;System&lt;/strong&gt;: represents a set of varied subsystems that make the whole system compound and difficult to view or work with&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;: interact with the façade so that it can easily communicate with the subsystem and get the work completed (doesn’t have to bother about the complex nature of the system)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-principle-of-least-knowledge&quot;&gt;The principle of least knowledge&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Design principle behind Façade pattern&lt;/li&gt;
  &lt;li&gt;Reduce the interactions between objects to just a few friend that are close enough to you&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-law-of-demeter&quot;&gt;The Law of Demeter&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Design guideline:
    &lt;ul&gt;
      &lt;li&gt;Each unit should have only limited knowledge of other units of the system&lt;/li&gt;
      &lt;li&gt;A unit should talk to its friends only&lt;/li&gt;
      &lt;li&gt;A unit should not know about the internal details of the object that it manipulates&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The principle of least knowledge and Law of Demeter are the same and both point to the philosophy of &lt;em&gt;loose coupling&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch5-the-proxy-pattern---controlling-object-access&quot;&gt;Ch5. The proxy pattern - controlling object access&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Proxy: a system that intermediates between the seeker and provider. Seeker is the one that makes the request, and provider delivers the resources in response to the request&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;A proxy server encapsulates requests, enables privacy, and works well in distributed architectures&lt;/li&gt;
  &lt;li&gt;Proxy is a wrapper or agent object that wraps the real serving object&lt;/li&gt;
  &lt;li&gt;Provide a surrogate or placeholder for another object in order to control access to a real object&lt;/li&gt;
  &lt;li&gt;Some useful scenarios:
    &lt;ul&gt;
      &lt;li&gt;Represents a complex system in a simpler way&lt;/li&gt;
      &lt;li&gt;Acts as a shield against malicious intentions and protect the real object&lt;/li&gt;
      &lt;li&gt;Provides a local interface for remote objects on different servers&lt;/li&gt;
      &lt;li&gt;Provides a light handle for a higher memory-consuming object&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-structure-components&quot;&gt;Data Structure components&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Proxy&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Subject/RealSubject&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;different-types-of-proxies&quot;&gt;Different types of proxies&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Virtual proxy&lt;/strong&gt;: placeholder for objects that are very heavy to instantiate&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remote proxy&lt;/strong&gt;: provides a local representation of a real object that resides on a remote server or different address space&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Protective proxy&lt;/strong&gt;: controls access to the sensitive matter object of &lt;code class=&quot;highlighter-rouge&quot;&gt;RealSubject&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Smart proxy&lt;/strong&gt;: interposes additional actions when an object is accessed&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Proxy&lt;/th&gt;
      &lt;th&gt;Façade&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Provides you with a surrogate or placeholder for another object to control access to it&lt;/td&gt;
      &lt;td&gt;Provides you with an interface to large subsystems of classes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A Proxy object has the same interface as that of the target object and holds references to target objects&lt;/td&gt;
      &lt;td&gt;Minimizes the communication and dependencies between subsystems&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Acts as an intermediary between the client and object that is wrapped&lt;/td&gt;
      &lt;td&gt;Provides a single simplified interface&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;decorator-vs-proxy&quot;&gt;Decorator vs Proxy&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Decorator adds behavior to the object that it decorates at runtime&lt;/li&gt;
  &lt;li&gt;Proxy controls access to an object&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;disadvantages&quot;&gt;Disadvantages&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Proxy pattern can increase the response time&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-the-observer-pattern---keeping-objects-in-the-know&quot;&gt;Ch6. The observer pattern - keeping objects in the know&lt;/h1&gt;

&lt;h2 id=&quot;behavioral-patterns-1&quot;&gt;Behavioral patterns&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Focus on the responsibilities that an object has&lt;/li&gt;
  &lt;li&gt;Deal with the interaction among objects to achieve larger functionality&lt;/li&gt;
  &lt;li&gt;Objects should be able to interact with each other, &lt;strong&gt;but they should still be loosely coupled&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;understanding-the-observer-design-pattern&quot;&gt;Understanding the observer design pattern&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;An object (Subject) maintains a list of dependents (Observers) so that the Subject can notify all the Observers about the changes that it undergoes using any of the methods defined by the Observer&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Defines a one-to-many dependency between objects so that any change in one object will be notified to the other dependent objects automatically&lt;/li&gt;
  &lt;li&gt;Encapsulates the core component of the Subject&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-pull-model&quot;&gt;The pull model&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Subject broadcasts to all the registered Observers when there is any change&lt;/li&gt;
  &lt;li&gt;Observer is responsible for getting the changes or pulling data from the subscriber when there is an amendment&lt;/li&gt;
  &lt;li&gt;Pull model is &lt;strong&gt;ineffective&lt;/strong&gt;: involves two steps:
    &lt;ul&gt;
      &lt;li&gt;Subject notifies the Observer&lt;/li&gt;
      &lt;li&gt;Observer pulls the required data from the Subject&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-push-model&quot;&gt;The push model&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Changes are pushed by the Subject to the Observer&lt;/li&gt;
  &lt;li&gt;Subject can send detailed information to the Observer (even though it may not be needed) -&amp;gt; can result in sluggish response times when a large amount of data in sent by the Subject but is never actually used by the Observer&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loose-coupling-and-the-observer-pattern&quot;&gt;Loose coupling and the observer pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Coupling refers to the degree of knowledge that one object has about the other object that it interacts with&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Loosely-coupled designs allow us to build flexbile object-oriented systems that can handle changes because they reduce the dependency between multiple objects&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Reduces the risk that a change made within one element might create an unanticipated impact on the other elements&lt;/li&gt;
  &lt;li&gt;Simplifies testing, maintenance, and troubleshooting problems&lt;/li&gt;
  &lt;li&gt;System can be easily broken down into definable elements&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch7-the-command-pattern---encapsulating-invocation&quot;&gt;Ch7. The command pattern - encapsulating invocation&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Behavioral design pattern in which an object is used to encapsulate all the information needed to perform an action or trigger an event at a later time&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;understanding-the-command-design-pattern&quot;&gt;Understanding the command design pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;Command&lt;/code&gt; object knows about the &lt;code class=&quot;highlighter-rouge&quot;&gt;Receiver&lt;/code&gt; objects and invokes a method of the &lt;code class=&quot;highlighter-rouge&quot;&gt;Receiver&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;Values for parameters of the receiver method are stored in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Command&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;The invoker knows how to execute a command&lt;/li&gt;
  &lt;li&gt;The client creates a &lt;code class=&quot;highlighter-rouge&quot;&gt;Command&lt;/code&gt; object and sets its receiver&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intentions&quot;&gt;Intentions&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Encapsulating a request as an object&lt;/li&gt;
  &lt;li&gt;Allowing the parametrization of clients with different requests&lt;/li&gt;
  &lt;li&gt;Allowing to save the requests in a queue&lt;/li&gt;
  &lt;li&gt;Providing an object-oriented callback&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scenarios-of-use&quot;&gt;Scenarios of use&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Parametrizing objects depending on the action to be performed&lt;/li&gt;
  &lt;li&gt;Adding actions to a queue and executing requests at different points&lt;/li&gt;
  &lt;li&gt;Creating a structure for high-level operations that are based on smaller operations&lt;/li&gt;
  &lt;li&gt;E.g.:
    &lt;ul&gt;
      &lt;li&gt;Redo or rollback operations&lt;/li&gt;
      &lt;li&gt;Asynchronous task execution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advantages&quot;&gt;Advantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Decouples the classes that invoke the operation from the object that knows how to execute the operation&lt;/li&gt;
  &lt;li&gt;Provide a queue system&lt;/li&gt;
  &lt;li&gt;Extensions to add new commands are easy&lt;/li&gt;
  &lt;li&gt;A rollback system with the command pattern can be defined&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;disadvantages-1&quot;&gt;Disadvantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;High number of classes and objects working together to achieve a goal&lt;/li&gt;
  &lt;li&gt;Every individual command is a &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteCommand&lt;/code&gt; class that increases the volume of classes for implementation and maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch8-the-templated-method-pattern---encapsulating-algorithm&quot;&gt;Ch8. The templated method pattern - encapsulating algorithm&lt;/h1&gt;

&lt;h2 id=&quot;use-cases&quot;&gt;Use cases&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;When multiple algorithms or classes implements similar or identical logic&lt;/li&gt;
  &lt;li&gt;The implementation of algorithms in subclasses helps reduce code duplication&lt;/li&gt;
  &lt;li&gt;Multiple algorithms can be defined by letting the subclasses implement the behavior through overriding&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intentions-1&quot;&gt;Intentions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Define a skeleton of an algorithm with primitive operations&lt;/li&gt;
  &lt;li&gt;Redefine certain operations of the subclass without changing the algorithm’s structure&lt;/li&gt;
  &lt;li&gt;Achieve code reuse and avoid duplicate efforts&lt;/li&gt;
  &lt;li&gt;Leverage common interfaces or implementations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;terms&quot;&gt;Terms&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AbstractClass&lt;/code&gt;: Declares an interface to define the steps of the algorithm&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteClass&lt;/code&gt;: Defines subclass-specific step definitions&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;template_method()&lt;/code&gt;: Defines the algorithm by calling the step methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hooks&quot;&gt;Hooks&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hook: a method that is declared in the abstract class&lt;/li&gt;
  &lt;li&gt;Give a subclass the ability to &lt;em&gt;hook into&lt;/em&gt; the algorithm whenever needed&lt;/li&gt;
  &lt;li&gt;Not imperative for the subclass to use hooks&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;We use abstract methods when the subclass must provide the implementation, and hook is used when it is optional for the subclass to implement it&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-hollywood-principle&quot;&gt;The Hollywood principle&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Design principle summarized by &lt;strong&gt;Don’t call us, we’ll call you&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Relates to the template method -&amp;gt; it’s the high-level abstract class that arranges the steps to define the algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advantages-1&quot;&gt;Advantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;No code duplication&lt;/li&gt;
  &lt;li&gt;Uses inheritance and not composition -&amp;gt; only a few methods need to be overriden&lt;/li&gt;
  &lt;li&gt;Flexibility lets subclasses decide how implement steps in an algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;disadvantages-2&quot;&gt;Disadvantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Confusing debugging and undestanding the sequence of flow&lt;/li&gt;
  &lt;li&gt;Documentation and strict error handling has to be done by the programmer&lt;/li&gt;
  &lt;li&gt;Maintenance can be a problem -&amp;gt; changes to any level can disturb the implementation&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch9-model-view-controller---compound-patterns&quot;&gt;Ch9. Model-View-Controller - Compound patterns&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;“A compound pattern combines two or more patterns into a solution that solves a recurring or general problem” - GoF&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A compound pattern is not a set of patterns working together; it is a general solution to a problem&lt;/p&gt;

&lt;h2 id=&quot;the-model-view-controller-pattern&quot;&gt;The Model-View-Controller pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Model represents the data and business logic: how information is stored and queried&lt;/li&gt;
  &lt;li&gt;View is nothing but the representation: how it is presented&lt;/li&gt;
  &lt;li&gt;Controller is the one that directs the model and view to behave in a certain way: it’s the glue between the two&lt;/li&gt;
  &lt;li&gt;The view and controller are dependent on the model, but not the other way around&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;terms-1&quot;&gt;Terms&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Model - knowledge of the application&lt;/strong&gt;: store and manipulate data (create, modify and delete). Has state and methods to change states, but is not aware of how the data would be seen by the client&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;View - the appearance&lt;/strong&gt;: build user interfaces and data displays (it should not contain any logic of its own and just display the data it receives)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Controller - the glue&lt;/strong&gt;: connects the model and view (it has methods that are used to route requests)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;User&lt;/strong&gt;: requests for certain results based on certain actions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intention&quot;&gt;Intention&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Keep the data and presentation of the data separate&lt;/li&gt;
  &lt;li&gt;Easy maintenance of the class and implementation&lt;/li&gt;
  &lt;li&gt;Flexibility to change the way in which data is stored and displayed -&amp;gt; both are independent and hence have the flexibility to change&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-mvc-pattern-in-the-real-world&quot;&gt;The MVC pattern in the real world&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Django or Rails&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MTV (Model, Template, View)&lt;/strong&gt;: model is the database, templates are the views, and controllers are the views/routes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;benefits-of-the-mvc-pattern&quot;&gt;Benefits of the MVC pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Easy maintenance&lt;/li&gt;
  &lt;li&gt;Loose coupling&lt;/li&gt;
  &lt;li&gt;Decrease complexity&lt;/li&gt;
  &lt;li&gt;Development efforts can run independently&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-the-state-design-pattern&quot;&gt;Ch10. The state design pattern&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Behavioral design pattern&lt;/li&gt;
  &lt;li&gt;Sometimes referred to as an &lt;strong&gt;objects for states&lt;/strong&gt; pattern&lt;/li&gt;
  &lt;li&gt;Used to develop Finite State Machines and helps to accommodate State Transaction Actions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;understanding-the-state-design-pattern&quot;&gt;Understanding the state design pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;State&lt;/code&gt;: an interface that encapsulates the object’s behavior. This behavior is associated with the state of the object&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt;: a subclass that implements the &lt;code class=&quot;highlighter-rouge&quot;&gt;State&lt;/code&gt; interface -&amp;gt; implements the actual behavior associated with the object’s particular state&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Context&lt;/code&gt;: the interface of interest to clients. Also maintains an instance of the &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt; subclass that internally defines the implementation of the object’s particular state&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advantages-2&quot;&gt;Advantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Removes the dependency on the if/else or switch/else conditional logic&lt;/li&gt;
  &lt;li&gt;Benefits of implementing polymorphic behavior, also easier to add states to support additional behavior&lt;/li&gt;
  &lt;li&gt;Improves cohesion: state-specific behaviors are aggregated into the &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt; classes, which are placed in one location in the code&lt;/li&gt;
  &lt;li&gt;Improves the flexibility to extend the behavior of the application and overall improves code maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;disadvantages-3&quot;&gt;Disadvantages&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Class explosion: every state needs to be defined with the help of &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcreteState&lt;/code&gt; -&amp;gt; might end up writing many more classes with a small functionality&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Context&lt;/code&gt; class needs to be updated to deal with each behavior&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch11-antipatterns&quot;&gt;Ch11. AntiPatterns&lt;/h1&gt;
&lt;p&gt;Four aspects of a bad design:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Immobile&lt;/strong&gt;: hard to reuse&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rigid&lt;/strong&gt;: any small change may in turn result in moving too many parts of the software&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fragile&lt;/strong&gt;: any change results in breaking the existing system fairly easy&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Viscose&lt;/strong&gt;: changes are done in the code or envinronment itself to avoid difficult architectural level changes&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;An AntiPattern is an outcome of a solution to recurring problems so that the outcome is innefective and becomes counterproductive&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;AntiPatterns may be the result of:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A developer not knowing the software development practices&lt;/li&gt;
  &lt;li&gt;A developer not applying design patterns in the correct context&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;software-development-antipatterns&quot;&gt;Software development AntiPatterns&lt;/h2&gt;
&lt;p&gt;Software deviates from the original code structure due to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The tought process of the developer evolves with development&lt;/li&gt;
  &lt;li&gt;Use cases change based on customer feedback&lt;/li&gt;
  &lt;li&gt;Data structures designed initially may undergo change with functionality or scalability considerations&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Refactoring is one of the critical parts of the software development journey, which provides developers an opportunity to relook the data structures and think about scalability and ever-evolving customer’s needs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;spaghetti-code&quot;&gt;Spaghetti code&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Minimum reuse of structures is possible&lt;/li&gt;
  &lt;li&gt;Maintenance efforts are too high&lt;/li&gt;
  &lt;li&gt;Extension and flexibility to change is reduced&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;golden-hammer&quot;&gt;Golden Hammer&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;One solution is obsessively applied to all software projects&lt;/li&gt;
  &lt;li&gt;The product is describe, not by the features, but the technology used in development&lt;/li&gt;
  &lt;li&gt;In the company corridors, you hear developers talking, “That could have been better than using this”&lt;/li&gt;
  &lt;li&gt;Requirements are not completed and not in sync with user expectations&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lava-flow&quot;&gt;Lava Flow&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Low code coverage for developed tests&lt;/li&gt;
  &lt;li&gt;Commented code without reasons&lt;/li&gt;
  &lt;li&gt;Obsolete interfaces, or developers try to work around existing code&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;copy-and-paste-or-cut-and-paste-programming&quot;&gt;Copy-and-paste or cut-and-paste programming&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Similar type of issues across software application&lt;/li&gt;
  &lt;li&gt;Higher maintenance costs and increased bug life cycle&lt;/li&gt;
  &lt;li&gt;Less modular code base with the same code running into a number of lines&lt;/li&gt;
  &lt;li&gt;Inheriting issues that existed in the first place&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;software-architecture-antipatterns&quot;&gt;Software architecture AntiPatterns&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Software architecture looks at modeling the software that is well understood by the development and test teams, product managers, and other stakeholders&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;reinventing-the-wheel&quot;&gt;Reinventing the wheel&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Too many solutions to solve one standard problem, with many of them not being well thought out&lt;/li&gt;
  &lt;li&gt;More time and resource utilization for the engineering team leading overbudgeting and more time to market&lt;/li&gt;
  &lt;li&gt;A closed system architecture (useful for only one product), duplication of efforts, and poor risk management&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vendor-lock-in&quot;&gt;Vendor lock-in&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Release cycles and product maintenance cycles of a company’s product releases are directly dependent on the vendor’s release time frame&lt;/li&gt;
  &lt;li&gt;The product is developed around the technology rather than on the customer’s requirements&lt;/li&gt;
  &lt;li&gt;The product’s time to market is unreliable and doesn’t meet customer’s expectations&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;design-by-committee&quot;&gt;Design by committee&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Conflicting viewpoints between developers and architects even after the design is finalized&lt;/li&gt;
  &lt;li&gt;Overly complex design that is very difficult to document&lt;/li&gt;
  &lt;li&gt;Any change in the specification or design undergoes review by many, resulting in implementation delays&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/python_design_patterns/python_design_patterns.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/python_design_patterns/python_design_patterns.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Clean Code: A Handbook of Agile Software Craftsmanship</title><link href="https://millengustavo.github.io/blog/book/software%20engineering/2020/07/26/clean-code.html" rel="alternate" type="text/html" title="Clean Code: A Handbook of Agile Software Craftsmanship" /><published>2020-07-26T00:00:00-05:00</published><updated>2020-07-26T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/software%20engineering/2020/07/26/clean-code</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/software%20engineering/2020/07/26/clean-code.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Authors: Robert C. Martin&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch1-clean-code&quot;&gt;Ch1. Clean Code&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Most managers want good code, even when they are obsessing about the schedule (…) It’s &lt;em&gt;your&lt;/em&gt; job to defend the code with equal passion”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Clean code is &lt;em&gt;focused&lt;/em&gt;: each function, each class, each module exposes a single-minded attitude that remains entirely undistracted, and upolluted, by the surrounding details&lt;/li&gt;
  &lt;li&gt;Code, without tests, is not clean. No matter how elegant it is, no matter how readable and accessible, if it hath not tests, it be unclean&lt;/li&gt;
  &lt;li&gt;You will read it, and it will be pretty much what you expected. It will be obvious, simple, and compelling&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reading-vs-writing&quot;&gt;Reading vs. Writing&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The ratio of time spent reading vs. writing is well over 10:1&lt;/li&gt;
  &lt;li&gt;We are constantly reading old code as part of the effort to write new code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;We want the reading of code to be easy, even if it makes the writing harder&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;You cannot write code if you cannot read the surrounding code&lt;/li&gt;
  &lt;li&gt;If you want to go fast, get done quickly, if you want your code to be easy to write, make it easy to read&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-meaningful-names&quot;&gt;Ch2. Meaningful Names&lt;/h1&gt;

&lt;h2 id=&quot;use-intention-revealing-names&quot;&gt;Use intention-revealing names&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Choosing good names takes time, but saves more than it takes. Take care with your names and change them when you find better ones&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;avoid-disinformation&quot;&gt;Avoid disinformation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Avoid leaving false clues that obscure the meaning of code&lt;/li&gt;
  &lt;li&gt;Avoid words whose entrenched meanings vary from our intended meaning&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;make-meaningful-distinctions&quot;&gt;Make meaningful distinctions&lt;/h2&gt;
&lt;p&gt;If names must be different, then they should also mean something different&lt;/p&gt;

&lt;h2 id=&quot;use-pronounceable-names&quot;&gt;Use pronounceable names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Humans are good at words&lt;/li&gt;
  &lt;li&gt;Words are, by definition, pronounceable&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-searchable-names&quot;&gt;Use searchable names&lt;/h2&gt;
&lt;p&gt;Single-letter names and numeric constants have a particular problem in that they are not easy to locate across a body of text&lt;/p&gt;

&lt;h2 id=&quot;avoid-encodings&quot;&gt;Avoid encodings&lt;/h2&gt;
&lt;p&gt;Encoding type or scope information into names simply adds an extra burden of deciphering&lt;/p&gt;

&lt;h2 id=&quot;avoid-mental-mapping&quot;&gt;Avoid mental mapping&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Clarity is king&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;class-names&quot;&gt;Class names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Classes and objects should have noun or noun phrase names&lt;/li&gt;
  &lt;li&gt;A class name should not be a verb&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;method-names&quot;&gt;Method names&lt;/h2&gt;
&lt;p&gt;Methods should have verb or verb phrase names&lt;/p&gt;

&lt;h2 id=&quot;dont-be-cute&quot;&gt;Don’t be cute&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Choose clarity over entertainment value&lt;/li&gt;
  &lt;li&gt;Say what you mean. Mean what you say&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pick-one-word-per-concept&quot;&gt;Pick one word per concept&lt;/h2&gt;
&lt;p&gt;A consistent lexicon is a great boon to the programmers who must use your code&lt;/p&gt;

&lt;h2 id=&quot;dont-pun&quot;&gt;Don’t pun&lt;/h2&gt;
&lt;p&gt;Avoid using the same word for two purposes -&amp;gt; essentially a pun&lt;/p&gt;

&lt;h2 id=&quot;use-solution-domain-names&quot;&gt;Use solution domain names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;People who read your code will be programmers&lt;/li&gt;
  &lt;li&gt;Use CS terms, algorithm names, pattern names, math terms&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-problem-domain-names&quot;&gt;Use problem domain names&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Separate solution and problem domain concepts&lt;/li&gt;
  &lt;li&gt;Code that has more to do with problem domain concepts should have names drawn from the problem domain&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;add-meaningful-context&quot;&gt;Add meaningful context&lt;/h2&gt;
&lt;p&gt;Most names are not meaningful in and of themselves&lt;/p&gt;

&lt;h2 id=&quot;dont-add-gratuitous-context&quot;&gt;Don’t add gratuitous context&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Shorter names are generally better than long ones, so long as they are clear&lt;/li&gt;
  &lt;li&gt;Add no more context to a name than is necessary&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Choosing good names requires good descriptive skills and a shared cultural background. This is a teaching issue rather than a technical, business, or management issue&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch3-functions&quot;&gt;Ch3. Functions&lt;/h1&gt;
&lt;h2 id=&quot;small&quot;&gt;Small&lt;/h2&gt;
&lt;p&gt;Functions should be small&lt;/p&gt;

&lt;h3 id=&quot;blocks-and-indenting&quot;&gt;Blocks and Indenting&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Blocks within &lt;code class=&quot;highlighter-rouge&quot;&gt;if&lt;/code&gt; statements, &lt;code class=&quot;highlighter-rouge&quot;&gt;else&lt;/code&gt; statements, &lt;code class=&quot;highlighter-rouge&quot;&gt;while&lt;/code&gt; statements should be on line long -&amp;gt; probably a function call&lt;/li&gt;
  &lt;li&gt;Keep the enclosing function small, adds documentary value&lt;/li&gt;
  &lt;li&gt;Functions should not be large enough to hold nested structures -&amp;gt; makes easier to read and understand&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;do-one-thing&quot;&gt;Do one thing&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Functions should do one thing. They should do it well. They should do it only&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Reasons to write functions: decompose a larger concept (the name of the function) into a set of steps at the next level of abstraction&lt;/li&gt;
  &lt;li&gt;Functions that do one thing cannot be divided into sections&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;one-level-of-abstraction-per-function&quot;&gt;One level of abstraction per function&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Once details are mixed with essential concepts, more details tend to accrete within the function&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-stepdown-rule&quot;&gt;The Stepdown rule&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;We want code to be read like a top-down narrative&lt;/li&gt;
  &lt;li&gt;A set of TO paragraphs, each describing the current level of abstraction and referencing subsequent TO paragraphs at the next level down&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-descriptive-names&quot;&gt;Use descriptive names&lt;/h2&gt;
&lt;p&gt;Ward’s principle: &lt;em&gt;“You know you are working on clean code when each routine turns out to be pretty much what you expected”&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spend time choosing a name&lt;/li&gt;
  &lt;li&gt;You should try several different names and read the code with each in place&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;function-arguments&quot;&gt;Function arguments&lt;/h2&gt;
&lt;p&gt;Ideal number of arguments for a function:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;zero (niladic)&lt;/li&gt;
  &lt;li&gt;one (monadic)&lt;/li&gt;
  &lt;li&gt;two (dyadic)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;more than that should be avoided where possible&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Arguments are hard from a testing point of view&lt;/strong&gt; -&amp;gt; test cases for all combinations of arguments&lt;/li&gt;
  &lt;li&gt;Output arguments are harder to understand than input arguments&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Passing a boolean into a function (flag arguments) is a terrible practice&lt;/strong&gt; -&amp;gt; loudly proclaiming that this function does more than one thing -&amp;gt; does one thing if the flag is true and another if the flag is false!&lt;/li&gt;
  &lt;li&gt;When a function seems to need more than two or three arguments, it is likely that some of those arguments ought to be wrapped into a class of their own -&amp;gt; When groups of variables are passed together, they are likely part of a concept that deserves a name of its own&lt;/li&gt;
  &lt;li&gt;Side effects are lies -&amp;gt; your functions promises to do one thing, but it also does other &lt;em&gt;hidden&lt;/em&gt; things&lt;/li&gt;
  &lt;li&gt;Either your function should change the state of an object, or it should return some information about the object&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Prefer Exceptions to returing error codes&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Extract try/catch blocks into functions of their own&lt;/li&gt;
  &lt;li&gt;Functions should do one thing -&amp;gt; error handling is one thing&lt;/li&gt;
  &lt;li&gt;Don’t repeat yourself -&amp;gt; duplication may be the root of all evil in software&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-do-you-write-functions-like-this&quot;&gt;How do you write functions like this?&lt;/h2&gt;
&lt;p&gt;Writing software is like any other kind of writing&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Get your thoughts down first&lt;/li&gt;
  &lt;li&gt;Massage it until it reads well&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first draft might be clumsy and disorganized, so you restructure it and refine it until it reads the way you want it to read&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Every system is built from a domain-specific language designed by the programmers to describe the system. Functions are the verbs of that language, and classes are the nouns.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch4-comments&quot;&gt;Ch4. Comments&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Comments are always failures. We must have them because we cannot always figure out how to express ourselves without them, but their use is not a cause for celebration&lt;/li&gt;
  &lt;li&gt;Comments lie. Not always, and not intentionally, but too often&lt;/li&gt;
  &lt;li&gt;The older a comment is, and the farther away it is from the code it describes, the more likely it is to be wrong&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Truth can only be found in the code&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Explain your intent in code: &lt;strong&gt;create a function that says the same thing as the comment you want to write&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;A comment may be used to amplify the importance of something that may otherwise seem inconsequential&lt;/li&gt;
  &lt;li&gt;We have good source code control systems now. Those systems will remember the code for us. We don’t have to comment it out any more. Just delete the code&lt;/li&gt;
  &lt;li&gt;Short functions don’t need much description -&amp;gt; well-chosen name for a small function that does one thing is better than a comment header&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch5-formatting&quot;&gt;Ch5. Formatting&lt;/h1&gt;
&lt;p&gt;Code formatting&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Too important to ignore&lt;/li&gt;
  &lt;li&gt;Is about communication -&amp;gt; developer’s first order of business&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Small files are easier to understand than large files are&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-newspaper-metaphor&quot;&gt;The newspaper metaphor&lt;/h2&gt;
&lt;p&gt;Source file should be like a newspaper article&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Name should be simple but explanatory&lt;/li&gt;
  &lt;li&gt;The name, by itself, should be sufficient to tell us whether we are in the right module or not&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vertical-formatting&quot;&gt;Vertical formatting&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Avoid forcing the reader to hop around through the source files and classes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dependent functions&lt;/strong&gt;: if one function calls another, they should be vertically close, and the caller should be above the callee&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;horizontal-formatting&quot;&gt;Horizontal formatting&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Strive to keep your lines short&lt;/li&gt;
  &lt;li&gt;Beyond 100~120 isn’t advisable&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-objects-and-data-structures&quot;&gt;Ch6. Objects and Data Structures&lt;/h1&gt;

&lt;h2 id=&quot;dataobject-anti-symmetry&quot;&gt;Data/Object anti-symmetry&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Objects hide their data behind abstractions and expose functions that operate on that data. Data structure expose their data and have no meaningful functions&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Procedural code (code using data structures) makes it easy to add new functions without changing the existing data structures. OO code makes it easy to add new classes without changing existing functions&lt;/li&gt;
  &lt;li&gt;Procedural code makes it hard to add new data structures because all the functions must change. OO code makes it hard to add new functions because all the classes must change&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mature programmers know that the idea that &lt;em&gt;everything is an object is a myth&lt;/em&gt;. Sometimes you really do want simple data structures with procedures operating on them&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;data-transfer-objects-dto&quot;&gt;Data transfer objects (DTO)&lt;/h2&gt;
&lt;p&gt;DTO: quintessential form of a data structure -&amp;gt; a class with public variables and no functions&lt;/p&gt;

&lt;h3 id=&quot;active-records&quot;&gt;Active records&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Special forms of DTOs&lt;/li&gt;
  &lt;li&gt;Data structures with public (or bean-accessed) variables; but they typically have navigational methods like &lt;code class=&quot;highlighter-rouge&quot;&gt;save&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;find&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;objects&quot;&gt;Objects&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;expose behavior and hide data&lt;/li&gt;
  &lt;li&gt;easy to add new kinds of objects without changing existing behaviors&lt;/li&gt;
  &lt;li&gt;hard to add new behaviors to existing objects&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-structures&quot;&gt;Data Structures&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;expose data and have no significant behavior&lt;/li&gt;
  &lt;li&gt;easy to add new behaviors to existing data structures&lt;/li&gt;
  &lt;li&gt;hard to add new data structures to existing functions&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch7-error-handling&quot;&gt;Ch7. Error Handling&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Things can go wrong, and when they do, we as programmers are responsible for making sure that our code what it needs to do&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Error handling is important, but if it obscures logic, it’s wrong&lt;/li&gt;
  &lt;li&gt;It is better to throw an exception when you encounter an error. The calling code is cleaner. Its logic is not obscured by error handling&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;write-your-try-catch-finally-statement-first&quot;&gt;Write your &lt;code class=&quot;highlighter-rouge&quot;&gt;Try-Catch-Finally&lt;/code&gt; statement first&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;try&lt;/code&gt; blocks are like transactions&lt;/li&gt;
  &lt;li&gt;Your &lt;code class=&quot;highlighter-rouge&quot;&gt;catch&lt;/code&gt; has to leave your program in a consistent state, no matter what happens in the &lt;code class=&quot;highlighter-rouge&quot;&gt;try&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Try to write tests to force exceptions, and then add behavior to your handler to satisfy your tests -&amp;gt; cause you to build the transaction scope of the &lt;code class=&quot;highlighter-rouge&quot;&gt;try&lt;/code&gt; block first and help maintain the transaction nature of that scope&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;provide-context-with-exceptions&quot;&gt;Provide context with exceptions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Create informative error messages and pass them along with your exceptions&lt;/li&gt;
  &lt;li&gt;Mention the operation that failed and the type of failure&lt;/li&gt;
  &lt;li&gt;If you are logging in your application, pass along enough information to be able to log the error in your &lt;code class=&quot;highlighter-rouge&quot;&gt;catch&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Wrapping third-party APIs is a best practice -&amp;gt; minimize your dependencies upon it: you can choose to move to a different library in the future without much penalty; makes it easier to mock out third-party calls when you are testing your own code&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;define-the-normal-flow&quot;&gt;Define the normal flow&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Special case pattern&lt;/strong&gt;: you create a class or configure an object so that it handles a special case for you -&amp;gt; the client code doesn’t have to deal with exceptional behavior&lt;/p&gt;

&lt;h1 id=&quot;ch8-boundaries&quot;&gt;Ch8. Boundaries&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;It’s not our job to test the third-party code, but it may be in our best interest to write tests for the third-party code we use&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Learning tests&lt;/strong&gt;: call the third-party API, as we expect to use it in our application -&amp;gt; controlled experiments that check our understanding of that API&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clean Boundaries&lt;/strong&gt;: code at the boundaries needs clear separation and tests that define expectations&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Avoid letting too much of our code know about the third-party particulars. It’s betters to depend on something you control than on something you don’t control, lest it end up controlling you&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch9-unit-tests&quot;&gt;Ch9. Unit Tests&lt;/h1&gt;
&lt;h2 id=&quot;the-three-laws-of-tdd&quot;&gt;The three laws of TDD&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;First Law&lt;/strong&gt;: You may not write production code until you have written a failing unit test&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second Law&lt;/strong&gt;: You may not write more of a unit test than is sufficient to fail, and not compiling is failing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Third Law&lt;/strong&gt;: You may not write more production code than is sufficient to pass the current failing test&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;keeping-tests-clean&quot;&gt;Keeping tests clean&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Having dirty tests is equivalent to, if not worse than, having no tests&lt;/li&gt;
  &lt;li&gt;Tests must change as the production code evolves -&amp;gt; the dirtier the tests, the harder they are to change&lt;/li&gt;
  &lt;li&gt;If your tests are dirty, you begin to lose the ability to improve the structure of that code
    &lt;blockquote&gt;
      &lt;p&gt;Test code is just as important as production code. It requires thought, design, and care. It must be kept as clean as production code&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;clean-tests&quot;&gt;Clean tests&lt;/h2&gt;
&lt;p&gt;Readability is perhaps even more important in unit tests than it is in production code&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Clarity&lt;/li&gt;
  &lt;li&gt;Simplicity&lt;/li&gt;
  &lt;li&gt;Density of expression (say a lot with as few expressions as possible)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;BUILD-OPERATE-CHECK&lt;/strong&gt; pattern:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;First part builds up the test data&lt;/li&gt;
  &lt;li&gt;Second part operates on that test data&lt;/li&gt;
  &lt;li&gt;Third part checks that the operation yielded the expected results&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Domain-Specific Testing Language&lt;/strong&gt;: testing language (specialized API used by the tests) -&amp;gt; make tests expressive and succint -&amp;gt; make the tests more convenient to write and easier to read&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;given-when-then&lt;/strong&gt; convention: makes the tests even easier to read&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TEMPLATE METHOD&lt;/strong&gt; pattern -&amp;gt; putting the given/when parts in the base classs, and the then parts in different derivatives&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The number of asserts in a test ought to be minimized&lt;/li&gt;
  &lt;li&gt;We want to test a single concept in each test function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;first&quot;&gt;F.I.R.S.T.&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: when tests run slow, you won’t want to run them frequently&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Independent&lt;/strong&gt;: you should be able to run each test independently and run the tests in any order you like&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Repeatable&lt;/strong&gt;: if your tests aren’t repeatable in any environment, then you’ll always have an excuse for why they fail&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Self-Validating&lt;/strong&gt;: you should not have to read through a log file to tell whether the tests pass (should have a boolean output -&amp;gt; pass/fail)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Timely&lt;/strong&gt;: unit tests should be written just before the production code that makes them pass&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-classes&quot;&gt;Ch10. Classes&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Smaller is the primary rule when it comes to designing classes&lt;/li&gt;
  &lt;li&gt;Name of the class = describe what responsibilities it fulfills&lt;/li&gt;
  &lt;li&gt;If we cannot derive a concise name for a class, then it’s likely too large -&amp;gt; the more ambiguous the class name, the more likely it has too many responsibilities&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-single-responsibility-principle&quot;&gt;The Single Responsibility Principle&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SRP&lt;/strong&gt; is one of the more important concepts in OO design&lt;/li&gt;
  &lt;li&gt;States that a class or module should have one and only one, &lt;em&gt;reason to change&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Definition of responsibility&lt;/li&gt;
  &lt;li&gt;Guidelines for class size&lt;/li&gt;
  &lt;li&gt;A system with many small classes has no more moving parts than a system with a few large classes&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Trying to identify responsibilities (reasons to change) often helps us recognize and create better abstractions in our code&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;cohesion&quot;&gt;Cohesion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Classes should have a small number of instance variables&lt;/li&gt;
  &lt;li&gt;Each of the methods of a class should manipulate one or more of those variables&lt;/li&gt;
  &lt;li&gt;A class in which each variable is used by each method is &lt;strong&gt;maximally cohesive&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Maintaining cohesion results in many small classes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;organizing-for-change&quot;&gt;Organizing for change&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Change is continual&lt;/li&gt;
  &lt;li&gt;Every change -&amp;gt; risk that the remainder of the system no longer works as intended&lt;/li&gt;
  &lt;li&gt;Clean system -&amp;gt; organize our classes to reduce the risk of change&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Open-Closed Principle (OCP)&lt;/strong&gt;: another key OO class design principle -&amp;gt; Classes should be open for extension but closed for modification&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Ideal system -&amp;gt; we incorporate new features by extending the system, not by making modifications to existing code&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Dependency Inversion Principle (DIP)&lt;/strong&gt; -&amp;gt; classes should depend upon abstractions, not on concrete details&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch11-systems&quot;&gt;Ch11. Systems&lt;/h1&gt;
&lt;h2 id=&quot;separate-constructing-a-system-from-using-it&quot;&gt;Separate constructing a system from using it&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Software systems should separate the startup process, when the application objects are constructed and the dependencies are “wired” together, from the runtime logic that takes over after startup&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Startup process: &lt;em&gt;concern&lt;/em&gt; that any application must address&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Separation of concerns&lt;/em&gt;: one of the most important design techniques&lt;/li&gt;
  &lt;li&gt;Never let little, convenient idioms lead to modularity breakdown&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;separation-of-main&quot;&gt;Separation of main&lt;/h2&gt;
&lt;h3 id=&quot;factories&quot;&gt;Factories&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ABSTRACT FACTORY&lt;/strong&gt;: pattern -&amp;gt; give the application control of &lt;em&gt;when&lt;/em&gt; to build the object, but keep the details of that construction separate from the application code&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dependency-injection-di&quot;&gt;Dependency injection (DI)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Powerful mechanism for separating construction from use&lt;/li&gt;
  &lt;li&gt;Application of &lt;em&gt;Inversion of Control&lt;/em&gt; (IoC) to dependency management&lt;/li&gt;
  &lt;li&gt;Moves secondary responsibilities from an object to other objects that are dedicated to the purpose (supporting SRP)&lt;/li&gt;
  &lt;li&gt;The invoking object doesn’t control what kind of object is actually returned, but the invoking object still actively resolves the dependency
    &lt;blockquote&gt;
      &lt;p&gt;An object should not take responsibility for instantiating dependencies itself. Instead, it should pass this responsibility to another “authoritative” mechanism (inverting control). Setup is a global concern, this authoritative mechanism will be either the “main” routine or a special-purpose container&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scaling-up&quot;&gt;Scaling up&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Myth&lt;/strong&gt;: we can get systems “right the first time”&lt;/li&gt;
  &lt;li&gt;Implement only today’s stories -&amp;gt; then refactor and expand the system to implement new stories tomorrow = essence of iterative and incremental agility&lt;/li&gt;
  &lt;li&gt;TDD, refactoring, and the clean code they produce make this work at the code level&lt;/li&gt;
  &lt;li&gt;Software systems are unique compared to physical systems. Their archiectures can grow incrementally, &lt;strong&gt;if we maintain the proper separation of concerns&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;test-drive-the-system-architecture&quot;&gt;Test drive the system architecture&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Big Design Up Front (BDUF)&lt;/strong&gt;: harmful because it inhibits adapting to change, due to psychological resistance to discarding prior effort and because of the way architecture choices influence subsequent thinking about the design&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;optimize-decision-making&quot;&gt;Optimize decision making&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Modularity and separation of concerns make decentralized management and decision making possible&lt;/li&gt;
  &lt;li&gt;Give responsibilities to the most qualified persons&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;It is best to postpone decisions until the last possible moment&lt;/strong&gt; -&amp;gt; lets us make informed choices with the best possible information. A premature decision is a decision made with suboptimal knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Whether you are designing systems or individual modules, never forget to use &lt;strong&gt;the simplest thing that can possibly work&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch12-emergence&quot;&gt;Ch12. Emergence&lt;/h1&gt;
&lt;p&gt;A design is “simple”, if it follows these rules:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Run all the tests&lt;/li&gt;
  &lt;li&gt;Contains no duplication&lt;/li&gt;
  &lt;li&gt;Expresses the intent of the programmer&lt;/li&gt;
  &lt;li&gt;Minimizes the number of classes and methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;simple-design-rule-1-runs-all-the-tests&quot;&gt;Simple design rule 1: runs all the tests&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Systems that aren’t testable aren’t verifiable&lt;/li&gt;
  &lt;li&gt;A system that cannot be verified should never be deployed&lt;/li&gt;
  &lt;li&gt;Tight coupling makes it difficult to write tests&lt;/li&gt;
  &lt;li&gt;The more tests we write, the more we use principles like DIP and tools like dependency injection, interfaces, and abstraction to minimize coupling -&amp;gt; our designs improve even more&lt;/li&gt;
  &lt;li&gt;Primary OO goals -&amp;gt; low coupling and high cohesion&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;simple-design-rule-2-4-refactoring&quot;&gt;Simple design rule 2-4: refactoring&lt;/h2&gt;
&lt;p&gt;For each few lines of code we add, we pause and reflect on the new design&lt;/p&gt;

&lt;h3 id=&quot;no-duplication&quot;&gt;No duplication&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Duplication is the primary enemy of a well-designed system&lt;/li&gt;
  &lt;li&gt;It represents additional work, additional risk, and additional unnecessary complexity&lt;/li&gt;
  &lt;li&gt;TEMPLATE METHOD pattern: common technique for removing higher-level duplication&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;expressive&quot;&gt;Expressive&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;It’s easy to write code that &lt;em&gt;we&lt;/em&gt; understand, because at the time we write it we’re deep in an understanding of the problem we’re trying to solve. Other maintainers of the code aren’t going to have so deep an understanding&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Choose good names&lt;/li&gt;
  &lt;li&gt;Keep your functions and classes small&lt;/li&gt;
  &lt;li&gt;Use standard nomenclature&lt;/li&gt;
  &lt;li&gt;Tests primary goal = act as documentation by example&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The most important way to be expressive is to try. Care is a precious resource&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;minimal-classes-and-methods&quot;&gt;Minimal classes and methods&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Effort to make our classes and methods small -&amp;gt; we might create too many tiny classes and methods -&amp;gt; &lt;strong&gt;also keep our function and class counts low!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Although it’s important to keep class and function count low, it’s more important to have tests, eliminate duplication, and express yourself&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch13-concurrency&quot;&gt;Ch13. Concurrency&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Objects are abstractions of processing. Threads are abstractions of schedule - James O. Coplien&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;why-concurrency&quot;&gt;Why concurrency?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Concurrency is a decoupling strategy&lt;/li&gt;
  &lt;li&gt;Helps us decouple &lt;strong&gt;what&lt;/strong&gt; gets done from &lt;strong&gt;when&lt;/strong&gt; it gets done&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;myths-and-misconceptions&quot;&gt;Myths and misconceptions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Concurrency can &lt;em&gt;sometimes&lt;/em&gt; improve performance, but only when there is a lot of wait time that can be shared between multiple threads or multiple processors&lt;/li&gt;
  &lt;li&gt;The design of a concurrent algorithm can be remarkably different from the design of a single-threaded system&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Concurrency bugs aren’t usually repeatable&lt;/strong&gt;, so they are often ignored as one-offs instead of the true defects they are&lt;/li&gt;
  &lt;li&gt;Concurrency often requires a fundamental change in design strategy&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;concurrency-defense-principles&quot;&gt;Concurrency defense principles&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Single responsibility principle&lt;/strong&gt;: keep your concurrency-related code separate from other code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Limit the scope of data&lt;/strong&gt;: data encapsulation; severely limit the access of any data that may be shared&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use copies of data&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Threads should be as independent as possible&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;know-your-execution-models&quot;&gt;Know your execution models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Producer-Consumer&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Readers-Writers&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dining Philosophers&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;others&quot;&gt;Others&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Keep synchronized sections small&lt;/li&gt;
  &lt;li&gt;Think about shut-down early and get it working early&lt;/li&gt;
  &lt;li&gt;Write tests that have the potential to expose problems and then run them frequently, with different programatic configurations and system configurations and load&lt;/li&gt;
  &lt;li&gt;Do not ignore system failures as one-offs&lt;/li&gt;
  &lt;li&gt;Do not try to chase down nonthreading bugs and threading bugs at the same time. Make sure your code works outside of threads&lt;/li&gt;
  &lt;li&gt;Make your thread-based code especially pluggable so that you can run it in various configurations&lt;/li&gt;
  &lt;li&gt;Run your threaded code on all target platforms early and often&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Code that is simple to follow can become nightmarish when multiple threads and shared data get into the mix -&amp;gt; you need to write clean code with rigor or else face subtle and infrequent failures&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/clean_code/clean_code.jpeg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/clean_code/clean_code.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Mastering Large Datasets with Python: Parallelize and Distribute Your Python Code</title><link href="https://millengustavo.github.io/blog/book/software%20engineering/python/big%20data/2020/06/23/master-large-data-python.html" rel="alternate" type="text/html" title="Mastering Large Datasets with Python: Parallelize and Distribute Your Python Code" /><published>2020-06-23T00:00:00-05:00</published><updated>2020-06-23T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/software%20engineering/python/big%20data/2020/06/23/master-large-data-python</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/software%20engineering/python/big%20data/2020/06/23/master-large-data-python.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Authors: John T. Wolohan&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.manning.com/books/mastering-large-datasets-with-python&quot;&gt;Available here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch1-introduction&quot;&gt;Ch1. Introduction&lt;/h1&gt;
&lt;p&gt;Map and reduce style of programming:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;easily write parallel programs&lt;/li&gt;
  &lt;li&gt;organize the code around two functions: &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;MapReduce&lt;/code&gt; = framework for parallel and distributed computing; &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; = style of programming that allows running the work in parallel with minimal rewriting and extend the work to distributed workflows&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Dask&lt;/strong&gt; -&amp;gt; another tool for managing large data without &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;procedural-programming&quot;&gt;Procedural programming&lt;/h2&gt;
&lt;p&gt;Program Workflow&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Starts to run&lt;/li&gt;
  &lt;li&gt;issues an instruction&lt;/li&gt;
  &lt;li&gt;instruction is executed&lt;/li&gt;
  &lt;li&gt;repeat 2 and 3&lt;/li&gt;
  &lt;li&gt;finishes running&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;parallel-programming&quot;&gt;Parallel programming&lt;/h2&gt;
&lt;p&gt;Program workflow&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Starts to run&lt;/li&gt;
  &lt;li&gt;divides up the work into chunks of instructions and data&lt;/li&gt;
  &lt;li&gt;each chunk of work is executed independently&lt;/li&gt;
  &lt;li&gt;chunks of work are reassembled&lt;/li&gt;
  &lt;li&gt;finishes running&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;map_reduce.png&quot; alt=&quot;map_reduce&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; style is applicable everywhere, but its specific strengths are in areas where you may need to scale&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-map-function-for-transforming-data&quot;&gt;The map function for transforming data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;: function to transform sequences of data from one type to another&lt;/li&gt;
  &lt;li&gt;Always retains the same number of objects in the output as were provided in the input&lt;/li&gt;
  &lt;li&gt;performs one-to-one transformations -&amp;gt; is a great way to transform data so it is more suitable for use&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Declarative programming: focuses on explaining the logic of the code and not on specifying low-level details -&amp;gt; scaling is natural, the logic stays the same&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-reduce-function-for-advanced-transformations&quot;&gt;The reduce function for advanced transformations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;: transform a sequence of data into a data structure of any shape or size&lt;/li&gt;
  &lt;li&gt;MapReduce programming pattern relies on the &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; function to transform some data into another type of data and then uses the &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; function to combine that data&lt;/li&gt;
  &lt;li&gt;performs one-to-any transformations -&amp;gt; is a great way to assemble data into a final result&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;distributed-computing-for-speed-and-scale&quot;&gt;Distributed computing for speed and scale&lt;/h2&gt;
&lt;p&gt;Extension of parallel computing in which the computer resource we are dedicating to work on each chunk of a given task is its own machine&lt;/p&gt;

&lt;h2 id=&quot;hadoop-a-distributed-framework-for-map-and-reduce&quot;&gt;Hadoop: A distributed framework for map and reduce&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Designed as an open source implementation of Google’s original MapReduce framework&lt;/li&gt;
  &lt;li&gt;Evolved into distributed computing software used widely by companies processing large amounts of data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spark-for-high-powered-map-reduce-and-more&quot;&gt;Spark for high-powered map, reduce, and more&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Something of a sucessor to the Apache Hadoop framework that does more of its work in memory instead of by writing to file&lt;/li&gt;
  &lt;li&gt;Can run more than 100x faster than Hadoop&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;aws-elastic-mapreduce-emr---large-datasets-in-the-cloud&quot;&gt;AWS Elastic MapReduce (EMR) - Large datasets in the cloud&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Popular way to implement Hadoop and Spark&lt;/li&gt;
  &lt;li&gt;tackle small problems with parallel programming as its cost effective&lt;/li&gt;
  &lt;li&gt;tackle large problems with parallel programming because we can procure as many resources as we need&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-accelerating-large-dataset-work-map-and-parallel-computing&quot;&gt;Ch2. Accelerating large dataset work: Map and parallel computing&lt;/h1&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;’s primary capabilities:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loops&lt;/li&gt;
  &lt;li&gt;Transform data&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; evaluates only when necessary, not when called -&amp;gt; generic &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; object as output&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; makes easy to parallel code -&amp;gt; break into pieces&lt;/p&gt;

&lt;h2 id=&quot;pattern&quot;&gt;Pattern&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Take a sequence of data&lt;/li&gt;
  &lt;li&gt;Transform it with a function&lt;/li&gt;
  &lt;li&gt;Get the outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Generators&lt;/code&gt; instead of normal loops prevents storing all objects in memory in advance&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;lazy-functions-for-large-datasets&quot;&gt;Lazy functions for large datasets&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; = lazy function = it doesn’t evaluate when we call &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Python stores the instructions for evaluating the function and runs them at the exact moment we ask for the value&lt;/li&gt;
  &lt;li&gt;Common lazy objects in Python = &lt;code class=&quot;highlighter-rouge&quot;&gt;range&lt;/code&gt; function&lt;/li&gt;
  &lt;li&gt;Lazy &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; allows us to transform a lot of data without an unnecessarily large amount of memory or spending the time to generate it&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parallel-processing&quot;&gt;Parallel processing&lt;/h2&gt;
&lt;h3 id=&quot;problems&quot;&gt;Problems&lt;/h3&gt;
&lt;h4 id=&quot;inability-to-pickle-data-or-functions&quot;&gt;Inability to pickle data or functions&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Pickling&lt;/em&gt;: Python’s version of object serialization or mashalling&lt;/li&gt;
  &lt;li&gt;Storing objects from our code in an efficient binary format on the disk that can be read back by our program at a later time (&lt;code class=&quot;highlighter-rouge&quot;&gt;pickle&lt;/code&gt; module)&lt;/li&gt;
  &lt;li&gt;allows us to share data across procesors or even machines, saving the instructions and data and then executing them elsewhere&lt;/li&gt;
  &lt;li&gt;Objects we can’t pickle: lambda functions, nested functions, nested classes&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pathos&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;dill&lt;/code&gt; module allows us to pickle almost anything&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;order-sensitive-operations&quot;&gt;Order-sensitive operations&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Work in parallel: not guaranteed that tasks will be finished in the same order they’re input&lt;/li&gt;
  &lt;li&gt;If work needs to be processed in a linear order -&amp;gt; probably shouldn’t do it in parallel&lt;/li&gt;
  &lt;li&gt;Even though Python may not complete the problems in order, it still remembers the order in which it was supposed to do them -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; returns in the exact order we would expect, even if it doesn’t process in that order&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;state-dependent-operations&quot;&gt;State-dependent operations&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Common solution for the state problem: &lt;strong&gt;take the internal state and make it an external variable&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other-observations&quot;&gt;Other observations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Best way to flatten a list into one big list -&amp;gt; Python’s itertools &lt;code class=&quot;highlighter-rouge&quot;&gt;chain&lt;/code&gt; function: takes an iterable of iterables and chains them together so they can all be accessed one after another -&amp;gt; lazy by default&lt;/li&gt;
  &lt;li&gt;Best way to visualize graphs is to take it out of Python and import it into Gephi: dedicated piece of graph visualization software&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Anytime we’re converting a sequence of some type into a sequence of another type, what we’re doing can be expressed as a map -&amp;gt; N-to-N transformation: we’re converting N data elements, into N data elements but in different format&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;To make this type of problem parallel only adds up to few lines of code:
    &lt;ul&gt;
      &lt;li&gt;one import&lt;/li&gt;
      &lt;li&gt;wrangling our processors with &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;modifying our &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; statements to use &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool.map&lt;/code&gt; method&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch3-function-pipelines-for-mapping-complex-transformations&quot;&gt;Ch3. Function pipelines for mapping complex transformations&lt;/h1&gt;

&lt;h2 id=&quot;helper-functions-and-function-chains&quot;&gt;Helper functions and function chains&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Helper functions&lt;/strong&gt;: small, simple functions that we rely on to do complex things -&amp;gt; break down large problems into small pieces that we can code quickly&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Function chains&lt;/strong&gt; or &lt;strong&gt;pipelines&lt;/strong&gt;: the way we put helper functions to work&lt;/p&gt;

&lt;h3 id=&quot;creating-a-pipeline&quot;&gt;Creating a pipeline&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Chaining helper functions together&lt;/li&gt;
  &lt;li&gt;Ways to do this:
    &lt;ul&gt;
      &lt;li&gt;Using a sequence of maps&lt;/li&gt;
      &lt;li&gt;Chaining functions together with &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Creating a function pipeline with &lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; are functions in the &lt;code class=&quot;highlighter-rouge&quot;&gt;toolz&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;compose&quot;&gt;Compose&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from toolz.functoolz import compose
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Pass &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; all the functions we want to include in our pipeline&lt;/li&gt;
  &lt;li&gt;Pass in &lt;strong&gt;reverse order&lt;/strong&gt; because &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; is going to apply them backwards&lt;/li&gt;
  &lt;li&gt;Store the output of our &lt;code class=&quot;highlighter-rouge&quot;&gt;compose&lt;/code&gt; function, which is itself a function, to a variable&lt;/li&gt;
  &lt;li&gt;Call that variable or pass it along to &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;pipe&quot;&gt;Pipe&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from toolz.functoolz import pipe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; function will pass a value through a pipeline&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; expects the functions to be in the order we want to apply them&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pipe&lt;/code&gt; evaluates each of the functions and returns a results&lt;/li&gt;
  &lt;li&gt;If we want to pass it to &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;, we have to wrap it in a function definition&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Major advantages of creating pipelines of helper functions are that the code becomes: &lt;strong&gt;Readable and clear; Modular and easy to edit&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Modular code play very nice with &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and can readily move into parallel workflows, such as by using the &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;We can simplify working with nested data structures by using nested function pipelines, which we can apply with &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch4-processing-large-datasets-with-lazy-workflows&quot;&gt;Ch4. Processing large datasets with lazy workflows&lt;/h1&gt;
&lt;h2 id=&quot;laziness&quot;&gt;Laziness&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Lazy evaluation&lt;/em&gt;: strategy when deciding when to perform computations&lt;/li&gt;
  &lt;li&gt;Under lazy evaluation, the Python interpreter executes lazy Python code only when the program needs the results of that code&lt;/li&gt;
  &lt;li&gt;Opposite of &lt;em&gt;eager evaluation&lt;/em&gt;, where everything is evaluated when it’s called&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;shrinking-sequences-with-the-filter-function&quot;&gt;Shrinking sequences with the filter function&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt;: function for pruning sequences.&lt;/li&gt;
  &lt;li&gt;Takes a sequence and restricts it to only the elements that meet a given condition&lt;/li&gt;
  &lt;li&gt;Related functions to know
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.filterfalse&lt;/code&gt;: get all the results that make a qualifier function return &lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.dicttoolz.keyfilter&lt;/code&gt;: filter on the keys of a &lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.dicttoolz.valfilter&lt;/code&gt;: filter on the values of a &lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.dicttoolz.itemfilter&lt;/code&gt;: filter on both the keys and the values of a dict&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;combining-sequences-with-zip&quot;&gt;Combining sequences with zip&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt;: function for merging sequences.&lt;/li&gt;
  &lt;li&gt;Takes two sequences and returns a single sequence of &lt;code class=&quot;highlighter-rouge&quot;&gt;tuples&lt;/code&gt;, each of which contains an element from each of the original sequences&lt;/li&gt;
  &lt;li&gt;Behaves like a zipper, it interlocks the values of Python iterables&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lazy-file-searching-with-iglob&quot;&gt;Lazy file searching with iglob&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;iglob&lt;/code&gt;: function for lazily reading from the filesystem.&lt;/li&gt;
  &lt;li&gt;Lazy way of querying our filesystem&lt;/li&gt;
  &lt;li&gt;Find a sequence of files on our filesystem that match a given pattern&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from glob import iglob
posts = iglob(&quot;path/to/posts/2020/06/*.md&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;understanding-iterators-the-magic-behind-lazy-python&quot;&gt;Understanding iterators: the magic behind lazy Python&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Replace data with instructions about where to find data and replace transformations with instructions for how to execute those transformations.&lt;/li&gt;
  &lt;li&gt;The computer only has to concern itself with the data it is processing right now, as opposed to the data it just processed or has to process in the future&lt;/li&gt;
  &lt;li&gt;Iterators are the base class of all the Python data types that can be iterated over&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The iteration process is defined by a special method called &lt;code class=&quot;highlighter-rouge&quot;&gt;.__iter__()&lt;/code&gt;. If a class has this method and returns an object with a &lt;code class=&quot;highlighter-rouge&quot;&gt;.__next__()&lt;/code&gt; method, then we can iterate over it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;One-way streets: once we call &lt;code class=&quot;highlighter-rouge&quot;&gt;next&lt;/code&gt;, the item returned is removed from the sequence. We can never back up or retrieve that item again&lt;/li&gt;
  &lt;li&gt;Not meant for by-hand inspection -&amp;gt; meant for processing big data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generators-functions-for-creating-data&quot;&gt;Generators: functions for creating data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Class of functions in Python that lazily produce values in a sequence&lt;/li&gt;
  &lt;li&gt;We can create generators with functions using &lt;code class=&quot;highlighter-rouge&quot;&gt;yield&lt;/code&gt; statements or through concise and powerful list comprehension-like generator expressions&lt;/li&gt;
  &lt;li&gt;They’re a simple way of implementing an iterator&lt;/li&gt;
  &lt;li&gt;Primary advantage of generators and lazy functions: &lt;strong&gt;avoiding storing more in memory than we need to&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.islice&lt;/code&gt;: take chunks from a sequence&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lazy functions are great at processing data, but hardware still limits how quickly we can work through it&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.frequencies&lt;/code&gt;: takes a sequence in and returns a &lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt; of items that occurred in the sequence as keys with corresponding values equal to the number of times they occurred -&amp;gt; provides the frequencies of items in our sequence&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;simulations&quot;&gt;Simulations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;For simulations -&amp;gt; writing classes allow us to consolidate the data about each piece of the simulation&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.count()&lt;/code&gt;: returns a generator that produces an infinite sequence of increasing numbers&lt;/li&gt;
  &lt;li&gt;Unzipping = the opposite of zipping -&amp;gt; takes a single sequence and returns two -&amp;gt; unzip = &lt;code class=&quot;highlighter-rouge&quot;&gt;zip(*my_sequence)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;operator.methodcaller&lt;/code&gt;: takes a string and returns a function that calls that method with the name of that string on any object passed to it -&amp;gt; call class methods using functions is helpful = allows us to use functions like &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt; on them&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch5-accumulation-operations-with-reduce&quot;&gt;Ch5. Accumulation operations with reduce&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;: function for N-to-X transformations&lt;/li&gt;
  &lt;li&gt;We have a sequence and want to transform it into something that we can’t use &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; for&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; can take care of the transformations in a very concise manner, whereas &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; can take care of the very final transformation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;three-parts-of-reduce&quot;&gt;Three parts of reduce&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Accumulator function&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sequence&lt;/strong&gt;: object that we can iterate through, such as lists, strings, and generators&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Initializer&lt;/strong&gt;: initial value to be passed to our accumulator (may be &lt;em&gt;optional&lt;/em&gt;) -&amp;gt; use an initalizer not when we want to change the value of our data, but when we want to change the &lt;em&gt;type&lt;/em&gt; of the data&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from functools import reduce

reduce(acc_fn, sequence, initializer)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;accumulator-functions&quot;&gt;Accumulator functions&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Does the heavy lifting for &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Special type of helper function&lt;/li&gt;
  &lt;li&gt;Common prototype:
    &lt;ul&gt;
      &lt;li&gt;take an accumulated value and the next element in the sequence&lt;/li&gt;
      &lt;li&gt;return another object, typically of the same type as the accumulated value&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;accumulator functions always needs to return a value&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Accumulator functions take two variables: one for the accumulated data (often designated as acc, left, or a), and one for the next element in the sequence (designated nxt, right, or b).&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def my_add(acc, nxt):
    return acc + nxt

# or, using lambda functions
lambda acc, nxt: acc + nxt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;reductions&quot;&gt;Reductions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;frequencies&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;using-map-and-reduce-together&quot;&gt;Using map and reduce together&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;If you can decompose a problem into an N-to-X transformation, all that stands between you and a reduction that solves that problem is a well-crafted accumulation function&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Using &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; pattern to decouple the transformation logic from the actual transformation itself:
    &lt;ul&gt;
      &lt;li&gt;leads to highly reusable code&lt;/li&gt;
      &lt;li&gt;with large datasets -&amp;gt; simple functions becomes paramount -&amp;gt; we may have to wait a long time to discover we made a small error&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;speeding-up-map-and-reduce&quot;&gt;Speeding up map and reduce&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Using a parallel map can counterintuitively be slower than using a lazy map in map an reduce scenarios&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;We can always use parallelization at the &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; level instead of at the &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; level&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-speeding-up-map-and-reduce-with-advanced-parallelization&quot;&gt;Ch6. Speeding up map and reduce with advanced parallelization&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;: use parallelization in the accumulation process instead of the transformation process&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;getting-the-most-out-of-parallel-map&quot;&gt;Getting the most out of parallel map&lt;/h2&gt;
&lt;p&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; will be slower than lazy &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;we’re going to iterate through the sequence a second time later in our workflow&lt;/li&gt;
  &lt;li&gt;size of the work done in each parallel instance is small compared to the overhead that parallelization imposes -&amp;gt; &lt;em&gt;chunksize&lt;/em&gt;: size of the different pieces into which we break our tasks for parallel processing&lt;/li&gt;
  &lt;li&gt;Python makes &lt;em&gt;chunksize&lt;/em&gt; available as an option -&amp;gt; vary according to the task at hand&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;more-parallel-maps-imap-and-starmap&quot;&gt;More parallel maps: &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt;&lt;/h3&gt;
&lt;h4 id=&quot;imap&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt;: for lazy parallel mapping&lt;/li&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt; method to work in parallel on very large sequences efficiently&lt;/li&gt;
  &lt;li&gt;Lazy and parallel? use the &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;.imap_unordered&lt;/code&gt; methods of &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool()&lt;/code&gt; -&amp;gt; both methods return iterators instead of lists&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.imap_unordered&lt;/code&gt;: behaves the same, except it doesn’t necessarily put the sequence in the right order for our iterator&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;starmap&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt; to work with complex iterables, especially those we’re likely to create using the &lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt; function -&amp;gt; more than one single parameter (map’s limitation)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;starmap&lt;/code&gt; unpacks &lt;code class=&quot;highlighter-rouge&quot;&gt;tuples&lt;/code&gt; as &lt;strong&gt;positional parameters&lt;/strong&gt; to the function with which we’re mapping&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools.starmap&lt;/code&gt;: lazy function&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Pool().starmap&lt;/code&gt;: parallel function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parallel-reduce-for-faster-reductions&quot;&gt;Parallel reduce for faster reductions&lt;/h2&gt;
&lt;p&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;break a problem into chunks&lt;/li&gt;
  &lt;li&gt;make no guarantees about order&lt;/li&gt;
  &lt;li&gt;need to pickle data&lt;/li&gt;
  &lt;li&gt;be finicky about stateful objects&lt;/li&gt;
  &lt;li&gt;run slower than its linear counterpart on small datasets&lt;/li&gt;
  &lt;li&gt;run faster than its linear counterpart on big datasets&lt;/li&gt;
  &lt;li&gt;require an accumulator function, some data, and an initial value&lt;/li&gt;
  &lt;li&gt;perform N-to-X transformations&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Parallel reduce has six parameters: an accumulation function, a sequence, an initializer value, a map, a chunksize, and a combination function - three more than the standard reduce function&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; workflow:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;break our problem into pieces&lt;/li&gt;
  &lt;li&gt;do some work&lt;/li&gt;
  &lt;li&gt;combine the work&lt;/li&gt;
  &lt;li&gt;return a result&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;With parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; we trade the simplicity of always having the same combination function for the flexibility of more possible transformations&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Implementing parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Importing the proper classes and functions&lt;/li&gt;
  &lt;li&gt;Rounding up some processors&lt;/li&gt;
  &lt;li&gt;Passing our &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; function the right helper functions and variables&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Python doesn’t natively support parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;pathos&lt;/code&gt; library&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz.fold&lt;/code&gt; -&amp;gt; parallel &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; implementation&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;toolz&lt;/code&gt; library: functional utility library that Python never came with. High-performance version of the library = &lt;code class=&quot;highlighter-rouge&quot;&gt;CyToolz&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch7-processing-truly-big-datasets-with-hadoop-and-spark&quot;&gt;Ch7. Processing truly big datasets with Hadoop and Spark&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hadoop&lt;/strong&gt;: set of tools that support distributed map and reduce style of programming through Hadoop MapReduce&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Spark&lt;/strong&gt;: analytics toolkit designed to modernize Hadoop&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;distributed-computing&quot;&gt;Distributed computing&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;share tasks and data long-term across a network of computers&lt;/li&gt;
  &lt;li&gt;offers large benefits in speed when we can parallelize our work&lt;/li&gt;
  &lt;li&gt;challenges:
    &lt;ul&gt;
      &lt;li&gt;keeping track of all our data&lt;/li&gt;
      &lt;li&gt;coordinating our work&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;If we distribute our work prematurely, we’ll end up losing performance spending too much time talking between computers and processors. A lot of performance improvements at the high-performance limits of distributed computing revolve around &lt;strong&gt;optimizing communication between machines&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;hadoop-five-modules&quot;&gt;Hadoop five modules&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;MapReduce&lt;/em&gt;: way of dividing work into parallelizable chunks&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;YARN&lt;/em&gt;: scheduler and resource manager&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;HDFS&lt;/em&gt;: file system for Hadoop&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Ozone&lt;/em&gt;: Hadoop extension for object storage and semantic computing&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Common&lt;/em&gt;: set of utilities that are shared across the previous four modules&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;yarn-for-job-scheduling&quot;&gt;YARN for job scheduling&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Scheduling
    &lt;ul&gt;
      &lt;li&gt;Oversees all of the work that is being done&lt;/li&gt;
      &lt;li&gt;Acts as a final decision maker in terms of how resources should be allocated across the cluster&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Application management (&lt;em&gt;node managers&lt;/em&gt;): work at the node (single-machine) level to determine how resources should be allocated within that machine
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;federation&lt;/em&gt;: tie together resource managers in extremely high demand use cases where thousands of nodes are not sufficient&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-data-storage-backbone-of-hadoop-hdfs&quot;&gt;The data storage backbone of Hadoop: HDFS&lt;/h3&gt;
&lt;p&gt;Hadoop Distributed File System (HDFS) -&amp;gt; reliable, performant foundation for high-performance distributed computing (but with that comes complexity). Use cases:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;process big datasets&lt;/li&gt;
  &lt;li&gt;be flexible in hardware choice&lt;/li&gt;
  &lt;li&gt;be protected against hardware failure&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moving code is faster than moving data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mapreduce-jobs-using-python-and-hadoop-streaming&quot;&gt;MapReduce jobs using Python and Hadoop Streaming&lt;/h3&gt;
&lt;p&gt;Hadoop MapReduce with Python -&amp;gt; Hadoop Streaming = utility for using Hadoop MapReduce with programming languages besides Java&lt;/p&gt;

&lt;p&gt;Hadoop natively supports compression data: .gz, .bz2, and .snappy&lt;/p&gt;

&lt;h2 id=&quot;spark-for-interactive-workflows&quot;&gt;Spark for interactive workflows&lt;/h2&gt;
&lt;p&gt;Analytics-oriented data processing framework designed to take advantage of higher-RAM compute clusters. Advantages for Python programmers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;direct Python interface - &lt;code class=&quot;highlighter-rouge&quot;&gt;PySpark&lt;/code&gt;: allows for us to interactively explore big data through a PySpark shell REPL&lt;/li&gt;
  &lt;li&gt;can query SQL databases directly (Java Database Connectivity - JDBC)&lt;/li&gt;
  &lt;li&gt;has a &lt;em&gt;DataFrame&lt;/em&gt; API: rows-and-columns data structure familiar to &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt; -&amp;gt; provides a convenience layer on top of the core Spark data object: the RDD (Resilient Distributed Dataset)&lt;/li&gt;
  &lt;li&gt;Spark has two high-performance data structures: RDDs, which are excellent for any type of data, and DataFrames, which are optimized for tabular data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Favor Spark over Hadoop when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;processing streaming data&lt;/li&gt;
  &lt;li&gt;need to get the task completed nearly instantaneously&lt;/li&gt;
  &lt;li&gt;willing to pay for high-RAM compute clusters&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pyspark-for-mixing-python-and-spark&quot;&gt;PySpark for mixing Python and Spark&lt;/h3&gt;
&lt;p&gt;PySpark: we can call Spark’s Scala methods through Python just like we would a normal Python library&lt;/p&gt;

&lt;h1 id=&quot;ch8-best-practices-for-large-data-with-apache-streaming-and-mrjob&quot;&gt;Ch8. Best practices for large data with Apache Streaming and mrjob&lt;/h1&gt;
&lt;p&gt;Use Hadoop to process&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;lots of data fast: distributed parallelization&lt;/li&gt;
  &lt;li&gt;data that’s important: low data loss&lt;/li&gt;
  &lt;li&gt;enormous amounts of data: petabyte scale&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Drawbacks&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;To use Hadoop with Python -&amp;gt; Hadoop Streaming utility&lt;/li&gt;
  &lt;li&gt;Repeatedly read in string from &lt;code class=&quot;highlighter-rouge&quot;&gt;stdin&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Error messages for Java are not helpful&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;unstructured-data-logs-and-documents&quot;&gt;Unstructured data: Logs and documents&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hadoop creators designed Hadoop to work on &lt;em&gt;unstructured data&lt;/em&gt; -&amp;gt; data in the form of documents&lt;/li&gt;
  &lt;li&gt;Unstructured data is notoriously unwieldly =/= tabular data&lt;/li&gt;
  &lt;li&gt;But, is one of the most common forms of data around&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;json-for-passing-data-between-mapper-and-reducer&quot;&gt;JSON for passing data between mapper and reducer&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;JavaScript Object Notation (JSON)&lt;/li&gt;
  &lt;li&gt;Data format used for moving data in plain text between one place and another&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;json.dumps()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;json.loads()&lt;/code&gt; functions from Python’s json library to achieve the transfer&lt;/li&gt;
  &lt;li&gt;Advantages:
    &lt;ul&gt;
      &lt;li&gt;easy for humans and machines to read&lt;/li&gt;
      &lt;li&gt;provides a number of useful basic data types (string, numeric, array)&lt;/li&gt;
      &lt;li&gt;emphasis on key-value pairs that aids the loose coupling of systems&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mrjob-for-pythonic-hadoop-streaming&quot;&gt;mrjob for pythonic Hadoop streaming&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt;: Python library for Hadoop Streaming that focuses on cloud compatibility for truly scalable analysis&lt;/li&gt;
  &lt;li&gt;keeps the mapper and reducer steps but wraps them up in a single worker class named &lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt; versions of &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt; share the same type signature, taking in keys and values and outputting keys and values&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt; enforces JSON data exchange between the mapper and reducer phases, so we need to ensure that our output data is JSON serializable.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch9-pagerank-with-map-and-reduce-in-pyspark&quot;&gt;Ch9. PageRank with map and reduce in PySpark&lt;/h1&gt;
&lt;p&gt;PySpark’s RDD class methods:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;-like methods: replicate the function of &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;-like methods: replicate the function of &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Convenience methods&lt;/em&gt;: solve common problems&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Partitions&lt;/strong&gt; are the abstraction that RDDs use to implement parallelization. The data in an RDD is split up across different partitions, and each partition is handled in memory. It is common in large data tasks to partition an RDD by a key&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;map-like-methods-in-pyspark&quot;&gt;Map-like methods in PySpark&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.map&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.flatMap&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.mapValues&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.flatMapValues&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;. mapPartitions&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.mapPartitionsWithIndex&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reduce-like-methods-in-pyspark&quot;&gt;Reduce-like methods in PySpark&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.reduce&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.fold&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.aggregate&lt;/code&gt; -&amp;gt; provides all the functionality of a parallel reduce. We can provide an initializer value, an aggregation function, and a combination function&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;convenience-methods-in-pyspark&quot;&gt;Convenience methods in PySpark&lt;/h3&gt;
&lt;p&gt;Many of these mirror functions in &lt;code class=&quot;highlighter-rouge&quot;&gt;functools&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;itertools&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;toolz&lt;/code&gt;. Some examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;.countByKey()&lt;/li&gt;
  &lt;li&gt;.countByValue()&lt;/li&gt;
  &lt;li&gt;.distinct()&lt;/li&gt;
  &lt;li&gt;.countApproxDistinct()&lt;/li&gt;
  &lt;li&gt;.filter()&lt;/li&gt;
  &lt;li&gt;.first()&lt;/li&gt;
  &lt;li&gt;.groupBy()&lt;/li&gt;
  &lt;li&gt;.groupByKey()&lt;/li&gt;
  &lt;li&gt;.saveAsTextFile()&lt;/li&gt;
  &lt;li&gt;.take()&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;saving-rdds-to-text-files&quot;&gt;Saving RDDs to text files&lt;/h4&gt;
&lt;p&gt;Excellent for a few reasons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The data is in a human-readable, persistent format.&lt;/li&gt;
  &lt;li&gt;We can easily read this data back into Spark with the &lt;code class=&quot;highlighter-rouge&quot;&gt;.textFile&lt;/code&gt; method of &lt;code class=&quot;highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The data is well structured for other parallel tools, such as Hadoop’s MapReduce.&lt;/li&gt;
  &lt;li&gt;We can specify a compression format for efficient data storage or transfer.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;RDD &lt;code class=&quot;highlighter-rouge&quot;&gt;.aggregate&lt;/code&gt; method—returns a dict. We need an RDD so that we can take advantage of Spark’s parallelization. To get an RDD, we’ll need to explicitly convert the items of that dict into an RDD using the &lt;code class=&quot;highlighter-rouge&quot;&gt;.parallelize&lt;/code&gt; method from our SparkContext: &lt;code class=&quot;highlighter-rouge&quot;&gt;sc&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Spark programs often use \ characters in their method chaining to increase their readability&lt;/li&gt;
  &lt;li&gt;Using the &lt;code class=&quot;highlighter-rouge&quot;&gt;byKey&lt;/code&gt; variations of methods in PySpark often results in significant speed-ups because like data is worked on by the same distributed compute worker&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-faster-decision-making-with-machine-learning-and-pyspark&quot;&gt;Ch10. Faster decision-making with machine learning and PySpark&lt;/h1&gt;
&lt;p&gt;One of the reasons why Spark is so popular = built-in machine learning capabilities&lt;/p&gt;

&lt;p&gt;PySpark’s machine learning capabilities live in a package called &lt;code class=&quot;highlighter-rouge&quot;&gt;ml&lt;/code&gt;. This package itself contains a few different modules categorizing some of the core machine learning capabilities, including&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.feature&lt;/code&gt; — For feature transformation and creation&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.classification&lt;/code&gt; — Algorithms for judging the category in which a data point belongs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.tuning&lt;/code&gt; — Algorithms for improving our machine learners&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.evaluation&lt;/code&gt; — Algorithms for evaluating machine leaners&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyspark.ml.util&lt;/code&gt; — Methods of saving and loading machine learners&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;PySpark’s machine learning features expect us to have our data in a PySpark &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; object - not an &lt;code class=&quot;highlighter-rouge&quot;&gt;RDD&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;RDD&lt;/code&gt; is an abstract parallelizable data structure at the core of Spark, whereas the &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; is a layer on top of the &lt;code class=&quot;highlighter-rouge&quot;&gt;RDD&lt;/code&gt; that provides a notion of rows and columns&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;organizing-the-data-for-learning&quot;&gt;Organizing the data for learning&lt;/h2&gt;
&lt;p&gt;Spark’s ml classifiers look for two columns in a &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;label&lt;/code&gt; column: indicates the correct classification of the data&lt;/li&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;features&lt;/code&gt; column: contains the features we’re going to use to predict that label&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;auxiliary-classes&quot;&gt;Auxiliary classes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;PySpark’s &lt;code class=&quot;highlighter-rouge&quot;&gt;StringIndexer&lt;/code&gt;: transforms categorical data stored as category names (using strings) and indexes the names as numerical variables. &lt;code class=&quot;highlighter-rouge&quot;&gt;StringIndexer&lt;/code&gt; indexes categories in order of frequency — from most common to least common. The most common category will be 0, the second most common category 1, and so on&lt;/li&gt;
  &lt;li&gt;Most data structures in Spark are immutable -&amp;gt; property of Scala (in which Spark is written)&lt;/li&gt;
  &lt;li&gt;Spark’s ml only want one column name &lt;code class=&quot;highlighter-rouge&quot;&gt;features&lt;/code&gt; -&amp;gt; PySpark’s &lt;code class=&quot;highlighter-rouge&quot;&gt;VectorAssembler&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;Transformer&lt;/code&gt; like &lt;code class=&quot;highlighter-rouge&quot;&gt;StringIndexer&lt;/code&gt; -&amp;gt; takes some input column names and an output column name and has methods to return a new &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; that has all the columns of the original, plus the new column we want to add&lt;/li&gt;
  &lt;li&gt;The feature creation classes are &lt;code class=&quot;highlighter-rouge&quot;&gt;Transformer&lt;/code&gt;-class objects, and their methods return new &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrames&lt;/code&gt;, rather than transforming them in place&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;PySpark’s &lt;code class=&quot;highlighter-rouge&quot;&gt;ml.evaluation&lt;/code&gt; module:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BinaryClassifierEvaluator&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RegressionEvaluator&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;MulticlassClassificationEvaluator&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cross-validation-in-pyspark&quot;&gt;Cross-validation in PySpark&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CrossValidator&lt;/code&gt; class: k-fold cross-validation, needs to be initialized with:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;An &lt;em&gt;estimator&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;parameter estimator&lt;/em&gt; - &lt;code class=&quot;highlighter-rouge&quot;&gt;ParamGridBuilder&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;An &lt;em&gt;evaluator&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch11-large-datasets-in-the-cloud-with-amazon-web-services-and-s3&quot;&gt;Ch11. Large datasets in the cloud with Amazon Web Services and S3&lt;/h1&gt;
&lt;p&gt;S3 is the go-to service for large datasets:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;effectively unlimited storage capacity&lt;/em&gt;. We never have to worry about our dataset becoming too large&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;cloud-based&lt;/em&gt;. We can scale up and down quickly as necessary.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;offers object storage&lt;/em&gt;. We can focus on organizing our data with metadata and store many different types of data.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;managed service&lt;/em&gt;. Amazon Web Services takes care of a lot of the details for us, such as ensuring data availability and durability. They also take care of security patches and software updates.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;supports versioning and life cycle policies&lt;/em&gt;. We can use them to update or archive our data as it ages&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;objects-for-convenient-heterogenous-storage&quot;&gt;Objects for convenient heterogenous storage&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Object storage: storage pattern that focuses on the &lt;strong&gt;what of the data instead of the where&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;With object storage we recognize objects by a unique identifier (instead of the name and directory)&lt;/li&gt;
  &lt;li&gt;Supports arbitrary metadata -&amp;gt; we can tag our objects flexibly based on our needs (helps us find those objects later when we need to use them)&lt;/li&gt;
  &lt;li&gt;Querying tools are available for S3 that allow SQL-like querying on these metadata tags for metadata analysis&lt;/li&gt;
  &lt;li&gt;Unique identifiers -&amp;gt; we can store heterogenous data in the same way&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parquet-a-concise-tabular-data-store&quot;&gt;Parquet: A concise tabular data store&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;CSV is a simple, tabular data store, and JSON is a human-readable document store. Both are common in data interchange and are often used in the storage of distributed large datasets. Parquet is a Hadoop- native tabular data format.&lt;/li&gt;
  &lt;li&gt;Parquet uses clever metadata to improve the performance of map and reduce operations. Running a job on Parquet can take as little as 1/100th the time a comparable job on a CSV or JSON file would take. Additionally, Parquet supports efficient compression. As a result, it can be stored at a fraction of the cost of CSV or JSON.&lt;/li&gt;
  &lt;li&gt;These benefits make Parquet an excellent option for data that primarily needs to be read by a machine, such as for batch analytics operations. JSON and CSV remain good options for smaller data or data that’s likely to need some human inspection.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Boto is a library that provides Pythonic access to many of the AWS APIs. We need the access key and secret key to programmatically access AWS through boto&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch12-mapreduce-in-the-cloud-with-amazons-elastic-mapreduce&quot;&gt;Ch12. MapReduce in the cloud with Amazon’s Elastic MapReduce&lt;/h1&gt;
&lt;h2 id=&quot;convenient-cloud-clusters-with-emr&quot;&gt;Convenient cloud clusters with EMR&lt;/h2&gt;
&lt;p&gt;Ways to get access to a compute cluster that support both Hadoop and Spark:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;AWS: Amazon’s Elastic MapReduce&lt;/li&gt;
  &lt;li&gt;Microsoft’s Azure HDInsight&lt;/li&gt;
  &lt;li&gt;Google’s Cloud Dataproc&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aws-emr&quot;&gt;AWS EMR&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;AWS EMR is a managed data cluster service&lt;/li&gt;
  &lt;li&gt;We specify general properties of the cluster, and AWS runs software that creates the cluster for us&lt;/li&gt;
  &lt;li&gt;When we’re done using the cluster, AWS absorbs the compute resources back into its network&lt;/li&gt;
  &lt;li&gt;Pricing model is a per-compute-unit per-second charge&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;There are no cost savings to doing things slowly. AWS encourages us to parallelize our problems away&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;starting-emr-clusters-with-mrjob&quot;&gt;Starting EMR clusters with mrjob&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;We can run Hadoop jobs on EMR with the &lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt; library, which allows us to write distributed MapReduce and procure cluster computing in Python.&lt;/li&gt;
  &lt;li&gt;We can use &lt;code class=&quot;highlighter-rouge&quot;&gt;mrjob&lt;/code&gt;’s configuration files to describe what we want our clusters to look like, including which instances we’d like to use, where we’d like those instances to be located, and any tags we may want to add.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hadoop on EMR is excellent for large data processing workloads, such as batch analytics or extract-transform-load (ETL)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;machine-learning-in-the-cloud-with-spark-on-emr&quot;&gt;Machine learning in the cloud with Spark on EMR&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hadoop is great for low-memory workloads and massive data.&lt;/li&gt;
  &lt;li&gt;Spark is great for jobs that are harder to break down into map and reduce steps, and situations where we can afford higher memory machines&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;running-machine-learning-algorithms-on-a-truly-large-dataset&quot;&gt;Running machine learning algorithms on a truly large dataset&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Get a sample of the full dataset.&lt;/li&gt;
  &lt;li&gt;Train and evaluate a few models on that dataset.&lt;/li&gt;
  &lt;li&gt;Select some models to evaluate on the full dataset.&lt;/li&gt;
  &lt;li&gt;Train several models on the full dataset in the cloud.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Run your Spark code with &lt;code class=&quot;highlighter-rouge&quot;&gt;spark-submit&lt;/code&gt; utility instead of Python. The &lt;code class=&quot;highlighter-rouge&quot;&gt;spark-submit&lt;/code&gt; utility queues up a Spark job, which will run in parallel locally and simulate what would happen if you ran the program on an active cluster&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;ec2-instance-types-and-clusters&quot;&gt;EC2 instance types and clusters&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;M-series&lt;/code&gt;: use for Hadoop and for testing Spark jobs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;C-series&lt;/code&gt;: compute-heavy workloads such as Spark analytics, Batch Spark jobs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;R-series&lt;/code&gt;: high-memory, use for streaming analytics&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;software-available-on-emr&quot;&gt;Software available on EMR&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;JupyterHub: cluster-ready version of Jupyter Notebook -&amp;gt; run interactive Spark and Hadoop jobs from a notebook environment&lt;/li&gt;
  &lt;li&gt;Hive: compile SQL code to Hadoop MapReduce jobs&lt;/li&gt;
  &lt;li&gt;Pig: compile &lt;em&gt;Pig-latin&lt;/em&gt; (SQL-like) commands to run Hadoop MapReduce jobs&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/master_large_data_python/master_large_data_python.png" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/master_large_data_python/master_large_data_python.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">High performance Python: Practical Performant Programming for Humans</title><link href="https://millengustavo.github.io/blog/book/python/software%20engineering/2020/06/10/high-performance-python.html" rel="alternate" type="text/html" title="High performance Python: Practical Performant Programming for Humans" /><published>2020-06-10T00:00:00-05:00</published><updated>2020-06-10T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/python/software%20engineering/2020/06/10/high-performance-python</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/python/software%20engineering/2020/06/10/high-performance-python.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Authors: Micha Gorelick, Ian Ozsvald&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Every programmer can benefit from understanding how to build performant systems (…) When something becomes ten times cheaper in time or compute costs, suddenly the set of applications you can address is wider than you imagined”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Supplemental material for the book (code examples, exercises, etc.) is available for download at https://github.com/mynameisfiber/high_performance_python_2e.&lt;/p&gt;

&lt;h1 id=&quot;ch1-understanding-performant-python&quot;&gt;Ch1. Understanding Performant Python&lt;/h1&gt;

&lt;h2 id=&quot;why-use-python&quot;&gt;Why use Python?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;highly expressive and easy to learn&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;scikit-learn&lt;/code&gt; wraps LIBLINEAR and LIBSVM (written in C)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; includes BLAS and other C and Fortran libraries&lt;/li&gt;
  &lt;li&gt;python code that properly utilizes these modules can be as fast as comparable C code&lt;/li&gt;
  &lt;li&gt;“batteries included”&lt;/li&gt;
  &lt;li&gt;enable fast prototyping of an idea&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-to-be-a-highly-performant-programmer&quot;&gt;How to be a highly performant programmer&lt;/h2&gt;
&lt;p&gt;Overall team velocity is far more important than speedups and complicated solutions. Several factors are key to this:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Good structure&lt;/li&gt;
  &lt;li&gt;Documentation&lt;/li&gt;
  &lt;li&gt;Debuggability&lt;/li&gt;
  &lt;li&gt;Shared standards&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch2-profiling-to-find-bottlenecks&quot;&gt;Ch2. Profiling to Find Bottlenecks&lt;/h1&gt;

&lt;p&gt;Profiling let you make the most pragmatic decisions for the least overall effort: Code run “fast enough” and “lean enough”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“If you avoid profiling and jump to optmization, you’ll quite likely do more work in the long run. Always be driven by the results of profiling”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;“Embarrassingly parallel problem”&lt;/em&gt;: no data is shared between points&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;timeit&lt;/code&gt; module temporarily disables the garbage collector&lt;/p&gt;

&lt;h2 id=&quot;cprofile-module&quot;&gt;cProfile module&lt;/h2&gt;
&lt;p&gt;Built-in profiling tool in the standard library&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;profile&lt;/code&gt;: original and slower pure Python profiler&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cProfile&lt;/code&gt;: same interface as &lt;code class=&quot;highlighter-rouge&quot;&gt;profile&lt;/code&gt; and is written in &lt;code class=&quot;highlighter-rouge&quot;&gt;C&lt;/code&gt; for a lower overhead&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Generate a &lt;em&gt;hypothesis&lt;/em&gt; about the speed of parts of your code&lt;/li&gt;
  &lt;li&gt;Measure how wrong you are&lt;/li&gt;
  &lt;li&gt;Improve your intuition about certain coding styles&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;visualizing-cprofile-output-with-snakeviz&quot;&gt;Visualizing cProfile output with Snakeviz&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;snakeviz&lt;/code&gt;: visualizer that draws the output of &lt;code class=&quot;highlighter-rouge&quot;&gt;cProfile&lt;/code&gt; as a diagram -&amp;gt; larger boxes are areas of code that take longer to run&lt;/p&gt;

&lt;h2 id=&quot;using-line_profiler-for-line-by-line-measurements&quot;&gt;Using line_profiler for line-by-line measurements&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;line_profilier&lt;/code&gt;: strongest tool for identifying the cause of CPU-bound problems in Python code: profile individual functions on a line-by-line basis&lt;/p&gt;

&lt;p&gt;Be aware of the complexity of &lt;strong&gt;Python’s dynamic machinery&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The order of evaluation for Python statements is both &lt;strong&gt;left to right and opportunistic&lt;/strong&gt;: put the cheapest test on the left side of the equation&lt;/p&gt;

&lt;h2 id=&quot;using-memory_profiler-to-diagnose-memory-usage&quot;&gt;Using memory_profiler to diagnose memory usage&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt; measures memory usage on a line-by-line basis:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Could we use less RAM by rewriting this function to work more efficiently?&lt;/li&gt;
  &lt;li&gt;Could we use more RAM and save CPU cycles by caching?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Memory profiling make your code run 10-100x slower&lt;/li&gt;
  &lt;li&gt;Install &lt;code class=&quot;highlighter-rouge&quot;&gt;psutil&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt; run faster&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt; occasionally and &lt;code class=&quot;highlighter-rouge&quot;&gt;line_profiler&lt;/code&gt; more frequently&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--pdb-mmem=XXX&lt;/code&gt; flag: &lt;code class=&quot;highlighter-rouge&quot;&gt;pdb&lt;/code&gt; debugger is activate after the process exceeds XXX MB -&amp;gt; drop you in directly at the point in your code where too many allocations are occurring&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introspecting-an-existing-process-with-pyspy&quot;&gt;Introspecting an existing process with PySpy&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;py-spy&lt;/code&gt;: sampling profiler, don’t require any code changes -&amp;gt; it introspects an already-running Python process and reports in the console with a &lt;em&gt;top-like&lt;/em&gt; display&lt;/p&gt;

&lt;h1 id=&quot;ch3-lists-and-tuples&quot;&gt;Ch3. Lists and Tuples&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lists&lt;/strong&gt;: dynamic arrays; mutable and allow for resizing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tuples&lt;/strong&gt;: static arrays; immutable and the data within them cannot be changed aftey they have been created&lt;/li&gt;
  &lt;li&gt;Tuples are cached by the Python runtime which means that we don’t need to talk to the kernel to reserve memory every time we want to use one&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Python lists have a built-in sorting algorithm that uses Tim sort -&amp;gt; O(n) in the best case and O(nlogn) in the worst case&lt;/p&gt;

&lt;p&gt;Once sorted, we can find our desired element using a binary search -&amp;gt; average case of complexity of O(logn)&lt;/p&gt;

&lt;p&gt;Dictionary lookup takes only O(1), but:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;converting the data to a dictionary takes O(n)&lt;/li&gt;
  &lt;li&gt;no repeating keys may be undesirable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bisect&lt;/code&gt; module: provide alternative functions, heavily optimized&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“&lt;strong&gt;Pick the right data structure and stick with it!&lt;/strong&gt; Although there may be more efficient data structures for particular operations, the cost of converting to those data structures may negate any efficiency boost”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Tuples are for describing multiple properties of one unchanging thing&lt;/li&gt;
  &lt;li&gt;List can be used to store collections of data about completely disparate objects&lt;/li&gt;
  &lt;li&gt;Both can take mixed types&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Generic code will be much slower than code specifically designed to solve a particular problem”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Tuple (immutable): lightweight data structure&lt;/li&gt;
  &lt;li&gt;List (mutable): extra memory needed to store them and extra computations needed when using them&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch4-dictionaries-and-sets&quot;&gt;Ch4. Dictionaries and Sets&lt;/h1&gt;
&lt;p&gt;Ideal data structures to use when your data has no intrinsic order (except for insertion order), but does have a unique object that can be used to reference it&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;key&lt;/em&gt;: reference object&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;value&lt;/em&gt;: data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sets do not actually contain values: is a collection of unique keys -&amp;gt; useful for doing set operations&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hashable&lt;/strong&gt; type: implements &lt;code class=&quot;highlighter-rouge&quot;&gt;__hash__&lt;/code&gt; and either &lt;code class=&quot;highlighter-rouge&quot;&gt;__eq__&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;__cmp__&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;complexity-and-speed&quot;&gt;Complexity and speed&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;O(1) lookups based on the arbitrary index&lt;/li&gt;
  &lt;li&gt;O(1) insertion time&lt;/li&gt;
  &lt;li&gt;Larger footprint in memory&lt;/li&gt;
  &lt;li&gt;Actual speed depends on the hashing function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-do-dictionaries-and-sets-work&quot;&gt;How do dictionaries and sets work?&lt;/h2&gt;
&lt;p&gt;Use &lt;em&gt;hash tables&lt;/em&gt; to achieve O(1) lookups and insertions -&amp;gt; clever usage of a hash function to turn an arbitrary key (i.e., a string or object) into an index for a list&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;load factor&lt;/em&gt;: how well distributed the data is throughout the hash table -&amp;gt; related to the entropy of the hash function&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hash functions must return integers&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Numerical types (&lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;float&lt;/code&gt;): hash is based on the bit value of the number they represent&lt;/li&gt;
  &lt;li&gt;Tuples and strings: hash value based on their contents&lt;/li&gt;
  &lt;li&gt;Lists: do not support hashing because their values can change&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;A custom-selected hash function should be careful to evenly distribute hash values in order to avoid collisions (will degrade the performance of a hash table) -&amp;gt; constantly “probe” the other values -&amp;gt; worst case O(n) = searching through a list&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Entropy&lt;/strong&gt;: “how well distributed my hash function is” -&amp;gt; max entropy = &lt;em&gt;ideal&lt;/em&gt; hash function = minimal number of collisions&lt;/p&gt;

&lt;h1 id=&quot;ch5-iterators-and-generators&quot;&gt;Ch5. Iterators and Generators&lt;/h1&gt;

&lt;h2 id=&quot;python-for-loop-deconstructed&quot;&gt;Python &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loop deconstructed&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# The Python loop
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;do_work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Is equivalent to
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;object_iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;object_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;StopIteration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;do_work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Changing to generators instead of precomputed arrays may require algorithmic changes (sometimes not so easy to understand)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Many of Python’s built-in functions that operate on sequences are generators themselves. &lt;code class=&quot;highlighter-rouge&quot;&gt;range&lt;/code&gt; returns a generator of values as opposed to the actual list of numbers within the specified range. Similarly, &lt;code class=&quot;highlighter-rouge&quot;&gt;map&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;reversed&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;enumerate&lt;/code&gt; all perform the calculation as needed and don’t store the full result”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Generators have less memory impact than list comprehension&lt;/li&gt;
  &lt;li&gt;Generators are really a way of organizing your code and having smarter loops&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lazy-generator-evaluation&quot;&gt;Lazy generator evaluation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Single pass&lt;/em&gt; or &lt;em&gt;online&lt;/em&gt; algorithms: at any point in our calculation with a generator, we have only the current value and cannot reference any other items in the sequence&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;itertools&lt;/code&gt; from the standard library provides useful functions to make generators easier to use:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;islice&lt;/code&gt;: slicing a potentially infinite generator&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;chain&lt;/code&gt;: chain together multiple generators&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;takewhile&lt;/code&gt;: adds a condition that will end a generator&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cycle&lt;/code&gt;: makes a finite generator infinite by constantly repeating it&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch6-matrix-and-vector-computation&quot;&gt;Ch6. Matrix and Vector Computation&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Understanding the motivation behind your code and the intricacies of the algorithm will give you deeper insight about possible methods of optimization&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;memory-fragmentation&quot;&gt;Memory fragmentation&lt;/h2&gt;
&lt;p&gt;Python doesn’t natively support vectorization&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Python lists store pointers to the actual data -&amp;gt; good because it allows us to store whatever type of data inside a list, however when it comes to vector and matrix operations, this is a source of performance degradation&lt;/li&gt;
  &lt;li&gt;Python bytecode is not optimized for vectorization -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loops cannot predict when using vectorization would be benefical&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;von Neumann bottleneck&lt;/em&gt;: limited bandwidth between memory and CPU as a result of the tiered memory architecture that modern computers use&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;perf&lt;/code&gt; Linux tool: insights into how the CPU is dealing with the program being run&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; object is less suitable for math and more suitable for storing fixed-type data more efficiently in memory&lt;/p&gt;

&lt;h2 id=&quot;numpy&quot;&gt;numpy&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; has all of the features we need—it stores data in contiguous chunks of memory and supports vectorized operations on its data. As a result, any arithmetic we do on &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays happens in chunks without us having to explicitly loop over each element. Not only is it much easier to do matrix arithmetic this way, but it is also faster&lt;/p&gt;

&lt;p&gt;Vectorization from &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt;: may run fewer instructions per cycle, but each instruction does much more work&lt;/p&gt;

&lt;h2 id=&quot;numexpr-making-in-place-operations-faster-and-easier&quot;&gt;numexpr: making in-place operations faster and easier&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt;’s optimization of vector operations: occurs on only one operation at a time&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numexpr&lt;/code&gt; is a module that can take an entire vector expression and compile it into very efficient code that is optimized to minimize cache misses and temporary space used. Expressions can utilize multiple CPU cores&lt;/li&gt;
  &lt;li&gt;Easy to change code to use &lt;code class=&quot;highlighter-rouge&quot;&gt;numexpr&lt;/code&gt;: rewrite the expressions as strings with references to local variables&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lessons-from-matrix-optimizations&quot;&gt;Lessons from matrix optimizations&lt;/h2&gt;
&lt;p&gt;Always take care of any administrative things the code must do during initialization&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;allocating memory&lt;/li&gt;
  &lt;li&gt;reading a configuration from a file&lt;/li&gt;
  &lt;li&gt;precomputing values that will be needed throughout the lifetime of a program&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pandas&quot;&gt;Pandas&lt;/h2&gt;
&lt;h3 id=&quot;pandass-internal-model&quot;&gt;Pandas’s internal model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Operations on columns often generate temporary intermediate arrays which consume RAM: expect a temporary memory usage of up to 3-5x your current usage&lt;/li&gt;
  &lt;li&gt;Operations can be single-threaded and limited by Python’s global interpreter lock (GIL)&lt;/li&gt;
  &lt;li&gt;Columns of the same &lt;code class=&quot;highlighter-rouge&quot;&gt;dtype&lt;/code&gt; are grouped together by a &lt;code class=&quot;highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt; -&amp;gt; make row-wise operations on columns of the same datatype faster&lt;/li&gt;
  &lt;li&gt;Operations on data of a single common block -&amp;gt; &lt;em&gt;view&lt;/em&gt;; different &lt;code class=&quot;highlighter-rouge&quot;&gt;dtypes&lt;/code&gt; -&amp;gt; can cause a &lt;em&gt;copy&lt;/em&gt; (slower)&lt;/li&gt;
  &lt;li&gt;Pandas uses a mix of NumPy datatypes and its own extension datatypes&lt;/li&gt;
  &lt;li&gt;numpy &lt;code class=&quot;highlighter-rouge&quot;&gt;int64&lt;/code&gt; isn’t NaN aware -&amp;gt; Pandas &lt;code class=&quot;highlighter-rouge&quot;&gt;Int64&lt;/code&gt; uses two columns of data: integers and NaN bit mask&lt;/li&gt;
  &lt;li&gt;numpy &lt;code class=&quot;highlighter-rouge&quot;&gt;bool&lt;/code&gt; isn’t NaN aware -&amp;gt; Pandas &lt;code class=&quot;highlighter-rouge&quot;&gt;boolean&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;More safety makes things run slower (checking passing appropriate data) -&amp;gt; &lt;strong&gt;Developer time (and sanity) x Execution time&lt;/strong&gt;. Checks enabled: avoid painful debugging sessions, which kill developer productivity. If we know that our data is of the correct form for our chosen algorithm, these checks will add a penalty&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;building-dataframes-and-series-from-partial-results-rather-than-concatenating&quot;&gt;Building DataFrames and Series from partial results rather than concatenating&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Avoid repeated calls to &lt;code class=&quot;highlighter-rouge&quot;&gt;concat&lt;/code&gt; in Pandas (and to the equivalent &lt;code class=&quot;highlighter-rouge&quot;&gt;concatenate&lt;/code&gt; in NumPy)&lt;/li&gt;
  &lt;li&gt;Build lists of intermediate results and then construct a Series or DataFrame from this list, rather than concatenating to an existing object&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advice-for-effective-pandas-development&quot;&gt;Advice for effective pandas development&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Install the optional dependencies &lt;code class=&quot;highlighter-rouge&quot;&gt;numexpr&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;bottleneck&lt;/code&gt; for additional performance improvements&lt;/li&gt;
  &lt;li&gt;Caution against chaining too many rows of pandas operations in sequence: difficult to debug, chain only a couple of operations together to simplify your maintenance&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Filter your data before calculating&lt;/strong&gt; on the remaining rows rather than filtering after calculating&lt;/li&gt;
  &lt;li&gt;Check the schema of your DataFrames as they evolve -&amp;gt; tool like &lt;code class=&quot;highlighter-rouge&quot;&gt;bulwark&lt;/code&gt;, you can visualize confirm that your expectations are being met&lt;/li&gt;
  &lt;li&gt;Large Series with low cardinality: &lt;code class=&quot;highlighter-rouge&quot;&gt;df['series_of_strings'].astype('category')&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;value_counts&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;groupby&lt;/code&gt; run faster and the Series consume less RAM&lt;/li&gt;
  &lt;li&gt;Convert 8-byte &lt;code class=&quot;highlighter-rouge&quot;&gt;float64&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;int64&lt;/code&gt; to smaller datatypes -&amp;gt; 2-byte &lt;code class=&quot;highlighter-rouge&quot;&gt;float16&lt;/code&gt; or 1-byte &lt;code class=&quot;highlighter-rouge&quot;&gt;int8&lt;/code&gt; -&amp;gt; smaller range to further save RAM&lt;/li&gt;
  &lt;li&gt;Use the &lt;code class=&quot;highlighter-rouge&quot;&gt;del&lt;/code&gt; keyword to delete earlier references and clear them from memory&lt;/li&gt;
  &lt;li&gt;Pandas &lt;code class=&quot;highlighter-rouge&quot;&gt;drop&lt;/code&gt; method to delete unused columns&lt;/li&gt;
  &lt;li&gt;Persist the prepared DataFrame version to disk by using &lt;code class=&quot;highlighter-rouge&quot;&gt;to_pickle&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Avoid &lt;code class=&quot;highlighter-rouge&quot;&gt;inplace=True&lt;/code&gt; -&amp;gt; are scheduled to be removed from the library over time&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Modin&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;cuDF&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Vaex&lt;/code&gt;: work on very large datasets that exceed RAM by using lazy evaluation while retaining a similar interface to Pandas -&amp;gt; large datasets and string-heavy operations&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch7-compiling-to-c&quot;&gt;Ch7. Compiling to C&lt;/h1&gt;
&lt;p&gt;To make code run faster:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Make it do less work&lt;/li&gt;
  &lt;li&gt;Choose good algorithms&lt;/li&gt;
  &lt;li&gt;Reduce the amount of data you’re processing&lt;/li&gt;
  &lt;li&gt;Execute fewer instructions -&amp;gt; compile your code down to machine code&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;python-offers&quot;&gt;Python offers&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt;: pure C-based compiling&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Numba&lt;/code&gt;: LLVM-based compiling&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PyPy&lt;/code&gt;: replacement virtual machine which includes a built-in just-in-time (JIT) compiler&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-sort-of-speed-gains-are-possible&quot;&gt;What sort of speed gains are possible?&lt;/h2&gt;
&lt;p&gt;Compiling generate more gains when the code:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;is mathematical&lt;/li&gt;
  &lt;li&gt;has lots of loops that repeat the same operations many times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unlikely to show speed up:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;calls to external libraries (regexp, string operations, calls to database)&lt;/li&gt;
  &lt;li&gt;programs that are I/O-bound&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;jit-versus-aot-compilers&quot;&gt;JIT versus AOT compilers&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;AOT (ahead of time)&lt;/strong&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt; -&amp;gt; you’ll have a library that can instantly be used -&amp;gt; best speedups, but requires the most manual effort&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;JIT (just in time)&lt;/strong&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;Numba&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;PyPy&lt;/code&gt; -&amp;gt; you don’t have to do much work up front, but you have a “cold start” problem -&amp;gt; impressive speedups with little manual intervention&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-does-type-information-help-the-code-run-faster&quot;&gt;Why does type information help the code run faster?&lt;/h2&gt;
&lt;p&gt;Python is dynamically typed -&amp;gt; keeping the code generic makes it run more slowly&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Inside a section of code that is CPU-bound, it is often the case that the types of variables do not change. This gives us an opportunity for &lt;strong&gt;static compilation and faster code execution&lt;/strong&gt;”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;using-a-c-compiler&quot;&gt;Using a C compiler&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt; uses &lt;code class=&quot;highlighter-rouge&quot;&gt;gcc&lt;/code&gt;: good choice for most platforms; well supported and quite advanced&lt;/p&gt;

&lt;h2 id=&quot;cython&quot;&gt;Cython&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Compiler that converts type-annotaded (C-like) Python into a compiled extension module&lt;/li&gt;
  &lt;li&gt;Wide used and mature&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OpenMP&lt;/code&gt; support: possible to convert parallel problems into multiprocessing-aware modules&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyximport&lt;/code&gt;: simplified build system&lt;/li&gt;
  &lt;li&gt;Annotation option that output an HTML file -&amp;gt; more yellow = more calls into the Python virtual machine; more white = more non-Python C code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lines that cost the most CPU time:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;inside tight inner loops&lt;/li&gt;
  &lt;li&gt;dereferencing &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;np.array&lt;/code&gt; items&lt;/li&gt;
  &lt;li&gt;mathematical operations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cdef&lt;/code&gt; keyword: declare variables inside the function body. These must be declared at the top of the function, as that’s a requirement from the C language specification&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Strength reduction&lt;/strong&gt;: writing equivalent but more specialized code to solve the same problem. Trade worse flexibility (and possibly worse readability) for faster execution&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;memoryview&lt;/code&gt;: allows the same low-level access to any object that implements the buffer interface, including &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays and Python arrays&lt;/p&gt;

&lt;h2 id=&quot;numba&quot;&gt;Numba&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;JIT compiler that specializes in &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; code, which it compiles via LLVM compiler at runtime&lt;/li&gt;
  &lt;li&gt;You provide a decorator telling it which functions to focus on and then you let Numba take over&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays and nonvectorized code that iterates over many items: Numba should give you a quick and very painless win.&lt;/li&gt;
  &lt;li&gt;Numba does not bind to external C libraries (which Cython can do), but it can automatically generate code for GPUs (which Cython cannot).&lt;/li&gt;
  &lt;li&gt;OpenMP parallelization support with &lt;code class=&quot;highlighter-rouge&quot;&gt;prange&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Break your code into small (&amp;lt;10 line) and discrete functions and tackle these one at a time&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from numba import jit

@jit()
def my_fn():
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;pypy&quot;&gt;PyPy&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Alternative implementation of the Python language that includes a tracing just-in-time compiler&lt;/li&gt;
  &lt;li&gt;Offers a faster experience than CPython&lt;/li&gt;
  &lt;li&gt;Uses a different type of garbage collector (modified mark-and-sweep) than CPython (reference counting) = may clean up an unused object much later&lt;/li&gt;
  &lt;li&gt;PyPy can use a lot of RAM&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;vmprof&lt;/code&gt;: lightweight sampling profiler&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;when-to-use-each-technology&quot;&gt;When to use each technology&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;./compiler_options.png&quot; alt=&quot;compiler_options&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Numba&lt;/code&gt;: quick wins for little effort; young project&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cython&lt;/code&gt;: best results for the widest set of prolbmes; requires more effort; mix Python and C annotations&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PyPy&lt;/code&gt;: strong option if you’re not using &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; or other hard-to-port C extensions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other-upcoming-projects&quot;&gt;Other upcoming projects&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Pythran&lt;/li&gt;
  &lt;li&gt;Transonic&lt;/li&gt;
  &lt;li&gt;ShedSkin&lt;/li&gt;
  &lt;li&gt;PyCUDA&lt;/li&gt;
  &lt;li&gt;PyOpenCL&lt;/li&gt;
  &lt;li&gt;Nuitka&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;graphics-processing-units-gpus&quot;&gt;Graphics Processing Units (GPUs)&lt;/h2&gt;
&lt;p&gt;Easy-to-use GPU mathematics libraries:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;TensorFlow&lt;/li&gt;
  &lt;li&gt;PyTorch&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dynamic-graphs-pytorch&quot;&gt;Dynamic graphs: PyTorch&lt;/h3&gt;
&lt;p&gt;Static computational graph tensor library that is particularly user-friendly and has a very intuitive API for anyone familiar with &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Static computational graph&lt;/em&gt;: performing operations on &lt;code class=&quot;highlighter-rouge&quot;&gt;PyTorch&lt;/code&gt; objects creates a dynamic definition of a program that gets compiled to GPU code in the background when it is executed -&amp;gt; changes to the Python code automatically get reflected in changes in the GPU code without an explicit compilation step needed&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;basic-gpu-profiling&quot;&gt;Basic GPU profiling&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nvidia-smi&lt;/code&gt;: inspect the resource utilization of the GPU&lt;/li&gt;
  &lt;li&gt;Power usage is a good proxy for judging how much of the GPU’s compute power is being used -&amp;gt; more power the GPU is drawing = more compute it is currently doing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;when-to-use-gpus&quot;&gt;When to use GPUs&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Task requires mainly linear algebra and matrix manipulations (multiplication, addition, Fourier transforms)&lt;/li&gt;
  &lt;li&gt;Particularly true if the calculation can happen on the GPU uninterrupted for a period of time before being copied back into system memory&lt;/li&gt;
  &lt;li&gt;GPU can run many more tasks at once than the CPU can, but each of those tasks run more slowly on the GPU than on the CPU&lt;/li&gt;
  &lt;li&gt;Not a good tool for tasks that require exceedingly large amounts of data, many conditional manipulations of the data, or changing data&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Ensure that the memory use of the problem will fit withing the GPU&lt;/li&gt;
  &lt;li&gt;Evaluate whether the algorithm requires a lot of branching conditions versus vectorized operations&lt;/li&gt;
  &lt;li&gt;Evaluate how much data needs to be moved between the GPU and the CPU&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;ch8-asynchronous-io&quot;&gt;Ch8. Asynchronous I/O&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;I/O bound program&lt;/em&gt;: the speed is bounded by the efficiency of the input/output&lt;/p&gt;

&lt;p&gt;Asynchronous I/O helps utilize the wasted &lt;em&gt;I/O wait&lt;/em&gt; time by allowing us to perform other operations while we are in that state&lt;/p&gt;

&lt;h2 id=&quot;introduction-to-asynchronous-programming&quot;&gt;Introduction to asynchronous programming&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Context switch&lt;/em&gt;: when a program enters I/O wait, the execution is paused so that the kernel can perform the low-level operations associated with the I/O request&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Callback paradigm&lt;/strong&gt;: functions are called with an argument that is generally called the callback -&amp;gt; instead of the function returing its value, it call the callback function with the value instead -&amp;gt; long chains = “callback hell”&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Future paradigm&lt;/strong&gt;: an asynchronous function returns a &lt;code class=&quot;highlighter-rouge&quot;&gt;Future&lt;/code&gt; object, which is a promise of a future result&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;asyncio&lt;/code&gt; standard library module and PEP 492 made the future’s mechanism native to Python&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-does-asyncawait-work&quot;&gt;How does async/await work?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;async&lt;/code&gt; function (defined with &lt;code class=&quot;highlighter-rouge&quot;&gt;async def&lt;/code&gt;) is called a &lt;em&gt;coroutine&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Coroutines are implemented with the same philosophies as generators&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt; is similar in function to a &lt;code class=&quot;highlighter-rouge&quot;&gt;yield&lt;/code&gt; -&amp;gt; the execution of the current function gets paused while other code is run&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gevent&quot;&gt;Gevent&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Patches the standard library with asynchronous I/O functions,&lt;/li&gt;
  &lt;li&gt;Has a &lt;code class=&quot;highlighter-rouge&quot;&gt;Greenlets&lt;/code&gt; object that can be used for concurrent execution&lt;/li&gt;
  &lt;li&gt;Ideal solution for mainly CPU-based problems that sometimes involve heavy I/O&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tornado&quot;&gt;tornado&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Frequently used package for asynchronous I/O in Python&lt;/li&gt;
  &lt;li&gt;Originally developed by Facebook primarily for HTTP clients and servers&lt;/li&gt;
  &lt;li&gt;Ideal for any application that is mostly I/O-bound and where most of the application should be asynchronous&lt;/li&gt;
  &lt;li&gt;Performant web server&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aiohttp&quot;&gt;aiohttp&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Built entirely on the &lt;code class=&quot;highlighter-rouge&quot;&gt;asyncio&lt;/code&gt; library&lt;/li&gt;
  &lt;li&gt;Provides both HTTP client and server functionality&lt;/li&gt;
  &lt;li&gt;Uses a similar API to &lt;code class=&quot;highlighter-rouge&quot;&gt;tornado&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;batched-results&quot;&gt;Batched results&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Pipelining&lt;/em&gt;: batching results -&amp;gt; can help lower the burden of an I/O task&lt;/li&gt;
  &lt;li&gt;Good compromise between the speeds of asynchronous I/O and the ease of writing serial programs&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch9-the-multiprocessing-module&quot;&gt;Ch9. The multiprocessing module&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Additional process = more communication overhead = decrease available RAM -&amp;gt; rarely get a full &lt;em&gt;n&lt;/em&gt;-times speedup&lt;/li&gt;
  &lt;li&gt;If you run out of RAM and the system reverts to using the disk’s swap space, any parallelization advantage will be massively lost to the slow paging of RAM back and forth to disk&lt;/li&gt;
  &lt;li&gt;Using hyperthreads: CPython uses a lot of RAM -&amp;gt; hyperthreading is not cache friendly. Hyperthreads = added bonus and not a resource to be optimized against -&amp;gt; adding more CPUs is more economical than tuning your code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Amdahl’s law&lt;/strong&gt;: if only a small part of your code can be parallelized, it doesn’t matter how many CPUs you throw at it; it still won’t run much faster overall&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt; module: process and thread-based parallel processing, share work over queues, and share data among processes -&amp;gt; focus: single-machine multicore parallelism&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt;: higher level, sharing Python data structures&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OpenMP&lt;/code&gt;: works with C primitive objects once you’ve compiled to C&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Keep the parallelism as simple as possible so that your development velocity is kept high&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Embarrassingly parallel&lt;/em&gt;: multiple Python processes all solving the same problem without communicating with one another -&amp;gt; not much penalty will be incurred as we add more and more Python processes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Typical jobs for the &lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt; module:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Parallelize a CPU-bound task with &lt;code class=&quot;highlighter-rouge&quot;&gt;Process&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool&lt;/code&gt; objects&lt;/li&gt;
  &lt;li&gt;Parallelize an I/O-bound task in a &lt;code class=&quot;highlighter-rouge&quot;&gt;Pool&lt;/code&gt; with threads using the &lt;code class=&quot;highlighter-rouge&quot;&gt;dummy&lt;/code&gt; module&lt;/li&gt;
  &lt;li&gt;Share pickled work via a &lt;code class=&quot;highlighter-rouge&quot;&gt;Queue&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Share state between parallelized workers, including bytes, primitive datatypes, dictionaries, and lists&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Joblib&lt;/code&gt;: stronger cross-platform support than &lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;replacing-multiprocessing-with-joblib&quot;&gt;Replacing multiprocessing with Joblib&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Joblib&lt;/code&gt; is an improvement on &lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Enables lightweight pipelining with a focus on:
    &lt;ul&gt;
      &lt;li&gt;easy parallel computing&lt;/li&gt;
      &lt;li&gt;transparent disk-based caching of results&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;It focuses on NumPy arrays for scientific computing&lt;/li&gt;
  &lt;li&gt;Quick wins:
    &lt;ul&gt;
      &lt;li&gt;process a loop that could be embarrassingly parallel&lt;/li&gt;
      &lt;li&gt;expensive functions that have no side effect&lt;/li&gt;
      &lt;li&gt;able to share &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; data between processes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Parallel&lt;/code&gt; class: sets up the process pool&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;delayed&lt;/code&gt; decorator: wraps our target function so it can be applied to the instantiated &lt;code class=&quot;highlighter-rouge&quot;&gt;Parallel&lt;/code&gt; object via an iterator&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intelligent-caching-of-function-call-results&quot;&gt;Intelligent caching of function call results&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Memory&lt;/code&gt; cache: decorator that caches functions results based on the input arguments to a disk cache&lt;/p&gt;

&lt;h3 id=&quot;using-numpy&quot;&gt;Using numpy&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; is more cache friendly&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; can achieve some level of additional speedup around threads by working outside the GIL&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;asynchronous-systems&quot;&gt;Asynchronous systems&lt;/h2&gt;
&lt;p&gt;Require a special level of patience. Suggestions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;K.I.S.S.&lt;/li&gt;
  &lt;li&gt;Avoiding asynchronous self-contained systems if possible, as they will grow in complexity and quickly become hard to maintain&lt;/li&gt;
  &lt;li&gt;Using mature libraries like &lt;code class=&quot;highlighter-rouge&quot;&gt;gevent&lt;/code&gt; that give you tried-and-tested approaches to dealing with certain problem sets&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;interprocess-communication-ipc&quot;&gt;Interprocess Communication (IPC)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Cooperation cost can be high: synchronizing data and checking the shared data&lt;/li&gt;
  &lt;li&gt;Sharing state tends to make things complicated&lt;/li&gt;
  &lt;li&gt;IPC is fairly easy but generally comes with a cost&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiprocessingmanager&quot;&gt;multiprocessing.Manager()&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Lets us share higher-level Python objects between processes as managed shared objects; the lower-level objects are wrapped in proxy objects&lt;/li&gt;
  &lt;li&gt;The wrapping and safety have a speed cost but also offer great flexibility.&lt;/li&gt;
  &lt;li&gt;You can share both lower-level objects (e.g., integers and floats) and lists and dictionaries.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;redis&quot;&gt;Redis&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Key/value in-memory storage engine&lt;/strong&gt;. It provides its own locking and each operation is atomic, so we don’t have to worry about using locks from inside Python (or from any other interfacing language).&lt;/li&gt;
  &lt;li&gt;Lets you share state not just with other Python processes but also other tools and other machines, and even to expose that state over a web-browser interface&lt;/li&gt;
  &lt;li&gt;Redis lets you store: Lists of strings; Sets of strings; Sorted sets of strings; Hashes of strings&lt;/li&gt;
  &lt;li&gt;Stores everything in RAM and snapshots to disk&lt;/li&gt;
  &lt;li&gt;Supports master/slave replication to a cluster of instances&lt;/li&gt;
  &lt;li&gt;Widely used in industry and is mature and well trusted&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mmap&quot;&gt;mmap&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Memory-mapped (shared memory) solution&lt;/li&gt;
  &lt;li&gt;The bytes in a shared memory block are not synchronized and they come with very little overhead&lt;/li&gt;
  &lt;li&gt;Bytes act like a file -&amp;gt; block of memory with a file-like interface&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch10-clusters-and-job-queues&quot;&gt;Ch10. Clusters and Job Queues&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Cluster&lt;/em&gt;: collection of computers working together to solve a common task&lt;/p&gt;

&lt;p&gt;Before moving to a clustered solution:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Profile your system to understand the bottlenecks&lt;/li&gt;
  &lt;li&gt;Exploit compile solutions (Numba, Cython)&lt;/li&gt;
  &lt;li&gt;Exploit multiple cores on a single machine (Joblib, multiprocessing)&lt;/li&gt;
  &lt;li&gt;Exploit techniques for using less RAM&lt;/li&gt;
  &lt;li&gt;Really need a lot of CPUs, high resiliency, rapid speed of response, ability to process data from disks in parallel&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;benefits-of-clustering&quot;&gt;Benefits of clustering&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Easily scale computing requirements&lt;/li&gt;
  &lt;li&gt;Improve reliability&lt;/li&gt;
  &lt;li&gt;Dynamic scaling&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;drawbacks-of-clustering&quot;&gt;Drawbacks of clustering&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Change in thinking&lt;/li&gt;
  &lt;li&gt;Latency between machines&lt;/li&gt;
  &lt;li&gt;Sysadmin problems: software versions between machines, are other machines working?&lt;/li&gt;
  &lt;li&gt;Moving parts that need to be in sync&lt;/li&gt;
  &lt;li&gt;“If you don’t have a documented restart plan, you should assume you’ll have to write one at the worst possible time”&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Using a cloud-based cluster can mitigate a lot of these problems, and some cloud providers also offer a spot-priced market for cheap but temporary computing resources.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;A system that’s easy to debug &lt;em&gt;probably&lt;/em&gt; beats having a faster system&lt;/li&gt;
  &lt;li&gt;Engineering time and the cost of downtime are &lt;em&gt;probably&lt;/em&gt; your largest expenses&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parallel-pandas-with-dask&quot;&gt;Parallel Pandas with Dask&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Provide a suite of parallelization solutions that scales from a single core on a laptop to multicore machines to thousands of cores in a cluster.&lt;/li&gt;
  &lt;li&gt;“Apache Spark lite”&lt;/li&gt;
  &lt;li&gt;For &lt;code class=&quot;highlighter-rouge&quot;&gt;Pandas&lt;/code&gt; users: larger-than-RAM datasets and desire for multicore parallelization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dask&quot;&gt;Dask&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Bag&lt;/em&gt;: enables parallelized computation on unstructured and semistructured data&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Array&lt;/em&gt;: enables distributed and larger-than-RAM &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; operations&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Distributed DataFrame&lt;/em&gt;: enables distributed and larger-than-RAM &lt;code class=&quot;highlighter-rouge&quot;&gt;Pandas&lt;/code&gt; operations&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Delayed&lt;/em&gt;: parallelize chains of arbitrary Python functions in a lazy fashion&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Futures&lt;/em&gt;: interface that includes &lt;code class=&quot;highlighter-rouge&quot;&gt;Queue&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Lock&lt;/code&gt; to support task collaboration&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Dask-ML&lt;/em&gt;: scikit-learn-like interface for scalable machine learning&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;You can use Dask (and Swifter) to parallelize any side-effect-free function that you’d usually use in an &lt;code class=&quot;highlighter-rouge&quot;&gt;apply&lt;/code&gt; call&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;npartitions&lt;/code&gt; = # cores&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;swifter&quot;&gt;Swifter&lt;/h4&gt;
&lt;p&gt;Builds on Dask to provide three parallelized options with very simple calls: &lt;code class=&quot;highlighter-rouge&quot;&gt;apply&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;resample&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;rolling&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;vaex&quot;&gt;Vaex&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;String-heavy DataFrames&lt;/li&gt;
  &lt;li&gt;Larger-than-RAM datasets&lt;/li&gt;
  &lt;li&gt;Subsets of a DataFrame -&amp;gt; Implicit lazy evaluation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;nsq-for-robust-production-clustering&quot;&gt;NSQ for robust production clustering&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Highly performant distributed messaging platform&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Queues&lt;/em&gt;: type of buffer for messages&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Pub/subs&lt;/em&gt;: describes who gets what messages (&lt;em&gt;publisher/subscriber&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch11-using-less-ram&quot;&gt;Ch11. Using less RAM&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Counting the amount of RAM used by Python object is tricky -&amp;gt; if we ask the OS for a count of bytes used, it will tell us the total amount allocated to the process&lt;/li&gt;
  &lt;li&gt;Each unique object has a memory cost&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;objects-for-primitives-are-expensive&quot;&gt;Objects for primitives are expensive&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%load_ext memory_profiler

%memit &amp;lt;operation&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;the-array-module-stores-many-primitive-objects-cheaply&quot;&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; module stores many primitive objects cheaply&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Creates a contiguos block of RAM to hold the underlying data. Which data structures:
    &lt;ul&gt;
      &lt;li&gt;integers, floats and characters&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;not&lt;/em&gt; complex numbers or classes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Good to pass the array to an external process or use only some of the data (not to compute on them)&lt;/li&gt;
  &lt;li&gt;Using a regular &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; to store many numbers is much less efficient in RAM than using an &lt;code class=&quot;highlighter-rouge&quot;&gt;array&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays are almost certainly a better choice if you are doing anything heavily numeric:
    &lt;ul&gt;
      &lt;li&gt;more datatype options&lt;/li&gt;
      &lt;li&gt;many specialized and fast functions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;using-less-ram-in-numpy-with-numexpr&quot;&gt;Using less RAM in NumPy with NumExpr&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NumExpr&lt;/code&gt; is a tool that both speeds up and reduces the size of intermediate operations&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Install the optional NumExpr when using Pandas (Pandas does not tell you if you haven’t installed NumExpr) -&amp;gt; calls to &lt;code class=&quot;highlighter-rouge&quot;&gt;eval&lt;/code&gt; will run more quickly -&amp;gt; import numpexpr: if this fails, install it!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;NumExpr breaks the long vectors into shorter, cache-friendly chunks and processes each in series, so local chunks of results are calculated in a cache-friendly way&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bytes-versus-unicode&quot;&gt;Bytes versus Unicode&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Python 3.x, all strings are Unicode by default, and if you want to deal in bytes, you’ll explicitly create a &lt;code class=&quot;highlighter-rouge&quot;&gt;byte&lt;/code&gt; sequence&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UTF-8 encoding&lt;/strong&gt; of a Unicode object uses 1 byte per ASCII character and more bytes for less frequently seen characters&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;more-efficient-tree-structures-to-represent-strings&quot;&gt;More efficient tree structures to represent strings&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tries&lt;/strong&gt;: share common prefixes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DAWG&lt;/strong&gt;: share common prefixes and suffixes&lt;/li&gt;
  &lt;li&gt;Overlapping sequences in your strings -&amp;gt; you’ll likely see a RAM improvement&lt;/li&gt;
  &lt;li&gt;Save RAM and time in exchange for a little additional effort in preparation&lt;/li&gt;
  &lt;li&gt;Unfamiliar data structures to many developers -&amp;gt; isolate in a module to simplify maintenance&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;directed-acyclic-word-graph-dawg&quot;&gt;Directed Acyclic Word Graph (DAWG)&lt;/h3&gt;
&lt;p&gt;Attemps to efficiently represent strings that share common prefixes and suffixes&lt;/p&gt;

&lt;h3 id=&quot;marisa-trie&quot;&gt;Marisa Trie&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Static trie&lt;/em&gt; using Cython bindings to an external library -&amp;gt; it cannot be modified after construction&lt;/p&gt;

&lt;h2 id=&quot;scikit-learns-dictvectorizer-and-featurehasher&quot;&gt;Scikit-learn’s DictVectorizer and FeatureHasher&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DictVectorizer&lt;/code&gt;: takes a dictionary of terms and their frequences and converts them into a variable-width sparse matrix -&amp;gt; it is possible to revert the process&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;FeatureHasher&lt;/code&gt;: converts the same dictionary of terms and frequencies into a fixed-width sparse matrix -&amp;gt; it doesn’t store a vocabulary and instead employs a hashing algorithm to assign token frequencies to columns -&amp;gt; can’t convert it back to the original token from hash&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scypys-sparse-matrices&quot;&gt;ScyPy’s Sparse Matrices&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Matrix in which most matrix elements are 0&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;C00&lt;/code&gt; matrices: simplest implementation: each non-zero element we store the value in addition to the location of the value -&amp;gt; each non-zero value = 3 numbers stored -&amp;gt; used only to contruct sparse matrices and not for actual computation&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CSR/CSC&lt;/code&gt; is preferred for computation&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Push and pull of speedups with sparse arrays: balance between losing the use of efficient caching and vectorization versus not having to do a lot of the calculations associated with the zero values of the matrix&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Limitations:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Low amount of support&lt;/li&gt;
  &lt;li&gt;Multiple implementations with benefits and drawbacks&lt;/li&gt;
  &lt;li&gt;May require expert knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tips-for-using-less-ram&quot;&gt;Tips for using less RAM&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;“If you can avoid putting it into RAM, do. Everything you load costs you RAM”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Numeric data: switch to using &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; arrays&lt;/li&gt;
  &lt;li&gt;Very sparse arrays: SciPy’s sparse array functionality&lt;/li&gt;
  &lt;li&gt;Strings: stick to &lt;code class=&quot;highlighter-rouge&quot;&gt;str&lt;/code&gt; rather than &lt;code class=&quot;highlighter-rouge&quot;&gt;bytes&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Many Unicode objects in a static structure: DAWG and trie structures&lt;/li&gt;
  &lt;li&gt;Lots of bit strings: &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;bitarray&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;probabilistic-data-structures&quot;&gt;Probabilistic Data Structures&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Make trade-offs in accuracy for immense decrease in memory usage&lt;/li&gt;
  &lt;li&gt;The number of operations you can do on them is much more restricted&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Probabilistic data structures are fantastic when you have taken the time to understand the problem and need to put something into production that can answer a very small set of questions about a very large set of data”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;“lossy compression”: find an alternative representation for the data that is more compact and contains the relevant information for answering a certain set of questions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;morris-counter&quot;&gt;Morris counter&lt;/h3&gt;
&lt;p&gt;Keeps track of an exponent and models the counted state as &lt;code class=&quot;highlighter-rouge&quot;&gt;2^exponent&lt;/code&gt; -&amp;gt; provides an &lt;em&gt;order of magnitude&lt;/em&gt; estimate&lt;/p&gt;

&lt;h3 id=&quot;k-minimum-values&quot;&gt;K-Minimum values&lt;/h3&gt;
&lt;p&gt;If we keep the &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt; smallest unique hash values we have seen, we can &lt;strong&gt;approximate the overall spacing between hash values&lt;/strong&gt; and infer the total number of items&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;idempotence&lt;/em&gt;: if we do the same operation, with the same inputs, on the structure multiple times, the state will not be changed&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bloom-filters&quot;&gt;Bloom filters&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Answer the question of &lt;strong&gt;whether we’ve seen an item before&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Work by having multiple hash values in order to represent a value as multiple integers. If we later see something with the same set of integers, we can be reasonably confident that it is the same value&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No false negatives and a controllable rate of false positives&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Set to have error rates below 0.5%&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch12-lessons-from-the-field&quot;&gt;Ch12. Lessons from the field&lt;/h1&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/high_performance_python/high_performance_python.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/high_performance_python/high_performance_python.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Machine Learning: tests and production</title><link href="https://millengustavo.github.io/blog/tests/machine%20learning/data%20science/deploy/2020/06/01/ml-test-production.html" rel="alternate" type="text/html" title="Machine Learning: tests and production" /><published>2020-06-01T00:00:00-05:00</published><updated>2020-06-01T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/tests/machine%20learning/data%20science/deploy/2020/06/01/ml-test-production</id><content type="html" xml:base="https://millengustavo.github.io/blog/tests/machine%20learning/data%20science/deploy/2020/06/01/ml-test-production.html">&lt;blockquote&gt;
  &lt;p&gt;“Creating reliable, production-level machine learning systems brings on a host of concerns not found in small toy examples or even large offline research experiments. Testing and monitoring are key considerations for ensuring the production-readiness of an ML system, and for reducing technical debt of ML systems.” - &lt;a href=&quot;https://research.google/pubs/pub46555/&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I recently read the excellent book written by Emmanuel Ameisen: &lt;a href=&quot;http://shop.oreilly.com/product/0636920215912.do&quot;&gt;Building Machine Learning Powered Applications Going from Idea to Product&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I definitely recommend the book to people involved at any stage in the process of developing and implementing products that use Machine Learning.&lt;/p&gt;

&lt;h1 id=&quot;the-ml-test-score-a-rubric-for-ml-production-readiness-and-technical-debt-reduction&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/h1&gt;
&lt;p&gt;A good reference I found in chapter 6 of the book entitled: Debug your ML problems, was the article written by Google engineers: &lt;a href=&quot;https://research.google/pubs/pub46555/&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the article, the authors:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“(…) present 28 specific tests and monitoring needs, drawn from experience with a wide range of production ML systems to help quantify these issues and present an easy to follow road-map to improve production readiness and pay down ML technical debt.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a good practice presented by Ameisen in his book when referring to reproducing successful results from the past: &lt;strong&gt;“Stand on the shoulders of giants”&lt;/strong&gt;, I believe that we can learn from Google’s experience in building applications using Machine Learning.&lt;/p&gt;

&lt;h2 id=&quot;manually-coded-systems-vs-ml-based-systems&quot;&gt;Manually coded systems vs. ML-based systems&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/systems_comparison.PNG&quot; alt=&quot;systems_comparison&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Unlike manually coded systems, the behavior of machine learning systems depends on data and models that are not always possible to specify fully a priori&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“(…) training data needs testing like code, and a trained ML model needs production practices like a binary does, such as debuggability, rollbacks and monitoring”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;tests&quot;&gt;Tests&lt;/h2&gt;
&lt;h3 id=&quot;data&quot;&gt;Data&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/data.PNG&quot; alt=&quot;data&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;model&quot;&gt;Model&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/model.PNG&quot; alt=&quot;model&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;infrastructure&quot;&gt;Infrastructure&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/infra.PNG&quot; alt=&quot;infra&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/monitor.PNG&quot; alt=&quot;monitor&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;computing-an-ml-test-score&quot;&gt;Computing an ML Test Score&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://millengustavo.github.io/blog/images/ml_test_production/score.PNG&quot; alt=&quot;score&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;insights-from-applying-the-rubric-to-real-systems&quot;&gt;Insights from applying the rubric to real systems&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Checklists&lt;/strong&gt; are helpful even for expert teams&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data dependencies&lt;/strong&gt; can lead to outsourcing responsibility for fully understanding it&lt;/li&gt;
  &lt;li&gt;The importance of &lt;strong&gt;frameworks&lt;/strong&gt;: pipeline platforms may allow building generic integration tests&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Deploying a machine learning system with monitoring is a very complex task. This is a problem faced by virtually all players in the market who are starting their journey with data.&lt;/p&gt;

&lt;p&gt;A good first step on this journey is to organize your data pipeline and use managed environments in the cloud for the ML tasks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Amazon SageMaker&lt;/li&gt;
  &lt;li&gt;Google Cloud AI Platform&lt;/li&gt;
  &lt;li&gt;Azure Machine Learning Studio&lt;/li&gt;
  &lt;li&gt;Databricks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even if we do not face the scale of some problems mentioned in the article, it is worth reflecting on how we can improve what we do today to reduce technical debt in the future.&lt;/p&gt;

&lt;h1 id=&quot;further-reading&quot;&gt;Further reading&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://research.google/pubs/pub46555/&quot;&gt;The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://shop.oreilly.com/product/0636920215912.do&quot;&gt;Building Machine Learning Powered Applications Going from Idea to Product - Emmanuel Ameisen&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mlinproduction.com/&quot;&gt;ML in Production blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://speakerdeck.com/trallard/what-is-your-ml-test-score&quot;&gt;What is your machine learning test score?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/mlflow/mlflow&quot;&gt;MLflow: A Machine Learning Lifecycle Platform&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/solutions/machine-learning&quot;&gt;Databricks for Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">“Creating reliable, production-level machine learning systems brings on a host of concerns not found in small toy examples or even large offline research experiments. Testing and monitoring are key considerations for ensuring the production-readiness of an ML system, and for reducing technical debt of ML systems.” - The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/ml_test_production/systems_comparison.PNG" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/ml_test_production/systems_comparison.PNG" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Building Machine Learning Powered Applications: Going from Idea to Product</title><link href="https://millengustavo.github.io/blog/book/machine%20learning/data%20science/deploy/2020/05/22/build-ml-app.html" rel="alternate" type="text/html" title="Building Machine Learning Powered Applications: Going from Idea to Product" /><published>2020-05-22T00:00:00-05:00</published><updated>2020-05-22T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/machine%20learning/data%20science/deploy/2020/05/22/build-ml-app</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/machine%20learning/data%20science/deploy/2020/05/22/build-ml-app.html">&lt;p&gt;My notes and highlights on the book.&lt;/p&gt;

&lt;p&gt;Author: Emmanuel Ameisen&lt;/p&gt;

&lt;h1 id=&quot;part-i-find-the-correct-ml-approach&quot;&gt;Part I. Find the Correct ML Approach&lt;/h1&gt;

&lt;h1 id=&quot;ch1-from-product-goal-to-ml-framing&quot;&gt;Ch1. From Product Goal to ML Framing&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;ML is particularly useful to build systems for which we are unable to define a heuristic solution&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Start from a concrete business problem, determine whether it requires ML, then work on finding the ML approach that will allow you to iterate as rapidly as possible&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Framing your product goal in an ML paradigm&lt;/li&gt;
  &lt;li&gt;Evaluating the feasibility of that ML task&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Estimating the challenge of data acquisition ahead of time is crucial in order to succeed&lt;/p&gt;

&lt;h2 id=&quot;data-availability-scenarios&quot;&gt;Data availability scenarios&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Labeled data exists&lt;/li&gt;
  &lt;li&gt;Weakly labeled data exists&lt;/li&gt;
  &lt;li&gt;Unlabeled data exists&lt;/li&gt;
  &lt;li&gt;We need to acquire data&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Having an imperfect dataset is entirely fine and shouldn’t stop you. The ML process is iterative in nature, so starting with a dataset and getting some initial results is the best way forward, regardless of the data quality.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-simplest-approach-being-the-algorithm&quot;&gt;The Simplest Approach: being the algorithm&lt;/h2&gt;
&lt;p&gt;Start with a human heuristic and then build a simple model: initial baseline = first step toward a solution -&amp;gt; Great way to inform what to build next&lt;/p&gt;

&lt;h2 id=&quot;what-to-focus-on-in-an-ml-project&quot;&gt;What to focus on in an ML project&lt;/h2&gt;
&lt;p&gt;Find the &lt;em&gt;impact bottleneck&lt;/em&gt;: piece of the pipeline that could provide the most value if improved&lt;/p&gt;

&lt;p&gt;Imagine that the impact bottleneck is solved: it was worth the effort you estimate it would take?&lt;/p&gt;

&lt;h2 id=&quot;which-modeling-techniques-to-use&quot;&gt;Which modeling techniques to use&lt;/h2&gt;
&lt;p&gt;Spend the manual effort to look at inputs and outputs of your model: see if anything looks weird. Looking at your data helps you think of good heuristics, models and ways to reframe the product&lt;/p&gt;

&lt;h1 id=&quot;ch2-create-a-plan&quot;&gt;Ch2. Create a Plan&lt;/h1&gt;

&lt;h2 id=&quot;measuring-success&quot;&gt;Measuring Success&lt;/h2&gt;
&lt;p&gt;First model: simplest model that could address a product’s needs -&amp;gt; generating and analyzing results is the fastest way to make progress in ML&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Baseline: heuristics based on domain knowledge&lt;/li&gt;
  &lt;li&gt;Simple model&lt;/li&gt;
  &lt;li&gt;Complex model&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;You don’t always need ML: even features that could benefit from ML can often simply use a heuristic for their first version (you may realize that you don’t need ML at all)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;business-performance&quot;&gt;Business Performance&lt;/h2&gt;
&lt;p&gt;Product metrics: goals of your product or feature. Ultimately the only ones that matter, all other metrics should be used as tools to improve product metrics&lt;/p&gt;

&lt;h3 id=&quot;updating-an-app-to-make-a-modeling-task-easier&quot;&gt;Updating an app to make a modeling task easier&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Change an interface so that a model’s results can be omitted if they are below a confidence threshold&lt;/li&gt;
  &lt;li&gt;Present a few other predictions or heuristics in addition to model’s top prediction&lt;/li&gt;
  &lt;li&gt;Communicate to users that model is still in an experimental phase and giving them opportunities to provide feedback&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“A product should be designed with reasonable assumptions of model performance in mind. If a product relies on a model being perfect to be useful, it is very likely to produce innacurate or even dangerous results”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;freshness-and-distribution-shift&quot;&gt;Freshness and Distribution Shift&lt;/h2&gt;
&lt;p&gt;Distribution of the data shifts -&amp;gt; model often needs to change in order to maintain the same level of performance&lt;/p&gt;

&lt;h2 id=&quot;leverage-domain-expertise&quot;&gt;Leverage Domain Expertise&lt;/h2&gt;
&lt;p&gt;Best way to devise heuristics -&amp;gt; see what experts are currently doing. Most practical applications are not entirely novel. How do people currently solve the problem you are trying to solve?&lt;/p&gt;

&lt;p&gt;Second best way -&amp;gt; look at your data. Based on your dataset, how would you solve this task if you were doing it manually?&lt;/p&gt;

&lt;h3 id=&quot;examining-the-data&quot;&gt;Examining the data&lt;/h3&gt;
&lt;p&gt;EDA: process of visualizing and exploring a dataset -&amp;gt; to get an intuition to a given business problem. Crucial part of building any data product&lt;/p&gt;

&lt;h2 id=&quot;stand-on-the-shoulders-of-giants&quot;&gt;Stand on the Shoulders of giants&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Reproduce existing results&lt;/li&gt;
  &lt;li&gt;Build on top of them&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;to-make-regular-progress-start-simple&quot;&gt;To make regular progress: start simple&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Start with the simplest model that could address your requirements&lt;/li&gt;
  &lt;li&gt;Build an end-to-end prototype including this model&lt;/li&gt;
  &lt;li&gt;Judge its performance: optimization metrics and product goal&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Looking at the performance of a simple model on an initial dataset is the best way to decide what task should be tackled next&lt;/p&gt;

&lt;h2 id=&quot;diagnose-problems&quot;&gt;Diagnose Problems&lt;/h2&gt;
&lt;p&gt;Write analysis and exploration functions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Visualize examples the model performs the best and worst on&lt;/li&gt;
  &lt;li&gt;Explore data&lt;/li&gt;
  &lt;li&gt;Explore model results&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;part-ii-build-a-working-pipeline&quot;&gt;Part II. Build a Working Pipeline&lt;/h1&gt;

&lt;h1 id=&quot;ch3-build-your-first-end-to-end-pipeline&quot;&gt;Ch3. Build your first end-to-end pipeline&lt;/h1&gt;
&lt;p&gt;First iteration: lackluster by design. Goal: allow us to have all the pieces of a pipeline in place:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;prioritize which ones to improve next&lt;/li&gt;
  &lt;li&gt;identify the impact bottleneck&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Frequently, your product is dead even if your model is successful” - Monica Rogati&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;test-your-workflow&quot;&gt;Test your workflow&lt;/h2&gt;
&lt;p&gt;Evaluate:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;usefulness of the current user experience&lt;/li&gt;
  &lt;li&gt;results of your handcrafted model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;finding-the-impact-bottleneck&quot;&gt;Finding the impact bottleneck&lt;/h2&gt;
&lt;p&gt;Next challenge to tackle next:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;iterating on the way we present results to the users or;&lt;/li&gt;
  &lt;li&gt;improving model performance by identifying key failure points&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ch4-acquire-an-initial-dataset&quot;&gt;Ch4. Acquire an initial dataset&lt;/h1&gt;
&lt;p&gt;Understanding your data well leads to the biggest performance improvements&lt;/p&gt;

&lt;h2 id=&quot;iterate-on-datasets&quot;&gt;Iterate on datasets&lt;/h2&gt;
&lt;p&gt;Data gathering, preparation and labeling should be seen as an iterative process, just like modeling&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ML engineering&lt;/strong&gt;: engineering + ML = products&lt;/p&gt;

&lt;p&gt;Choosing an initial dataset, regularly updating it, and augmenting it is the majority of the work&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data&lt;/strong&gt;: best source of inspiration to develop new models and the first place to look for answers when things go wrong&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Models only serve as a way to extract trends and patterns from existing data. Don’t overestimate the impact of working on the model and underestimate the value of working on the data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Before noticing predictive trends, start by examining &lt;strong&gt;quality&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-quality-rubric&quot;&gt;Data quality rubric&lt;/h2&gt;

&lt;h3 id=&quot;format&quot;&gt;Format&lt;/h3&gt;
&lt;p&gt;Validate that you understand the way in which the data was processed&lt;/p&gt;

&lt;h3 id=&quot;quality&quot;&gt;Quality&lt;/h3&gt;
&lt;p&gt;Notice the quality &lt;strong&gt;ahead of time&lt;/strong&gt; -&amp;gt; missing labels, weak labels&lt;/p&gt;

&lt;h3 id=&quot;quantity-and-distribution&quot;&gt;Quantity and distribution&lt;/h3&gt;
&lt;p&gt;Estimate:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;enough data?&lt;/li&gt;
  &lt;li&gt;feature values are within reasonable range?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary-statistics&quot;&gt;Summary statistics&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Identifying differences in distributions between classes of data early: will either make our modeling task easier or prevent us from overestimating the performance of a model that may just be leveraging one particularly informative feature.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;data-leakage&quot;&gt;Data leakage&lt;/h3&gt;
&lt;p&gt;Using training and validation data for vectorizing/preprocessing can cause data leakage -&amp;gt; leveraging info from outside the training set to create training features&lt;/p&gt;

&lt;h2 id=&quot;clustering&quot;&gt;Clustering&lt;/h2&gt;
&lt;p&gt;As with dimensionality reduction: additional way to surface issues and interesting data points&lt;/p&gt;

&lt;h2 id=&quot;let-data-inform-features-and-models&quot;&gt;Let data inform features and models&lt;/h2&gt;
&lt;p&gt;The more data you have and the less noisy your data is, the less feature engineering work you usually have to do&lt;/p&gt;

&lt;h3 id=&quot;feature-crosses&quot;&gt;Feature crosses&lt;/h3&gt;
&lt;p&gt;Feature generated by multiplying (crossing) two or more features -&amp;gt; nonlinear combination of features -&amp;gt; allows our model to discriminate more easily&lt;/p&gt;

&lt;h3 id=&quot;giving-your-model-the-answer&quot;&gt;Giving your model the answer&lt;/h3&gt;
&lt;p&gt;New binary feature that takes a nonzero value only when relevant combination of values appear&lt;/p&gt;

&lt;h2 id=&quot;robert-munro-how-do-you-find-label-and-leverage-data&quot;&gt;Robert Munro: how do you find, label and leverage data&lt;/h2&gt;

&lt;h3 id=&quot;uncertainty-sampling&quot;&gt;Uncertainty sampling&lt;/h3&gt;
&lt;p&gt;Identify examples that your model is most uncertain about and find similar examples to add to the training set&lt;/p&gt;

&lt;h3 id=&quot;error-model&quot;&gt;“Error model”&lt;/h3&gt;
&lt;p&gt;Use the mistakes your model makes as labels: “predicted correctly” or “predicted incorrectly”. Use the trained error model on unlabeled data and label the examples that it predicts your model will fail on&lt;/p&gt;

&lt;h3 id=&quot;labeling-model&quot;&gt;“Labeling model”&lt;/h3&gt;
&lt;p&gt;To find the best examples to label next. Identify data points that are most different from what you’ve already labeled and label those&lt;/p&gt;

&lt;h3 id=&quot;validation&quot;&gt;Validation&lt;/h3&gt;
&lt;p&gt;While you should use strategies to gather data, you should always randomly sample from your test set to validate your model&lt;/p&gt;

&lt;h1 id=&quot;part-iii-iterate-on-models&quot;&gt;Part III. Iterate on Models&lt;/h1&gt;

&lt;h1 id=&quot;ch5-train-and-evaluate-your-model&quot;&gt;Ch5. Train and evaluate your model&lt;/h1&gt;

&lt;h2 id=&quot;the-simplest-appropriate-model&quot;&gt;The simplest appropriate model&lt;/h2&gt;
&lt;p&gt;Not the best approach: try every possible model, benchmark and pick the one with the best results on a test set&lt;/p&gt;

&lt;h3 id=&quot;simple-model&quot;&gt;Simple model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Quick to implement: won’t be your last&lt;/li&gt;
  &lt;li&gt;Understandable: debug easily&lt;/li&gt;
  &lt;li&gt;Deployable: fundamental requirement for a ML-powered application&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Model explainability and interpretability: ability for a model to expose reasons that caused it to make predictions&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;test-set&quot;&gt;Test set&lt;/h2&gt;
&lt;p&gt;“While using a test set is a best practice, practitioners sometimes use the validation set as a test set. This increases the risk of biasing a model toward the validation set but can be appropriate when running only a few experiments”&lt;/p&gt;

&lt;h2 id=&quot;data-leakage-1&quot;&gt;Data leakage&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Temporal data leakage&lt;/li&gt;
  &lt;li&gt;Sample contamination&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Always investigate the results of a model, especially if it shows surprisingly strong performance&lt;/p&gt;

&lt;h2 id=&quot;bias-variance-trade-off&quot;&gt;Bias variance trade-off&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Underfitting: weak performance on the training set = high bias&lt;/li&gt;
  &lt;li&gt;Overfitting: strong performance on the training set, but weak performance on the validation set = high variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluate-your-model-look-beyond-accuracy&quot;&gt;Evaluate your model: look beyond accuracy&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Contrast data and predictions&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Confusion matrix&lt;/strong&gt;: see whether our model is particularly successful on certain classes and struggles on some others&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ROC Curve&lt;/strong&gt;: plot a threshold on it to have a more concrete goal than simply getting the largest AUC score&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Calibration Curve&lt;/strong&gt;: whether our model’s outputed probability represents its confidence well. Shows the fraction of true positive examples as a function of the confidence of our classifier&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dimensionality reduction for errors&lt;/strong&gt;: identify a region in which a model performs poorly and visualize a few data points in it&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The top-k method&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;k best performing examples&lt;/strong&gt;: identify features that are successfully leveraged by a model&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;k worst performing examples&lt;/strong&gt;: on train: identify trends in data the model fails on, identify additional features that would make them easier for a model. On validation: identify examples that significantly differ from the train data&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;k most uncertain examples&lt;/strong&gt;: on train: often a symptom of conflicting labels. On validation: can help find gaps in your training data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Top-k implementation: &lt;a href=&quot;https://github.com/hundredblocks/ml-powered-applications/blob/master/ml_editor/model_evaluation.py#L250-L295&quot;&gt;book’s Github repository&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;evaluate-feature-importance&quot;&gt;Evaluate Feature Importance&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Eliminate or iterate on features that are currently not helping the model&lt;/li&gt;
  &lt;li&gt;Identify features that are suspiciously predictive, which is often a sign of data leakage&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;black-box-explainers&quot;&gt;Black-box explainers&lt;/h2&gt;
&lt;p&gt;Attempt to explain a model’s predictions independently of its inner workings, i.e. LIME and SHAP&lt;/p&gt;

&lt;h1 id=&quot;ch6-debug-your-ml-problems&quot;&gt;Ch6. Debug your ML problems&lt;/h1&gt;

&lt;h2 id=&quot;software-best-practices&quot;&gt;Software Best Practices&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;KISS principle&lt;/strong&gt;: building only what you need&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Most software applications: strong test coverage = high confidence app is functioning well. ML pipelines can pass many tests, but still give entirely incorrect results. Doesn’t have just to run, it should produce accurate predictive outputs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Progressive approach, validate:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Data flow&lt;/li&gt;
  &lt;li&gt;Learning capacity&lt;/li&gt;
  &lt;li&gt;Generalization and inference&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Make sure your pipeline works for a few examples, then write tests to make sure it keeps functioning as you make changes&lt;/p&gt;

&lt;h2 id=&quot;visualization-steps&quot;&gt;Visualization steps&lt;/h2&gt;
&lt;p&gt;Inspect changes at regular intervals&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data loading&lt;/strong&gt;: Verify data is formatted correctly&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cleaning and feature selection&lt;/strong&gt;: remove any unnecessary information&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Feature generation&lt;/strong&gt;: check that the feature values are populated and that the values seem reasonable&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data formatting&lt;/strong&gt;: shapes, vectors&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Model output&lt;/strong&gt;: first look if the predictions are the right type or shape, then check if the model is actually leveraging the input data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;separate-your-concerns&quot;&gt;Separate your concerns&lt;/h2&gt;
&lt;p&gt;Modular organization: separate each function so that you can check that it individually works before looking at the broader pipeline. Once broken down, you’ll be able to write tests&lt;/p&gt;

&lt;h2 id=&quot;test-your-ml-code&quot;&gt;Test your ML code&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hundredblocks/ml-powered-applications/tree/master/tests&quot;&gt;Source code on book’s Github repository&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Test data ingestion&lt;/li&gt;
  &lt;li&gt;Test data processing&lt;/li&gt;
  &lt;li&gt;Test model outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;debug-training-make-your-model-learn&quot;&gt;Debug training: make your model learn&lt;/h2&gt;
&lt;p&gt;Contextualize model performance: generate an estimate of what an acceptable error for the taks is by labeling a few examples yourself&lt;/p&gt;

&lt;h3 id=&quot;task-difficulty&quot;&gt;Task difficulty&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;The quantity and diversity of data you have&lt;/strong&gt;: more diverse/complex the problem = more data for the model to learn from it&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;How predictive the features are&lt;/strong&gt;: make the data more expressive to help the model learn better&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The complexity of your model&lt;/strong&gt;: simplest model is good to quickly iterate, but some tasks are entirely out of reach of some models&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;debug-generalization-make-your-model-useful&quot;&gt;Debug generalization: make your model useful&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Leakage&lt;/strong&gt;: if you are surprised by validation performance, inspect the features; fixing a leakage issue will lead to lower validation performance, but a better model&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt;: model performs drastically better on the training set than on the test set. Add regularization or data augmentation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dataset redesign&lt;/strong&gt;: use k-fold cross validation to alleviate concerns that data splits may be of unequal quality&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“If your models aren’t generalizing, your task may be too hard. There may not be enough information in your training examples to learn meaningful features that will be informative for future data points. If that is the case, then the problem you have is not well suited for ML”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch7-using-classifiers-for-writing-recommendations&quot;&gt;Ch7. Using classifiers for writing recommendations&lt;/h1&gt;

&lt;h1 id=&quot;part-iv-deploy-and-monitor&quot;&gt;Part IV. Deploy and Monitor&lt;/h1&gt;
&lt;p&gt;Production ML pipelines need to be able to detect data and model failures and handle them with grace -&amp;gt; &lt;strong&gt;proactively&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;ch8-considerations-when-deploying-models&quot;&gt;Ch8. Considerations when deploying models&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;How was the data you are using collected?&lt;/li&gt;
  &lt;li&gt;What assumptions is your model making by learning from this dataset?&lt;/li&gt;
  &lt;li&gt;Is this dataset representative enough to produce a useful model?&lt;/li&gt;
  &lt;li&gt;How could the results of your work be misused?&lt;/li&gt;
  &lt;li&gt;What is the intended use and scope of your model?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-concerns&quot;&gt;Data Concerns&lt;/h2&gt;

&lt;h3 id=&quot;data-ownership&quot;&gt;Data ownership&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Collection&lt;/li&gt;
  &lt;li&gt;Usage and permission&lt;/li&gt;
  &lt;li&gt;Storage&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-bias&quot;&gt;Data bias&lt;/h3&gt;
&lt;p&gt;Datasets: results of specific data collection decisions -&amp;gt; lead to datasets presenting a biased view of the world. ML models learn from datasets -&amp;gt; will reproduce these biases&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Measurement errors or corrupted data&lt;/li&gt;
  &lt;li&gt;Representation&lt;/li&gt;
  &lt;li&gt;Access&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;test-sets&quot;&gt;Test sets&lt;/h4&gt;
&lt;p&gt;Build a test set that is inclusive, representative, and realistic -&amp;gt; proxy for performance in production -&amp;gt; improve the chances that every user has an equally positive experience&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Models are trained on historical data -&amp;gt; state of the world in the past. Bias most often affects populations that are already disenfranchised. Working to eliminate bias -&amp;gt; help make systems fairer for the people who need it most&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;modeling-concerns&quot;&gt;Modeling Concerns&lt;/h2&gt;

&lt;h3 id=&quot;feedback-loops&quot;&gt;Feedback loops&lt;/h3&gt;
&lt;p&gt;User follow a model’s recommendation -&amp;gt; future models make the same recommendation -&amp;gt; models enter a self-reinforcing feedback loop&lt;/p&gt;

&lt;p&gt;To limit negative effects of feedback loops -&amp;gt; choose a label that is less prone to creating such a loop&lt;/p&gt;

&lt;h3 id=&quot;inclusive-model-performance&quot;&gt;Inclusive model performance&lt;/h3&gt;
&lt;p&gt;Look for performance on a segment of the data, instead of only comparing aggregate performance&lt;/p&gt;

&lt;h3 id=&quot;adversaries&quot;&gt;Adversaries&lt;/h3&gt;
&lt;p&gt;Regularly update models&lt;/p&gt;

&lt;p&gt;Some types of attacks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fool models into a wrong prediction (most common)&lt;/li&gt;
  &lt;li&gt;Use a trained model to learn about the data it was trained on&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;chris-harland-shipping-experiments&quot;&gt;Chris Harland: Shipping Experiments&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;When giving advice, the cost of being wrong is very high, so precision is the most useful&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch9-choose-your-deployment-option&quot;&gt;Ch9. Choose Your Deployment Option&lt;/h1&gt;

&lt;h2 id=&quot;server-side-deployment&quot;&gt;Server-side deployment&lt;/h2&gt;
&lt;p&gt;Setting up a web server that can accept requests from clients, run them through an inference pipeline, and return the results. The servers represents a central failure point for the application and can be costly if the product becomes popular&lt;/p&gt;

&lt;h3 id=&quot;streaming-api-workflow&quot;&gt;Streaming API workflow&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Endpoint approach&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quick to implement&lt;/li&gt;
  &lt;li&gt;Requires infrastructure to scale linearly with the current number of users (1 user = 1 separate inference call)&lt;/li&gt;
  &lt;li&gt;Required when strong latency constraints exist (info the model needs is available only at prediction time and model’s prediction is required immediately)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;batch-predictions&quot;&gt;Batch Predictions&lt;/h3&gt;
&lt;p&gt;Inference pipeline as a job that can be run on multiple examples at once. Store predictions so they can be used when needed&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Appropriate when you have access to the features need for a model before the model’s prediction is required&lt;/li&gt;
  &lt;li&gt;Easier to allocate and parallelize resources&lt;/li&gt;
  &lt;li&gt;Faster at inference time since results have been precomputed and only need to be retrieved (similar gains to caching)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hybrid-approach&quot;&gt;Hybrid Approach&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Precompute as many cases as possible&lt;/li&gt;
  &lt;li&gt;At inference either retrieve precomputed results or compute them on the spot if they are not available or are outdated&lt;/li&gt;
  &lt;li&gt;Have to maintain both a batch and streaming pipeline (more complexity of the system)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;client-side-deployment&quot;&gt;Client-side deployment&lt;/h2&gt;
&lt;p&gt;Run all computations on the client, eliminating the need for a server to run models. Models are still trained in the same manner and are sent to the device for inference&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reduces the need to build infra&lt;/li&gt;
  &lt;li&gt;Reduces the quantity of data that needs to be transferred between the device and the server
    &lt;ul&gt;
      &lt;li&gt;Reduces network latency (app may even run without internet)&lt;/li&gt;
      &lt;li&gt;Removes the need for sensitive information to be transferred to a remote server&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;If the time it would take to run inference on device is larger than the time it would take to transmit data to the server to be processed, consider running your model in the cloud&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On-device deployment is only worthwhile if the latency, infrastructure, and privacy benefits are valuable enough to invest the engineering effort (simplifying a model)&lt;/p&gt;

&lt;h2 id=&quot;browser-side&quot;&gt;Browser side&lt;/h2&gt;
&lt;p&gt;Some libraries use browsers to have the client perform ML tasks&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Tensorflow.js&lt;/code&gt;: train and run inference in JavaScript in the browser for most differentiable models, even trained in different languages such as Python&lt;/p&gt;

&lt;h2 id=&quot;federated-learning-a-hybrid-apporach&quot;&gt;Federated Learning: a hybrid apporach&lt;/h2&gt;
&lt;p&gt;Each client has their own model. Each model learns from their user’s data and send aggregated (and potentially anonymized) updates to the server. The server leverages all updates to improve its model and distills this new model back to individual clients. Each user receives a model personalized to their needs, while still benefiting from aggregate information about other users&lt;/p&gt;

&lt;h1 id=&quot;ch10-build-safeguards-for-models&quot;&gt;Ch10. Build Safeguards for Models&lt;/h1&gt;
&lt;p&gt;No matter how good a model is, it will fail on some examples -&amp;gt; engineer a system that can gracefully handle such features&lt;/p&gt;

&lt;h2 id=&quot;check-inputs&quot;&gt;Check inputs&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Very different data from train&lt;/li&gt;
  &lt;li&gt;Some features missing&lt;/li&gt;
  &lt;li&gt;Unexpected types&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Input checks are part of the pipeline -&amp;gt; change the control flow of a program based on the quality of inputs&lt;/p&gt;

&lt;h2 id=&quot;model-outputs&quot;&gt;Model outputs&lt;/h2&gt;
&lt;p&gt;Prediction falls outside an acceptable range -&amp;gt; consider not displaying it&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Acceptable outcome: not only if the outcome is plausible -&amp;gt; also depends if the outcome would be &lt;strong&gt;useful for the user&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;model-failure-fallbacks&quot;&gt;Model failure fallbacks&lt;/h2&gt;
&lt;p&gt;Flag cases that are too hard and encourage user to provide an easier input (e.g. well-lit photo)&lt;/p&gt;

&lt;p&gt;Detecting errors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Track the confidence of a model&lt;/li&gt;
  &lt;li&gt;Build an additional model tasked with detecting examples a main model is likely to fail on&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;filtering-model&quot;&gt;Filtering model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ML version of input tests&lt;/li&gt;
  &lt;li&gt;Binary classifier&lt;/li&gt;
  &lt;li&gt;Estimate how well a model will perform on an example without running the model on it&lt;/li&gt;
  &lt;li&gt;Decrease the likelihood of poor results and improve resource usage&lt;/li&gt;
  &lt;li&gt;Catch:
    &lt;ul&gt;
      &lt;li&gt;qualitatively different inputs&lt;/li&gt;
      &lt;li&gt;inputs the model struggled&lt;/li&gt;
      &lt;li&gt;adversarial inputs meant to fool the model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Minimum criteria:
    &lt;ul&gt;
      &lt;li&gt;should be fast (reduce the computational burden)&lt;/li&gt;
      &lt;li&gt;should be good at eliminating hard cases&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The faster your filtering model is, the less effective it needs to be&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;engineer-for-performance&quot;&gt;Engineer for Performance&lt;/h2&gt;
&lt;h3 id=&quot;scale-to-multiple-users&quot;&gt;Scale to multiple users&lt;/h3&gt;
&lt;p&gt;ML is horizontally scalable = more servers = keep response time reasonable when the number of requests increases&lt;/p&gt;

&lt;h3 id=&quot;caching-fo-ml&quot;&gt;Caching fo ML&lt;/h3&gt;
&lt;p&gt;Storing results to function calls -&amp;gt; future calls with same parameters simply retrieve the stored results&lt;/p&gt;

&lt;h4 id=&quot;caching-inference-results&quot;&gt;Caching inference results&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Least recently used (LRU) cache&lt;/strong&gt;: keep track the most recent inputs to a model and their corresponding outputs&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;not appropriate if each input is unique&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;functools&lt;/code&gt; Python module proposes a default implementation of an LRU cache that you can use with a simple decorator&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
from functools import lru_cache

@lru_cache(maxsize=128)
def run_model(data):
  # Insert slow model inference below
  pass

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;caching-by-indexing&quot;&gt;Caching by indexing&lt;/h4&gt;
&lt;p&gt;Cache other aspects of the pipeline that can be precomputed. Easy if a model does not only rely on user inputs&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Caching can improve performance, but it adds a layer of complexity. The size of the cache becomes an additional hyperparameter to tune depending on your application’s workload. In addition, any time a model or the underlying data is updated, the cache needs to be cleared in order to prevent it from serving outdated results”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;model-and-data-life-cycle-management&quot;&gt;Model and data life cycle management&lt;/h2&gt;
&lt;p&gt;ML application:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;produces reproducible results&lt;/li&gt;
  &lt;li&gt;is resilient to model updates&lt;/li&gt;
  &lt;li&gt;is flexible enough to handle significant modelling and data processing changes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reproducibility&quot;&gt;Reproducibility&lt;/h3&gt;
&lt;p&gt;Each model/dataset pair should be assigned an unique identifier -&amp;gt; should be logged each time a model is used in production&lt;/p&gt;

&lt;h3 id=&quot;resilience&quot;&gt;Resilience&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;production pipeline should aim to update models without significant downtime&lt;/li&gt;
  &lt;li&gt;if a new model performs poorly, we’d like to be able to roll back to the previous one&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-processing-and-dags&quot;&gt;Data Processing and DAGs&lt;/h2&gt;
&lt;p&gt;Directed acyclic graph (DAG): can be used to represent our process of going from raw data to trained model -&amp;gt; each node represent a processing step and each step represent a dependency between two nodes&lt;/p&gt;

&lt;p&gt;DAGs helps systematize, debug, and version a pipeline -&amp;gt; can become a crucial time saver&lt;/p&gt;

&lt;h2 id=&quot;ask-for-feedback&quot;&gt;Ask for feedback&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Explicity asking for feedback (display model’s prediction accompanying it with a way for users to judge and correct a prediction)&lt;/li&gt;
  &lt;li&gt;Measuring implicit signals&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;User feedback is a good source of training data and can be the first way to notice a degradation in performance&lt;/p&gt;

&lt;h2 id=&quot;chris-moody-empowering-data-scientist-to-deploy-models&quot;&gt;Chris Moody: Empowering Data Scientist to Deploy Models&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Make humans and algorithms work together: spend time thinking about the right way to present information&lt;/li&gt;
  &lt;li&gt;Canary development -&amp;gt; start deploying the new version to one instance and progressively update instances while monitoring performance&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Ownership of the entire pipeline leads individuals to optimize for impact and reliability, rather than model complexity”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ch11-monitor-and-update-models&quot;&gt;Ch11. Monitor and update models&lt;/h1&gt;
&lt;h2 id=&quot;monitoring-saves-lives&quot;&gt;Monitoring saves lives&lt;/h2&gt;
&lt;p&gt;Monitoring: track the health of a system. For models: performance and quality of their predictions&lt;/p&gt;

&lt;h3 id=&quot;monitor-to-inform-refresh-rate&quot;&gt;Monitor to inform refresh rate&lt;/h3&gt;
&lt;p&gt;Detect when a model is not fresh anymore and needs to be retrained. Retraining events happen when accuracy dips below a threshold.&lt;/p&gt;

&lt;h3 id=&quot;monitor-to-detect-abuse&quot;&gt;Monitor to detect abuse&lt;/h3&gt;
&lt;p&gt;Anomaly detection to detect attacks&lt;/p&gt;

&lt;h2 id=&quot;choose-what-to-monitor&quot;&gt;Choose what to monitor&lt;/h2&gt;
&lt;p&gt;Commonly monitor metrics such as the average time it takes to process a request, the proportion of requests that fail to be processed, and the amount of available resources&lt;/p&gt;

&lt;h3 id=&quot;performance-metrics&quot;&gt;Performance Metrics&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Track changes in the input distribution (&lt;em&gt;feature drift&lt;/em&gt;)&lt;/li&gt;
  &lt;li&gt;Monitor the input distribution (summary statistics)&lt;/li&gt;
  &lt;li&gt;Monitor distribution shifts&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Conterfactual evaluation&lt;/strong&gt;: aims to evaluate what would have happened if we hadn’t actioned a model -&amp;gt; Not acting on a random subset of examples allow us to observe an unbiased distribution of the positive class. Comparing model predictions to true outcomes for the random data, we can begin to estimate a model’s precision and recall&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;business-metrics&quot;&gt;Business metrics&lt;/h3&gt;
&lt;p&gt;Product metrics should be closely monitored&lt;/p&gt;

&lt;h2 id=&quot;cicd-for-ml&quot;&gt;CI/CD for ML&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CI&lt;/strong&gt;: letting multiple developers regularly merge their code back into a central codebase&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CD&lt;/strong&gt;: improving the speed at which new versions of software can be released&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CI/CD for ML: make it easier to deploy new models or update existing ones&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Releasing updates quickly is easy; the challenge comes in guaranteeing their quality (…) There is no substitute for live performance to judge the quality of a model”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Shadow mode&lt;/strong&gt;: deploying a new model in parallel to an existing one. When running inference, both models’ predictions are computed and stored, but the application only uses the prediction of the existing model&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;estimate a new models’ performance in a production environment without changing the user experience&lt;/li&gt;
  &lt;li&gt;test the infrastructure required to run inference for a new model (may be more complex)&lt;/li&gt;
  &lt;li&gt;but can’t observe the user’s response to the new model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ab-testing-and-experimentation&quot;&gt;A/B Testing and Experimentation&lt;/h2&gt;
&lt;p&gt;Goal: maximize chances of using the best model, while minimizing the cost of trying out suboptimal models&lt;/p&gt;

&lt;p&gt;Expose a sample of users to a new model, and the rest to another. Larger control group (current model) and a smaller treatment group (new version we want to test). Run for a sufficient amount of time -&amp;gt; compare the results for both groups and choose the better model&lt;/p&gt;

&lt;h3 id=&quot;choosing-groups-and-duration&quot;&gt;Choosing groups and duration&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Users in both groups should be as similar as possible -&amp;gt; any difference in outcome = our model and not difference in cohorts&lt;/li&gt;
  &lt;li&gt;Treatment group should be:
    &lt;ul&gt;
      &lt;li&gt;large enough: statistically meaningful conclusion&lt;/li&gt;
      &lt;li&gt;small as possible: limit exposure to a potentially worse model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Duration of the test:
    &lt;ul&gt;
      &lt;li&gt;too short: not enough information&lt;/li&gt;
      &lt;li&gt;too long: risk losing users&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;estimating-the-better-variant&quot;&gt;Estimating the better variant&lt;/h3&gt;
&lt;p&gt;Decide on the size of each group and the length of the experiment before running it&lt;/p&gt;

&lt;h3 id=&quot;building-the-infrastructure&quot;&gt;Building the infrastructure&lt;/h3&gt;
&lt;p&gt;Branching logic: decides which model to run depending on a given field’s value (harder if a model is accessible to logged-out users)&lt;/p&gt;

&lt;h2 id=&quot;other-approaches&quot;&gt;Other approaches&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Multiarmed bandits&lt;/strong&gt;: more flexible approach, can test variants continually and on more than two alternatives. Dynamically update which model to serve based on how well each option in performing&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contextual multiarmed bandits&lt;/strong&gt;: go even further, by learning which model is a better option for each particular user&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The majority of work involved with building ML products consists of data and engineering work”&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">My notes and highlights on the book.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/build_ml_app/build_ml_app.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/build_ml_app/build_ml_app.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Leadership Strategy and Tactics: Field Manual</title><link href="https://millengustavo.github.io/blog/book/leadership/management/2020/03/17/leadership.html" rel="alternate" type="text/html" title="Leadership Strategy and Tactics: Field Manual" /><published>2020-03-17T00:00:00-05:00</published><updated>2020-03-17T00:00:00-05:00</updated><id>https://millengustavo.github.io/blog/book/leadership/management/2020/03/17/leadership</id><content type="html" xml:base="https://millengustavo.github.io/blog/book/leadership/management/2020/03/17/leadership.html">&lt;blockquote&gt;
  &lt;p&gt;What makes leadership so hard is dealing with people, and people are crazy. And the craziest person a leader has to deal with is themselves.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Those are the notes I took when reading the book “Leadership Strategy and Tactics: Field Manual” by Jocko Willink. I recommend reading the book for a more coherent view of the context in which each note is inserted.&lt;/p&gt;

&lt;h1 id=&quot;first-platoon-detach&quot;&gt;First Platoon: Detach&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Pay attention to yourself and what is happening around you.&lt;/li&gt;
  &lt;li&gt;Avoid being fully absorbed in the minute details of any situation.&lt;/li&gt;
  &lt;li&gt;Stay aware, check yourself, avoid getting tunnel vision.&lt;/li&gt;
  &lt;li&gt;Put the team and the mission above yourself.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Prioritize and Execute&lt;/strong&gt;. The most impactful task or the biggest problem must be addressed first&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Extreme Ownership&lt;/strong&gt; is a mind-set of not making excuses and not blaming anyone or anything else when problems occur.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Dichotomy of Leadership&lt;/strong&gt; describes opposing forces that are pulling leaders in contradictory directions at the same time. To lead properly, a leader must be balanced&lt;/li&gt;
  &lt;li&gt;Leadership requires relationships. The better the relationships, the more open and effective communication there is. The more communication there is, the stronger the team will be.&lt;/li&gt;
  &lt;li&gt;Communicate ideas in a simple, clear manner&lt;/li&gt;
  &lt;li&gt;Look people in the eye when talking to them, listen intently to what others say, and speak clearly with humble authority.&lt;/li&gt;
  &lt;li&gt;Pay attention to body language, facial expressions, and tone of voice.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“There is one type of person who can never become a good leader: a person who lacks humility. People who lack humility cannot improve because they don’t acknowledge their own weaknesses.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The good of the mission and the good of the team outweigh any personal concern a true leader has for themselves.&lt;/li&gt;
  &lt;li&gt;Good leaders do the right things for the right reasons; they work hard, support the team, and lead solid execution.&lt;/li&gt;
  &lt;li&gt;Ego is like reactive armor; the harder you push against it, the more it pushes back.&lt;/li&gt;
  &lt;li&gt;Subordinating your ego is actually the ultimate form of self-confidence. That level of confidence earns respect.&lt;/li&gt;
  &lt;li&gt;Communicate often so the bad news will sting less.&lt;/li&gt;
  &lt;li&gt;Lead from the front, especially when things are bad. As a leader, do the hard things. Don’t leave it to the troops.&lt;/li&gt;
  &lt;li&gt;Most criticism is best delivered indirectly, with the minimal amount of negativity needed to get the desired change.&lt;/li&gt;
  &lt;li&gt;A leader must be constantly improving and learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;core-tenets&quot;&gt;Core Tenets&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;If you need help with something, ask for it. Subordinates understand that their leaders might not know everything.&lt;/li&gt;
  &lt;li&gt;If you want to have influence over others, you need to allow them to have influence over you.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Preemptive ownership&lt;/strong&gt;: take ownership of things to prevent problems from unfolding in the first place&lt;/li&gt;
  &lt;li&gt;People tend to shy away from suffering; they will procrastinate and avoid getting started. But when the leader jumps in and starts attacking the job, others will jump in and get started as well.&lt;/li&gt;
  &lt;li&gt;The best ideas often come from the people on the team who are closest to the problem; those are the folks on the front line. Take a step back and let your team lead.&lt;/li&gt;
  &lt;li&gt;Overreaction is always bad.&lt;/li&gt;
  &lt;li&gt;Relationships do not mean preferential treatment.&lt;/li&gt;
  &lt;li&gt;Before diving into a problem: How will this problem impact the team’s strategic goals? Can it cause mission failure? Is it worth my time and effort to engage in it? How bad can it get if I leave it alone?&lt;/li&gt;
  &lt;li&gt;The goal is always to allow problems to get solved at the lowest level. When subordinates are solving low-level problems, it allows the leader to focus on more important, strategic issues.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;principles&quot;&gt;Principles&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Every person’s job is absolutely critical. Explain to them what happens if they don’t do their jobs well. How their jobs fit into the big picture and the strategic mission.&lt;/li&gt;
  &lt;li&gt;If you really want to take care of your people, you need to push them. You need to make sure they understand their jobs. You need to drive them toward their goals.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The easy path leads to misery. The path of discipline leads to freedom.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Optimal discipline in a team is not imposed by the leader; it is chosen by the team itself. Optimal discipline is self-discipline&lt;/li&gt;
  &lt;li&gt;A leader doesn’t have to constantly police infractions and motivate them to give their best; if there is pride, the team polices itself.&lt;/li&gt;
  &lt;li&gt;To build pride within a team, you have to put the members in situations that require unity, strength, and perseverance to get through.&lt;/li&gt;
  &lt;li&gt;No pride is built on easy wins, but a team has to win some to have some pride&lt;/li&gt;
  &lt;li&gt;Encourage the rest of your team to think and to question you. Don’t surround yourself with yes-men. They do nothing to help you or the team.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“There are no situations and no exceptions where a subordinate is ultimately responsible for the performance of a team. It is always the leader’s fault. The exception is that it is possible to have a good team that delivers outstanding performance despite a bad leader.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;becoming-a-leader&quot;&gt;Becoming a Leader&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Don’t make being chosen as a leader your goal. Instead, make your goal helping the team win.&lt;/li&gt;
  &lt;li&gt;Lack of preparation shows the team you don’t really care. So stay humble, study, ask questions, learn, and balance the dichotomy between too much humility and too much confidence.&lt;/li&gt;
  &lt;li&gt;Don’t be the leader with your hands in your pockets, but don’t be the leader with your hands in everything.&lt;/li&gt;
  &lt;li&gt;Don’t change things that are working, but don’t accept things that are not working&lt;/li&gt;
  &lt;li&gt;In everyday situations, overt leadership is not needed. It is better to give subtle direction and let the troops move forward based on their own ideas.&lt;/li&gt;
  &lt;li&gt;The best leaders usually led not by orders but by suggestion.&lt;/li&gt;
  &lt;li&gt;Indirect leadership almost always trumps direct leadership.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;leadership-skills&quot;&gt;Leadership Skills&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;“It was always safe to assume that when different people had different ideas, the idea that people liked the best was almost always their own.”&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Be decisive when you need to be, but try not to make decisions until you have to. Make smaller decisions with minimum commitment to move in the direction you most highly suspect is the right one.&lt;/li&gt;
    &lt;li&gt;Prevent giving your troops the impression that your delegation is avoidance of hard work is to take on some of the harshest jobs yourself. Do some of the nasty work.&lt;/li&gt;
    &lt;li&gt;Don’t alienate yourself from the group. Become part of it and earn your influence. This is the opposite of having an aggressive attitude and attacking the group’s beliefs head-on&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;maneuvers&quot;&gt;Maneuvers&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;One of the best tools a leader has to help shape others is leadership itself; giving people responsibility and putting them in leadership positions teaches them to be better in a multitude of ways.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Life is the ultimate teacher of humility. If a person lives long enough and takes on true challenges, eventually they will get humbled.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The medicine for a lack of confidence is very similar to the medicine for overconfidence: put the individual in charge.&lt;/li&gt;
  &lt;li&gt;Micromanagement is a tool, but it is not a permanent solution. Use it, but know when it has reached its limitations, and then remove or replace personnel to fix the problem.&lt;/li&gt;
  &lt;li&gt;It is always good to support your leader. If you undermine a leader, it not only hurts them, it also hurts the morale of the troops as well as you as a subordinate leader.&lt;/li&gt;
  &lt;li&gt;The best way to treat combat stress—and any stress—is to remove the affected individual from the stress-inducing environment.&lt;/li&gt;
  &lt;li&gt;To punish an individual for the infraction of an unwritten rule is usually inappropriate, unless the behavior is grievous enough that any reasonable person would deem it out of line.&lt;/li&gt;
  &lt;li&gt;No one should be surprised when they receive a punishment, and knowing what they are risking in terms of punishment will eliminate much of the need for it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;communication&quot;&gt;Communication&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;In any leadership situation, it is critical for the leader to keep everyone on the team as informed as possible.&lt;/li&gt;
  &lt;li&gt;You have to be proactive in updating your troops.&lt;/li&gt;
  &lt;li&gt;Get aggressive and attack rumors by getting ahead of the bad news and telling your team what is going on. Be truthful, be direct, and be timely.&lt;/li&gt;
  &lt;li&gt;Explaining why is important. But the why has to tie back and connect to everyone in the chain of command.&lt;/li&gt;
  &lt;li&gt;When delivering criticism, it is important to do it with consideration and delicacy.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“As a leader, you must remember you are being watched. And in everything you do, you must set the example.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Praise should be given when warranted. But it must be given judiciously, and it should be tempered with a goal that requires the team to still push.&lt;/li&gt;
  &lt;li&gt;Praise is a tool, but it is a tool that must be wielded with caution. Too much and it can cause people to let up and rest on their laurels. Too little and the team can lose hope.&lt;/li&gt;
  &lt;li&gt;Ultimatums are not optimal leadership tools. Like digging in, they allow no room to maneuver. No one likes being trapped and controlled.&lt;/li&gt;
  &lt;li&gt;A leader must have control over his or her emotions. Letting emotions drive decisions is a mistake.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reflect and Diminish&lt;/strong&gt; means to reflect the emotions you are seeing from your subordinate but diminish them to a more controlled level.&lt;/li&gt;
  &lt;li&gt;Patience is appreciated and respected much more than a hot temper.&lt;/li&gt;
  &lt;li&gt;The less you talk, the more people listen. Don’t be the person who is always talking. Speak when you need to, but don’t talk just to talk.&lt;/li&gt;
  &lt;li&gt;There is nothing wrong with apologizing when you make a mistake. That is part of taking ownership.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion-it-is-all-on-you-but-not-about-you&quot;&gt;Conclusion: It is All On You, But Not About You&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Leadership is all on you. But at the same time, leadership is not about you. Not at all. Leadership is about the team. The team is more important than you are. The moment you put your own interests above the team and above the mission is the moment you fail as a leader.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference:&lt;/h1&gt;

&lt;p&gt;Willink, Jocko. Leadership Strategy and Tactics: Field Manual. &lt;a href=&quot;https://www.amazon.com/Leadership-Strategy-Tactics-Field-Manual/dp/1250226848&quot;&gt;https://www.amazon.com/Leadership-Strategy-Tactics-Field-Manual/dp/1250226848&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">What makes leadership so hard is dealing with people, and people are crazy. And the craziest person a leader has to deal with is themselves.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://millengustavo.github.io/blog/images/leadership/leadership_book_cover.jpg" /><media:content medium="image" url="https://millengustavo.github.io/blog/images/leadership/leadership_book_cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>